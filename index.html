<!DOCTYPE html><html lang="[&quot;en&quot;,&quot;zh-TW&quot;,&quot;default&quot;]"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.0.0-rc.0" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.0.0-rc.0" type="image/png" sizes="32x32"><meta name="description" content="Share experience in software development">
<meta property="og:type" content="website">
<meta property="og:title" content="ExpShare">
<meta property="og:url" content="https://newjerseystyle.github.io/index.html">
<meta property="og:site_name" content="ExpShare">
<meta property="og:description" content="Share experience in software development">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="NewJerseyStyle">
<meta property="article:tag" content="development implementation iot c++ python tutorial">
<meta name="twitter:card" content="summary"><meta name="keywords" content="NewJerseyStyle, ExpShare"><meta name="description" content="Share experience in software development"><title>ExpShare | Playground of NewJerseyStyle</title><link ref="canonical" href="https://newjerseystyle.github.io/index.html"><link rel="alternate" href="/atom.xml" type="application/atom+xml"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.0.0-rc.0"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":false,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"carbon","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"Copy","copySuccess":"Copy Success","copyError":"Copy Error"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 4.2.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">Home</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/softdev/"><span class="header-nav-menu-item__icon"><i class="fas fa-laptop-code"></i></span><span class="header-nav-menu-item__text">Coding</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/toolz/"><span class="header-nav-menu-item__icon"><i class="fas fa-toolbox"></i></span><span class="header-nav-menu-item__text">Tools</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">Tags</span></a></div></div><div class="header-nav-search"><span class="header-nav-search__icon"><i class="fas fa-search"></i></span><span class="header-nav-search__text">Search</span></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">ExpShare</div><div class="header-banner-info__subtitle">Playground of NewJerseyStyle</div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content content-home" id="content"><section class="postlist"><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/en/2020/Why-Game-Theory-works/">Why Game Theory works</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-08-23</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-08-23</span></span></div></header><div class="post-body"><div class="post-excerpt"><!-- # Why Game Theory works -->

        <h2 id="Think-Forward"   >
          <a href="#Think-Forward" class="heading-link"><i class="fas fa-link"></i></a>Think Forward</h2>
      <ol>
<li>People receive information</li>
<li>People process information and think about it (interaction with belief)</li>
<li>Try to evaluate available actions</li>
<li>Make decisions and take actions</li>
</ol>

        <h2 id="Thank-Backward"   >
          <a href="#Thank-Backward" class="heading-link"><i class="fas fa-link"></i></a>Thank Backward</h2>
      <ol>
<li>People take actions based on decisions they made</li>
<li>People make decisoin based on evaluation to action according to information received</li>
</ol>

        <h2 id="Game-theory"   >
          <a href="#Game-theory" class="heading-link"><i class="fas fa-link"></i></a>Game theory</h2>
      <p>As the action is limited to a person, it does not matter with the complex processes in their brain.</p>
<p>Now with limited action porson can take, the reward of each action is limited.</p>
<p>People try to predict the reward for evaluating each action. Now we say, the information people received does not matter.</p>
<p>Now we know limited evaluations to each action of a player in game is related to the result.</p>
<p>We can then simplify the process with a theory and we called it “Game Theory”.</p>
<p>For all possible action, there are evaluation results to take the action or not. Both the evaluations and actions are limited, so we can calculate it in way of mathematics.</p>

        <h2 id="Conclusion"   >
          <a href="#Conclusion" class="heading-link"><i class="fas fa-link"></i></a>Conclusion</h2>
      <p>If we know the payoff of all actions to a player in game, we can predict the result. This is Game Theory.</p>
<p>Good day =)</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/en/2020/Pytorch-with-nvidia-docker-on-Ubuntu-18-04/">Pytorch with nvidia-docker on Ubuntu 18.04</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-06-18</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-08-23</span></span></div></header><div class="post-body"><div class="post-excerpt"><!-- # Pytorch with nvidia-docker on Ubuntu 18.04 -->

        <h2 id="Goal"   >
          <a href="#Goal" class="heading-link"><i class="fas fa-link"></i></a>Goal</h2>
      <p>A new computer with 2080 Ti just joint us. This time we try to use nvidia-docker.</p>
<p>We all loved docker continer don’t we? <span class="exturl"><a class="exturl__link"   href="https://docker-curriculum.com/"  target="_blank" rel="noopener">A Docker Tutorial for Beginners</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>

        <h2 id="Requirements"   >
          <a href="#Requirements" class="heading-link"><i class="fas fa-link"></i></a>Requirements</h2>
      <ul>
<li>Ubuntu 16.04 or later</li>
<li>NVIDIA GPU(s) that support CUDA</li>
</ul>

        <h2 id="Tips-for-LVM"   >
          <a href="#Tips-for-LVM" class="heading-link"><i class="fas fa-link"></i></a>Tips for LVM</h2>
      <p>If you install your Ubuntu with LVM, extend the LVM partition before anything else</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lvm</span><br><span class="line">lvm&gt; lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv</span><br><span class="line">lvm&gt; <span class="built_in">exit</span></span><br><span class="line">$ sudo resize2fs /dev/ubuntu-vg/ubuntu-lv</span><br></pre></td></tr></table></div></figure>
<p>The path <code>/dev/ubuntu-vg/ubuntu-lv</code> is physical device for my <code>root</code>, check your path with <code>sudo fdisk -l</code>.</p>

        <h2 id="Install-GPU-driver"   >
          <a href="#Install-GPU-driver" class="heading-link"><i class="fas fa-link"></i></a>Install GPU driver</h2>
      <p>Since CUDA is with the nvidia-docker all we need to do is to install GPU driver.</p>
<p>C++ compiler and other related tools are required to finish the installation, and I am sooooo L-A-Z-Y- that I just install everything I need to build anything.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install build-essential</span><br></pre></td></tr></table></div></figure>

<p>Find your driver from <span class="exturl"><a class="exturl__link"   href="https://www.nvidia.com/download/index.aspx?lang=en-us"  target="_blank" rel="noopener">NVIDIA download center</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> </p>
<p><img src="/en/2020/Pytorch-with-nvidia-docker-on-Ubuntu-18-04/Pytorch-with-nvidia-docker-on-Ubuntu-18-04.png" alt="Screen capture for downloading driver"></p>
<p>You will need to answer few question during installation, so don’t leave the screen for too long.</p>

        <h2 id="Use-docker-for-the-project"   >
          <a href="#Use-docker-for-the-project" class="heading-link"><i class="fas fa-link"></i></a>Use docker for the project</h2>
      <blockquote>
<p>Suppose you have installed docker, I choosed to install docker during installation of Ubuntu so it is come with my system… If you need to install it manually, check out official instructions <span class="exturl"><a class="exturl__link"   href="https://docs.docker.com/engine/install/ubuntu/"  target="_blank" rel="noopener">Install Docker Engine on Ubuntu</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
</blockquote>
<p>It will be a good idea to use separated Docker for each project. It is easy to set up and run.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run --gpus all nvidia/cuda nvidia-smi</span><br></pre></td></tr></table></div></figure>

<p>I can see it printed the status for all my GPUs.</p>

        <h2 id="Use-Pytorch-docker"   >
          <a href="#Use-Pytorch-docker" class="heading-link"><i class="fas fa-link"></i></a>Use Pytorch docker</h2>
      <figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run --gpus all pytorch/pytorch nvidia-smi</span><br></pre></td></tr></table></div></figure>

<p>It works too, great!</p>
<p>Now mount our data and source code for a trail…</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run --gpus all --rm -v /home/user/code:/workspace -v /home/user/data:/data -v /home/user/outputs:/outputs pytorch/pytorch</span><br></pre></td></tr></table></div></figure>

<p>Well done!</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/en/2020/Turn-Raspberry-Pi-3B-with-Ubuntu-Server-18-04-into-Wired-4G-Router/">Turn Raspberry Pi 3B+ with Ubuntu Server 18.04 into Wired 4G Router</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-04-26</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-08-23</span></span></div></header><div class="post-body"><div class="post-excerpt"><!-- # Turn Raspberry Pi 3B+ with Ubuntu Server 18.04 into Wired 4G Router -->

        <h2 id="Previous"   >
          <a href="#Previous" class="heading-link"><i class="fas fa-link"></i></a>Previous</h2>
      <p>We have used <a href="/en/2020/Raspberry-Pi-as-4G-LTE-Router/">Raspberry Pi as 4G LTE Router</a> before with NOOBS Raspbian system. This time I installed Ubuntu Server 18.04 for the Raspberry Pi.</p>
<p>However, the workflow does not work as expected with the tutorial we did before. I have just fixed the problems and made it work, here is the new tutorial for newer system.</p>

        <h2 id="Driver"   >
          <a href="#Driver" class="heading-link"><i class="fas fa-link"></i></a>Driver</h2>
      <p>I assume you have finished the assembly, or you can check out the <a href="/en/2020/Raspberry-Pi-as-4G-LTE-Router/#Assembly">older tutorial</a>.</p>
<p>Sixfab provides two methods to control the LTE module, <span class="exturl"><a class="exturl__link"   href="https://sixfab.com/ppp-installer-for-sixfab-shield/"  target="_blank" rel="noopener">PPP</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> and <span class="exturl"><a class="exturl__link"   href="https://sixfab.com/qmi-interface-with-3g-4g-lte-base-shield-v2/"  target="_blank" rel="noopener">QMI interface</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>.</p>
<p>I used PPP connection here.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://raw.githubusercontent.com/sixfab/Sixfab_PPP_Installer/master/ppp_installer/install.sh</span><br><span class="line"></span><br><span class="line">$ chmod +x install.sh</span><br><span class="line"></span><br><span class="line">$ sudo ./install.sh</span><br></pre></td></tr></table></div></figure>


        <h3 id="Tips-for-options"   >
          <a href="#Tips-for-options" class="heading-link"><i class="fas fa-link"></i></a>Tips for options</h3>
      <ul>
<li>Choose your Sixfab<ul>
<li><code>6</code> for the <code>Raspberry Pi 3G/4G&amp;LTE Base HAT</code> (The option <code>2</code> for <code>3G, 4G/LTE Base Shield</code> is compatible with <code>6</code>)</li>
</ul>
</li>
<li>APN<ul>
<li>Google the APN for the service provider</li>
<li>Or insert the SIM Card to a phone and view the APN in settings</li>
</ul>
</li>
<li>PORT name<ul>
<li>For 3G, 4G/LTE Base Shield &amp;&amp; Base HAT it will be <code>ttyUSB3</code></li>
<li>Always <code>ttyUSB3</code>, no thing to do with physical port</li>
</ul>
</li>
</ul>

        <h2 id="Troubleshooting"   >
          <a href="#Troubleshooting" class="heading-link"><i class="fas fa-link"></i></a>Troubleshooting</h2>
      
        <h3 id="Auto-connect-not-working"   >
          <a href="#Auto-connect-not-working" class="heading-link"><i class="fas fa-link"></i></a>Auto-connect not working</h3>
      <p>The automate establish connection bash script does not work on Ubuntu Server 18.04 start up. The connection will fail in start up. The solution is to run the script after boot.</p>
<p>I used <code>crontab</code> with <code>@reboot</code> to run the script after the booting instead of run it in start up.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crontab -e</span><br></pre></td></tr></table></div></figure>
<p>If it is the first time to use <code>crontab</code>, a question will pop-up and ask for the default editor for editing <code>crontab</code> jobs. Default <code>nano</code> is suggested, just press Enter. And add the following line.</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@reboot &#x2F;usr&#x2F;src&#x2F;reconnect.sh</span><br></pre></td></tr></table></div></figure>
<p><code>Ctrl</code>+<code>X</code>, <code>y</code>, <code>Enter</code> to save the setting in <code>nano</code>.</p>

        <h3 id="Other-problems"   >
          <a href="#Other-problems" class="heading-link"><i class="fas fa-link"></i></a>Other problems</h3>
      <p>You can check out the <a href="/en/2020/Raspberry-Pi-as-4G-LTE-Router/#Troubleshooting">older tutorial</a>.</p>

        <h2 id="Wired-Router"   >
          <a href="#Wired-Router" class="heading-link"><i class="fas fa-link"></i></a>Wired Router</h2>
      <p>I have setup <a href="/en/2020/Raspberry-Pi-as-4G-LTE-Router/#Wired-Router">a wired router</a> before, please follow the instructions there to set up the NAT connection and other DNS/DHCP server.</p>
<p><strong>Beware of the patches below</strong></p>

        <h3 id="File-interfaces-deprecated"   >
          <a href="#File-interfaces-deprecated" class="heading-link"><i class="fas fa-link"></i></a>File interfaces deprecated</h3>
      <p>Ubuntu Server 18.04 uses <code>netplan</code>, so we do not use <code>/etc/network/interfaces</code>, we edit the file <code>/etc/netplan/50-cloud-init.yaml</code>.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo nano /etc/netplan/50-cloud-init.yaml</span><br></pre></td></tr></table></div></figure>
<p>And change the <code>ethernets</code> section:</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">network:</span><br><span class="line">    ethernets:</span><br><span class="line">        eth0:</span><br><span class="line">            addresses: [192.168.2.1&#x2F;24]</span><br><span class="line">            gateway4: 192.168.2.1</span><br><span class="line">            nameservers:</span><br><span class="line">                addresses: [8.8.8.8,8.8.4.4]</span><br><span class="line">            dhcp4: no</span><br><span class="line">    version: 2</span><br></pre></td></tr></table></div></figure>
<p>Now verify the yaml file.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo netplan try</span><br></pre></td></tr></table></div></figure>
<p>It will ask user to type enter after passing the testing, if user did not press enter, after a timeout of 120 seconds will automatically rewrite the yaml file to default configuration. I guess it is a fail safe mechanism.</p>
<p>Now apply the configuration.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo netplan apply</span><br></pre></td></tr></table></div></figure>
<p>Done!</p>
<p><span class="exturl"><a class="exturl__link"   href="https://websiteforstudents.com/configure-static-ip-addresses-on-ubuntu-18-04-beta/"  target="_blank" rel="noopener">More about netplan</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>.</p>

        <h3 id="No-wwan0-device"   >
          <a href="#No-wwan0-device" class="heading-link"><i class="fas fa-link"></i></a>No wwan0 device</h3>
      <p>Change <code>wwan0</code> to <code>ppp0</code> in the commands in the old tutorial.</p>

        <h3 id="NAT-does-not-work"   >
          <a href="#NAT-does-not-work" class="heading-link"><i class="fas fa-link"></i></a>NAT does not work</h3>
      <p>In Ubnutu 18.04, the <code>rc-local</code> seem to be deprecated that <code>iptables-restore</code> will not be executed. Used <code>crontab</code> to replace it.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ crontab -e</span><br></pre></td></tr></table></div></figure>
<p>And add one more line at the bottom</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@reboot sudo iptables-restore &lt; &#x2F;etc&#x2F;iptables.ipv4.nat</span><br></pre></td></tr></table></div></figure>

        <h2 id="DONE"   >
          <a href="#DONE" class="heading-link"><i class="fas fa-link"></i></a>DONE</h2>
      <p>Connect laptop to Raspberry Pi </p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ping 8.8.8.8</span><br><span class="line">PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.</span><br><span class="line">64 bytes from 8.8.8.8: icmp_seq=2 ttl=51 time=123.8 ms</span><br><span class="line">64 bytes from 8.8.8.8: icmp_seq=1 ttl=51 time=82.9 ms</span><br><span class="line">64 bytes from 8.8.8.8: icmp_seq=3 ttl=51 time=95.7 ms</span><br></pre></td></tr></table></div></figure>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/zh-TW/2020/%E5%9C%A8-Ubuntu-18-04-%E4%B8%8A%E5%AE%89%E8%A3%9D-CUDA-%E5%92%8C-Pytorch/">在 Ubuntu 18.04 上安裝 CUDA 和 Pytorch</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-04-26</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-08-23</span></span></div></header><div class="post-body"><div class="post-excerpt"><!-- # 在 Ubuntu 18.04 上安裝 CUDA 和 Pytorch -->

        <h2 id="目標"   >
          <a href="#目標" class="heading-link"><i class="fas fa-link"></i></a>目標</h2>
      <p>發生了不幸的事件，於是要重裝某個 GTX 1070 Ti 的電腦，安裝了 Ubuntu Server 18.04 之後我對於如何安裝 CUDA 有些混亂了，於是做個記錄方便之後參考。</p>
<p>其實安裝步驟很簡單，但是文檔就好像很詳細、很複雜的樣子。</p>

        <h2 id="系統要求"   >
          <a href="#系統要求" class="heading-link"><i class="fas fa-link"></i></a>系統要求</h2>
      <ul>
<li>Ubuntu 16.04 or later</li>
<li>NVIDIA GPU(s) that support CUDA</li>
</ul>

        <h2 id="使用-LVM-的溫馨提示"   >
          <a href="#使用-LVM-的溫馨提示" class="heading-link"><i class="fas fa-link"></i></a>使用 LVM 的溫馨提示</h2>
      <p>我安裝 Ubuntu Server 18.04 的時候用了 LVM，硬盤瞬間縮水不夠用。原來默認是不放開所有空間給系統用，所以要<span class="exturl"><a class="exturl__link"   href="https://askubuntu.com/questions/1106795/ubuntu-server-18-04-lvm-out-of-space-with-improper-default-partitioning"  target="_blank" rel="noopener">調整空間大小</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ lvm</span><br><span class="line">lvm&gt; lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv</span><br><span class="line">lvm&gt; <span class="built_in">exit</span></span><br><span class="line">$ resize2fs /dev/ubuntu-vg/ubuntu-lv</span><br></pre></td></tr></table></div></figure>


        <h2 id="安裝-CUDA"   >
          <a href="#安裝-CUDA" class="heading-link"><i class="fas fa-link"></i></a>安裝 CUDA</h2>
      <p>CUDA 的版本其實不用管，詳細安裝文檔可以參考<span class="exturl"><a class="exturl__link"   href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu-installation"  target="_blank" rel="noopener">鏈接</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>.</p>
<p>我已經安裝好最新的 Ubuntu Server LTS 版本，我知道它肯定支援 CUDA。而 GTX 1070 Ti也當然支援 CUDA。那就只有兩個編譯工具需要確認一下</p>
<p>我很懶惰，所以直接一鍵安裝所有編譯工具</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install build-essential</span><br></pre></td></tr></table></div></figure>

<p>然後安裝適合當前內核的 kernel headers 以供安裝 CUDA</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install linux-headers-$(uname -r)</span><br></pre></td></tr></table></div></figure>

<p>如果有自帶的驅動要先卸載，圖形化桌面要暫時關閉</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get purge nvidia-cuda*</span><br><span class="line">sudo apt-get purge nvidia-*</span><br></pre></td></tr></table></div></figure>
<p><span class="exturl"><a class="exturl__link"   href="https://askubuntu.com/questions/830916/how-to-install-cuda-8-0-on-ubuntu-16-04-with-nvidia-geforce-gtx-1080"  target="_blank" rel="noopener">參見</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>然後去 <span class="exturl"><a class="exturl__link"   href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=runfilelocal"  target="_blank" rel="noopener">CUDA Toolkit Download Page</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 下載安裝包，然後跟著網頁上的說明輸入指令。</p>
<p><img src="/en/2020/Installing-Pytorch-with-CUDA-on-Ubuntu-18-04/Installing-Pytorch-with-CUDA-on-Ubuntu-18.PNG" alt="Screen capture for downloading installation package"></p>
<p>我選擇自動安裝腳本來安裝，中間要輸入同意用戶協議之類的。</p>

        <h2 id="將項目放到-Docker-容器裏"   >
          <a href="#將項目放到-Docker-容器裏" class="heading-link"><i class="fas fa-link"></i></a>將項目放到 Docker 容器裏</h2>
      <p>這樣更容易管理資源和系統依賴的各種版本，如果全都放在本地系統就容易互相污染。學學如何用 Docker 和 NVIDIA GPU 進行深度學習項目<span class="exturl"><a class="exturl__link"   href="https://github.com/NVIDIA/nvidia-docker#ubuntu-16041804-debian-jessiestretchbuster"  target="_blank" rel="noopener">一鍵傳送</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --gpus all nvidia/cuda:10.0-base nvidia-smi</span><br></pre></td></tr></table></div></figure>


        <h2 id="安裝-Pytorch"   >
          <a href="#安裝-Pytorch" class="heading-link"><i class="fas fa-link"></i></a>安裝 Pytorch</h2>
      <p>你要有 Python 的軟件包管理器 <code>pip</code>，沒有就裝</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install python3-pip</span><br></pre></td></tr></table></div></figure>
<p>然後安裝 Pytorch</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip3 install torch torchvision</span><br></pre></td></tr></table></div></figure>
<p>如果你的環境和我不一樣，你需要 Pytorch <span class="exturl"><a class="exturl__link"   href="https://pytorch.org/get-started/locally/"  target="_blank" rel="noopener">的官方指令生成器</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/en/2020/Installing-Pytorch-with-CUDA-on-Ubuntu-18-04/">Installing Pytorch with CUDA on Ubuntu 18.04</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-04-25</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-08-23</span></span></div></header><div class="post-body"><div class="post-excerpt"><!-- # Installing Pytorch with CUDA on Ubuntu 18.04 -->

        <h2 id="Goal"   >
          <a href="#Goal" class="heading-link"><i class="fas fa-link"></i></a>Goal</h2>
      <p>For some reason I need to reinstall operating system and CUDA on a deep learning machine with GTX 1070 Ti. After installed Ubuntu Server 18.04, I was confused with the NVIDIA document, so I write down this notes to keep a reference.</p>
<p>The procedures are actually very simple, but the document was a bit too detailed or the layout is too complex to find the key points, I was lost in the lines.</p>

        <h2 id="Requirements"   >
          <a href="#Requirements" class="heading-link"><i class="fas fa-link"></i></a>Requirements</h2>
      <ul>
<li>Ubuntu 16.04 or later</li>
<li>NVIDIA GPU(s) that support CUDA</li>
</ul>

        <h2 id="Tips-for-LVM"   >
          <a href="#Tips-for-LVM" class="heading-link"><i class="fas fa-link"></i></a>Tips for LVM</h2>
      <p>Since I installed the Ubuntu Server 18.04 with LVM, I soon used up all space. It seems the default space is just fit for the operating system. <span class="exturl"><a class="exturl__link"   href="https://askubuntu.com/questions/1106795/ubuntu-server-18-04-lvm-out-of-space-with-improper-default-partitioning"  target="_blank" rel="noopener">Solution to it</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> is to extend the LVM partition.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lvm</span><br><span class="line">lvm&gt; lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv</span><br><span class="line">lvm&gt; <span class="built_in">exit</span></span><br><span class="line">$ sudo resize2fs /dev/ubuntu-vg/ubuntu-lv</span><br></pre></td></tr></table></div></figure>


        <h2 id="Install-CUDA"   >
          <a href="#Install-CUDA" class="heading-link"><i class="fas fa-link"></i></a>Install CUDA</h2>
      <p>CUDA version does not really matter. <span class="exturl"><a class="exturl__link"   href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu-installation"  target="_blank" rel="noopener">Detailed Installation guide for your reference</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>.</p>
<p>It is simple as I have installed the latest Ubuntu Server LTS version and I know it is supports CUDA things, I also sure GTX 1070 Ti supports CUDA. All I need to do now is to install GCC compiler and Linux development packages.</p>
<p>I am so lazy that I just install everything I need to build anything.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install build-essential</span><br></pre></td></tr></table></div></figure>

<p>Then install the kernel headers and development packages for the currently running kernel.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install linux-headers-$(uname -r)</span><br></pre></td></tr></table></div></figure>

<p>Now go to <span class="exturl"><a class="exturl__link"   href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=runfilelocal"  target="_blank" rel="noopener">CUDA Toolkit Download Page</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> download the installation package and follow the guide to install it.</p>
<p><img src="/en/2020/Installing-Pytorch-with-CUDA-on-Ubuntu-18-04/Installing-Pytorch-with-CUDA-on-Ubuntu-18.PNG" alt="Screen capture for downloading installation package"></p>
<p>I choosed the easiest way to install, use a automated script. Copy the instructions, enter the terminal, press Enter key and wait… Few agreement will require manual input “accept” for EULA before proceed to install the package.</p>

        <h2 id="Use-docker-for-the-project"   >
          <a href="#Use-docker-for-the-project" class="heading-link"><i class="fas fa-link"></i></a>Use docker for the project</h2>
      <p>It will be a good idea to use Docker for each project. It is easy to set up and run. If you know how to work with Docker, check out the <span class="exturl"><a class="exturl__link"   href="https://github.com/NVIDIA/nvidia-docker#ubuntu-16041804-debian-jessiestretchbuster"  target="_blank" rel="noopener">document</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --gpus all nvidia/cuda:10.0-base nvidia-smi</span><br></pre></td></tr></table></div></figure>


        <h2 id="Install-Pytorch"   >
          <a href="#Install-Pytorch" class="heading-link"><i class="fas fa-link"></i></a>Install Pytorch</h2>
      <p>Make sure <code>pip</code> is available for Python, install it if not.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install python3-pip</span><br></pre></td></tr></table></div></figure>
<p>And then install Pytorch.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip3 install torch torchvision</span><br></pre></td></tr></table></div></figure>
<p>Find the command for your environment from Pytorch <span class="exturl"><a class="exturl__link"   href="https://pytorch.org/get-started/locally/"  target="_blank" rel="noopener">Official document</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/zh-TW/2020/%E5%9C%A8-Ubuntu-18-04-%E4%B8%8A%E5%AE%89%E8%A3%9D-ROCm-3.3.0-%E5%92%8C-Pytorch/">在 Ubuntu 18.04 上安裝 ROCm 3.3.0 和 Pytorch</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-04-18</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-08-23</span></span></div></header><div class="post-body"><div class="post-excerpt"><!-- # 在 Ubuntu 18.04 上安裝 ROCm 3.3.0 和 Pytorch -->

        <h2 id="目標"   >
          <a href="#目標" class="heading-link"><i class="fas fa-link"></i></a>目標</h2>
      <p>現在我有一個可以跑 TensorFlow 的 RX 580 了。可是我還是不滿足，於是買了一個 VEGA 56。10.54 TFLOPS 的 FP32 運算能力現在好像也只要 266 美刀。</p>
<p>和之前一樣，在 Ubuntu Server 18.04 上安裝 ROCm 3.3.0 （參見<a href="/en/2020/Installing-ROCm-for-Deep-learning-on-Ubuntu-18.04/">之前的操作和系統要求</a>)。</p>
<blockquote>
<p>RX 580 不能用 Pytorch 了，Pytorch 說它太舊了</p>
</blockquote>
<p>我基本上是按照 <span class="exturl"><a class="exturl__link"   href="https://rocm-documentation.readthedocs.io/en/latest/Deep_learning/Deep-learning.html"  target="_blank" rel="noopener">ROCm 的官方教學</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 不過有些地方可能出問題，這邊提供了指引去避免這些坑。</p>
<p><strong>你至少要 16 GB 記憶體，不然編譯會很慢而且測試的時候會出錯，我試過了</strong></p>

        <h2 id="準備編譯"   >
          <a href="#準備編譯" class="heading-link"><i class="fas fa-link"></i></a>準備編譯</h2>
      
        <h3 id="安裝-Docker"   >
          <a href="#安裝-Docker" class="heading-link"><i class="fas fa-link"></i></a>安裝 Docker</h3>
      <p>我們使用 Docker 來編譯，避免污染系統的設置，這樣之後編譯其他版本的時候不會需要卸載和重新安裝。Docker 其實就類似是一個虛擬機，<span class="exturl"><a class="exturl__link"   href="https://www.docker.com/resources/what-container"  target="_blank" rel="noopener">可以去官網瞭解更多</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 我現在都基本上不用虛擬機，全都用 Docker 了。</p>
<p><span class="exturl"><a class="exturl__link"   href="https://docs.docker.com/engine/install/ubuntu/"  target="_blank" rel="noopener">參考官方文檔安裝 Docker </a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 或者你可以學我直接用一鍵安裝的腳本。官方說 <strong>千萬千萬要先自己檢查一下我們的腳本再運行，不然剛好有人惡意黑了我們改了腳本你就糟了</strong>。很貼心的說明。</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ curl -fsSL https://get.docker.com -o get-docker.sh</span><br><span class="line"><span class="comment"># 跑下面這句運行它之前，先打開來看看腳本裏面寫了什麼哦~</span></span><br><span class="line">$ sudo sh get-docker.sh</span><br></pre></td></tr></table></div></figure>

        <h3 id="安裝-ROCm-Dev-開發軟件包"   >
          <a href="#安裝-ROCm-Dev-開發軟件包" class="heading-link"><i class="fas fa-link"></i></a>安裝 ROCm-Dev 開發軟件包</h3>
      <p>編譯 Pytorch 之前要先安裝 <code>rocm-dev</code>提供 ROCm 的 API 接口</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br><span class="line"> </span><br><span class="line">$ sudo apt-get upgrade</span><br><span class="line"> </span><br><span class="line">$ sudo apt-get install rocm-dev</span><br></pre></td></tr></table></div></figure>

        <h2 id="Docker-鏡像和下載代碼"   >
          <a href="#Docker-鏡像和下載代碼" class="heading-link"><i class="fas fa-link"></i></a>Docker 鏡像和下載代碼</h2>
      
        <h3 id="下載編譯環境"   >
          <a href="#下載編譯環境" class="heading-link"><i class="fas fa-link"></i></a>下載編譯環境</h3>
      <p>現在我要編譯配合 ROCm 3.3.0 的 Pytorch了。官方文檔認爲你不可能是白癡，沒有告訴你記得檢查 <code>docker pull rocm/pytorch:rocm3.0_ubuntu16.04_py3.6_pytorch</code> 這句是不是對應你的 ROCm 版本。到 <span class="exturl"><a class="exturl__link"   href="https://hub.docker.com/r/rocm/pytorch/tags"  target="_blank" rel="noopener">DockerHub</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 尋找你的 ROCm 版本的標籤來換掉文檔中的 <code>rocm3.0_ubuntu16.04_py3.6_pytorch</code>。我的 ROCm 3.3.0 是<code>rocm3.3_ubuntu16.04_py3.6_pytorch</code>。</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker pull rocm/pytorch:rocm3.3_ubuntu16.04_py3.6_pytorch</span><br></pre></td></tr></table></div></figure>

        <h3 id="下載-Pytorch-源代碼"   >
          <a href="#下載-Pytorch-源代碼" class="heading-link"><i class="fas fa-link"></i></a>下載 Pytorch 源代碼</h3>
      <p>我們用 Git 來下載代碼，沒有的話請自行安裝：<code>sudo apt-get install git</code></p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~</span><br><span class="line"> </span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/pytorch/pytorch.git</span><br></pre></td></tr></table></div></figure>
<p>然後讓 Git 把其他依賴的代碼一鍵自動下載</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> pytorch</span><br><span class="line"> </span><br><span class="line">$ git submodule init</span><br><span class="line"> </span><br><span class="line">$ git submodule update</span><br></pre></td></tr></table></div></figure>
<p>可是編譯的時候還是報錯，有部分的依賴好像還有自己的依賴，所以要跑 <code>git submodule update --init --recursive</code> 而不是 <code>git submodule update</code>。用 <code>--recursive</code> 將依賴的依賴的依賴的依賴什麼的都統統下載下來。</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git submodule update --init --recursive</span><br></pre></td></tr></table></div></figure>


        <h2 id="編譯！"   >
          <a href="#編譯！" class="heading-link"><i class="fas fa-link"></i></a>編譯！</h2>
      <p>先跑一下 <code>rocminfo</code> 並且記下你的 GPU 型號（例如我是 gfx 900）</p>

        <h3 id="進入編譯環境"   >
          <a href="#進入編譯環境" class="heading-link"><i class="fas fa-link"></i></a>進入編譯環境</h3>
      <p>這裏，再一次確認你的鏡像標籤，我的標籤是 <code>rocm3.3_ubuntu16.04_py3.6_pytorch</code> 對應 ROCm 3.3.0。你可能是其他版本需要修改再跑。</p>
<blockquote>
<p>如果你想保留這個編譯的容器而不是完成之後自動移除，你可以移除 <strong><code>--rm</code></strong> 參數。</p>
</blockquote>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -it -v <span class="variable">$HOME</span>:/data --privileged --rm --device=/dev/kfd --device=/dev/dri --group-add video rocm/pytorch:rocm3.3_ubuntu16.04_py3.6_pytorch</span><br></pre></td></tr></table></div></figure>
<p>之後應該會看到一個類似這樣的環境。</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;#</span><br></pre></td></tr></table></div></figure>
<p>切換到代碼的位置</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# cd &#x2F;data&#x2F;pytorch</span><br></pre></td></tr></table></div></figure>

        <h3 id="開始編譯"   >
          <a href="#開始編譯" class="heading-link"><i class="fas fa-link"></i></a>開始編譯</h3>
      <p>你需要先指出你的 GPU 型號。如果你忘記事先用 <code>rocminfo</code> 查看的話，可以去<span class="exturl"><a class="exturl__link"   href="https://llvm.org/docs/AMDGPUUsage.html#processors"  target="_blank" rel="noopener">查表</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 我是 VEGA 56 是 <code>gfx900</code>，用這行指令指定。</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# export HCC_AMDGPU_TARGET&#x3D;gfx900</span><br></pre></td></tr></table></div></figure>

<p>然後就用這個自動建構的指令</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# .jenkins&#x2F;pytorch&#x2F;build.sh</span><br></pre></td></tr></table></div></figure>
<p>如果你沒有足夠的記憶體，將會花費你很長時間……</p>

        <h2 id="測試"   >
          <a href="#測試" class="heading-link"><i class="fas fa-link"></i></a>測試</h2>
      <p>運行自動測試腳本</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# PYTORCH_TEST_WITH_ROCM&#x3D;1 python test&#x2F;run_test.py --verbose</span><br></pre></td></tr></table></div></figure>
<p>然後大概你會出現 <code>Import Error : no module named torch</code> 的問題。</p>
<p>那樣的話，你需要確認你的 Python 版本。我的情況是這樣的：</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# python -V</span><br><span class="line">Python 2.7.18</span><br><span class="line">root@f78375b1c487:&#x2F;# python3 -V</span><br><span class="line">Python 3.5.8</span><br><span class="line">root@f78375b1c487:&#x2F;# python3.6 -V</span><br><span class="line">Python 3.6.10</span><br></pre></td></tr></table></div></figure>
<p>這個 Pytorch 應該是編譯並且安裝給了 Python 3.6，所以要用 Python 3.6 來測試才對。</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# PYTORCH_TEST_WITH_ROCM&#x3D;1 python3.6 test&#x2F;run_test.py --verbose</span><br></pre></td></tr></table></div></figure>

        <h3 id="出錯？"   >
          <a href="#出錯？" class="heading-link"><i class="fas fa-link"></i></a>出錯？</h3>
      <p>如果沒有 16 GB RAM 就會出現 <code>malloc</code> 無法賦予位置的錯誤</p>

        <h3 id="Install-torchvision"   >
          <a href="#Install-torchvision" class="heading-link"><i class="fas fa-link"></i></a>Install torchvision</h3>
      <p>試試安裝 torchvision，應該是在編譯過程中已經一起安裝了的。</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# pip install torchvision</span><br></pre></td></tr></table></div></figure>

        <h3 id="保存這個-Docker-容器"   >
          <a href="#保存這個-Docker-容器" class="heading-link"><i class="fas fa-link"></i></a>保存這個 Docker 容器</h3>
      <p>用容器 ID 來保存它，ID 一直都在上面有顯示，例如我的就是 <code>f78375b1c487</code></p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker commit f78375b1c487 -m <span class="string">'pytorch installed'</span></span><br></pre></td></tr></table></div></figure>
<p>如果退出這個容器的話就什麼也沒有了（前面執行 <code>docker run</code> 的時候使用的 <code>--rm</code> 參數發揮效用），所以需要在另一個指令行裡執行 <code>commit</code>。你可以另外開一個命令行（Terminal）窗口，或者用 <code>Ctrl</code>+<code>Alt</code>+<code>F3</code> 進入另一個黑底白字的命令行介面，或者如果你是和我一樣在用 <code>tmux</code>，就 <code>Ctrl</code>+<code>B</code> 然後再輸入 <code>C</code> 再開一個窗口來執行 <code>commit</code>。</p>

        <h2 id="DONE"   >
          <a href="#DONE" class="heading-link"><i class="fas fa-link"></i></a>DONE</h2>
      <p><span class="exturl"><a class="exturl__link"   href="https://github.com/twtrubiks/docker-tutorial"  target="_blank" rel="noopener">學學如何用 Docker 吧</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>，它與你來日方長。</p>
<p>Pytorch time! (&gt;w&lt;)b</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/zh-TW/2020/%E5%9C%A8-Ubuntu-18-04-%E4%B8%8A%E5%AE%89%E8%A3%9D-ROCm-3.3.0-%E5%92%8C-TensorFlow/">在 Ubuntu 18.04 上安裝 ROCm 3.3.0 和 TensorFlow</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-04-18</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-08-23</span></span></div></header><div class="post-body"><div class="post-excerpt"><!-- # 在 Ubuntu 18.04 上安裝 ROCm 3.3.0 和 TensorFlow -->

        <h2 id="目標"   >
          <a href="#目標" class="heading-link"><i class="fas fa-link"></i></a>目標</h2>
      <p>我一直覺得 AMD 出的幾張織女星顯卡很是吸引。 <span class="exturl"><a class="exturl__link"   href="https://www.techpowerup.com/gpu-specs/radeon-rx-vega-56.c2993"  target="_blank" rel="noopener">VEGA 56</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> ，<span class="exturl"><a class="exturl__link"   href="https://www.techpowerup.com/gpu-specs/radeon-rx-vega-64.c2871"  target="_blank" rel="noopener">VEGA 64</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 都是很強勁的計算裝置，和 <span class="exturl"><a class="exturl__link"   href="https://www.techpowerup.com/gpu-specs/geforce-rtx-2080-ti.c3305"  target="_blank" rel="noopener">NVIDIA 2080 Ti</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 不相上下。 <span class="exturl"><a class="exturl__link"   href="https://www.techpowerup.com/gpu-specs/radeon-vii.c3358"  target="_blank" rel="noopener">Radeon VII</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 更是讓我流口水，13.44 TFLOPS FP32 (float) 運算能力（理論值）而且只有 2080 Ti 的一半價錢。</p>
<p>爲了嘗試 AMD 的表現，和依賴庫的穩定性，我買了一張 RX 580 來玩，只花了我100美刀。<span class="exturl"><a class="exturl__link"   href="https://www.techpowerup.com/gpu-specs/radeon-rx-580.c2938"  target="_blank" rel="noopener">AMD Radeon RX 580</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 感覺性價比很高，有 6 TFLOPS 的運算能力。</p>
<p>NVIDIA 的 GPU 就用 CUDA 來跑，那 AMD 怎麼安裝 CUDA 呢？不怕，我們有 ROCm 來替代 CUDA。</p>

        <h2 id="前提"   >
          <a href="#前提" class="heading-link"><i class="fas fa-link"></i></a>前提</h2>
      <p>對於使用性價比超高的 AMD GPU 來跑模型我已經迫不及待了，不過原來 ROCm 有很多要求，不是隨便哪個舊電腦就可以跑的。</p>
<ul>
<li>要有比較新的 CPU 支援 PCIe Gen3 和 PCIe Atomics 操作的才行</li>
<li>底板要支援 PCIe 3.0</li>
<li>GPU 也要比較新的才行，AMD 說太舊的顯卡性能太差懶得支援了</li>
<li>更新你的 Linux 系統到內核版本 kernel 4.17 以上（如果你用 Windows 就不行了）</li>
</ul>

        <h3 id="支援的-CPU-型號"   >
          <a href="#支援的-CPU-型號" class="heading-link"><i class="fas fa-link"></i></a>支援的 CPU 型號</h3>
      <ul>
<li>AMD Ryzen CPUs</li>
<li>The CPUs in AMD Ryzen APUs</li>
<li>AMD Ryzen Threadripper CPUs</li>
<li>AMD EPYC CPUs</li>
<li>Intel Xeon E7 v3 或以上</li>
<li>Intel Xeon E5 v3 或以上</li>
<li>Intel Xeon E3 v3 或以上</li>
<li>Intel Core i7 v4 或以上 （i.e. 要 Haswell 或更新的架構）</li>
<li>Intel Core i5 v4 或以上</li>
<li>Intel Core i3 v4 或以上</li>
<li>某些 Ivy Bridge-E systems</li>
</ul>
<p><span class="exturl"><a class="exturl__link"   href="https://github.com/RadeonOpenCompute/ROCm#supported-cpus"  target="_blank" rel="noopener">原文鏈接</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>我也不知道 “某些 Ivy Bridge-E systems” 是哪些，有需要的話請前往<span class="exturl"><a class="exturl__link"   href="https://github.com/RadeonOpenCompute/ROCm/issues"  target="_blank" rel="noopener">提問</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>。他們說有限度支援某些舊 CPU 和 GPU，不過最好就不要自尋短見了，除非你想幫忙搞底層代碼來支援那些硬件。</p>

        <h3 id="支援的-GPU-型號"   >
          <a href="#支援的-GPU-型號" class="heading-link"><i class="fas fa-link"></i></a>支援的 GPU 型號</h3>
      <ul>
<li>GFX8 GPUs<ul>
<li>“Fiji” 晶片，例如 AMD Radeon R9 Fury X 和 Radeon Instinct MI8</li>
<li>“Polaris 10” 晶片，例如 AMD Radeon RX 580 和 Radeon Instinct MI6</li>
</ul>
</li>
<li>GFX9 GPUs<ul>
<li>“Vega 10” 晶片，例如 AMD Radeon RX Vega 64 和 Radeon Instinct MI25</li>
<li>“Vega 7nm” 晶片，例如 Radeon Instinct MI50, Radeon Instinct MI60 和 AMD Radeon VII</li>
</ul>
</li>
</ul>
<p>參考 <span class="exturl"><a class="exturl__link"   href="https://github.com/RadeonOpenCompute/ROCm#supported-gpus"  target="_blank" rel="noopener">原文</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>. 有些 GFX8 和 GFX7 系列的 GPU 碰巧可以支援，不過如果出問題的話，也沒人可以幫你解決了。順帶一提我的 RX 580 後來發現 Pytorch 不支援了，嫌棄我的 GPU 舊。.</p>

        <h2 id="安裝-ROCm"   >
          <a href="#安裝-ROCm" class="heading-link"><i class="fas fa-link"></i></a>安裝 ROCm</h2>
      
        <h3 id="我的配置"   >
          <a href="#我的配置" class="heading-link"><i class="fas fa-link"></i></a>我的配置</h3>
      <ul>
<li>i5-4570 CPU</li>
<li>RX 580 GPU</li>
<li>Ubuntu Server 18.04.</li>
</ul>
<p><span class="exturl"><a class="exturl__link"   href="https://rocm-documentation.readthedocs.io/en/latest/Installation_Guide/Installation-Guide.html#ubuntu"  target="_blank" rel="noopener">官方的教學</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 可以直接用，除非你想用 Pytorch，那可能有幾個不起眼的地方官方忘記提醒你要注意。可以汲取我的<a href="/zh-TW/2020/在-Ubuntu-18-04-上安裝-CUDA-和-Pytorch/">教訓</a>避免再入坑。</p>

        <h3 id="前期準備"   >
          <a href="#前期準備" class="heading-link"><i class="fas fa-link"></i></a>前期準備</h3>
      <blockquote>
<p>如果你安裝 Pytorch 就要記一下你選的 ROCm 版本，我裝 ROCm 3.3.0。</p>
</blockquote>
<p>先更新系統，然後安裝 <code>libnuma-dev</code> 然後重啓</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update</span><br><span class="line"> </span><br><span class="line">$ sudo apt dist-upgrade</span><br><span class="line"> </span><br><span class="line">$ sudo apt install libnuma-dev</span><br><span class="line"> </span><br><span class="line">$ sudo reboot</span><br></pre></td></tr></table></div></figure>

        <h3 id="安裝-ROCm-1"   >
          <a href="#安裝-ROCm-1" class="heading-link"><i class="fas fa-link"></i></a>安裝 ROCm</h3>
      <p>將 ROCm 的下載位置加入到系統的軟件包管理當中</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ wget -q -O - http://repo.radeon.com/rocm/apt/debian/rocm.gpg.key | sudo apt-key add -</span><br><span class="line"> </span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">'deb [arch=amd64] http://repo.radeon.com/rocm/apt/debian/ xenial main'</span> | sudo te</span><br></pre></td></tr></table></div></figure>
<p>然後用系統的軟件包管理自動安裝</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update</span><br><span class="line"> </span><br><span class="line">$ sudo apt install rocm-dkms</span><br></pre></td></tr></table></div></figure>


        <h3 id="安裝善後"   >
          <a href="#安裝善後" class="heading-link"><i class="fas fa-link"></i></a>安裝善後</h3>
      <p>記得幫你自己的用戶加入 GPU 的操作權限</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo usermod -a -G video <span class="variable">$LOGNAME</span></span><br></pre></td></tr></table></div></figure>
<p>如果你要考慮再加其他用戶就請去複製<span class="exturl"><a class="exturl__link"   href="https://rocm-documentation.readthedocs.io/en/latest/Installation_Guide/Installation-Guide.html#ubuntu"  target="_blank" rel="noopener">官方文檔的指令</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>然後重啓系統</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo reboot</span><br></pre></td></tr></table></div></figure>


        <h3 id="測試安裝及啓用"   >
          <a href="#測試安裝及啓用" class="heading-link"><i class="fas fa-link"></i></a>測試安裝及啓用</h3>
      <p>測試 ROCm 的安裝</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ /opt/rocm/bin/rocminfo</span><br><span class="line">$ /opt/rocm/opencl/bin/x86_64/clinfo</span><br></pre></td></tr></table></div></figure>
<p>你應該會看到一些類似報告表格的東西，那就說明安裝成功了。</p>
<p>接下來將 ROCm 植入系統的環境 PATH 當中讓其他程序可以找得到它</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="string">'export PATH=$PATH:/opt/rocm/bin:/opt/rocm/profiler/bin:/opt/rocm/opencl/bin/x86_64'</span> |</span><br><span class="line">&gt; sudo tee -a /etc/profile.d/rocm.sh</span><br></pre></td></tr></table></div></figure>


        <h2 id="安裝-TensorFlow"   >
          <a href="#安裝-TensorFlow" class="heading-link"><i class="fas fa-link"></i></a>安裝 TensorFlow</h2>
      <p>這個很簡單，只有兩步，不過現在好像默認安裝 2.0 以上最新版本，如果你要安裝其他版本要自己指定版本，不會的話去問問谷歌<code>pip安裝如何指定版本</code>。<span class="exturl"><a class="exturl__link"   href="https://rocm-documentation.readthedocs.io/en/latest/Deep_learning/Deep-learning.html"  target="_blank" rel="noopener">參考原文說明書</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update</span><br><span class="line"> </span><br><span class="line">$ sudo apt install rocm-libs miopen-hip cxlactivitylogger rccl</span><br><span class="line"> </span><br><span class="line">$ sudo apt install wget python3-pip</span><br><span class="line"> </span><br><span class="line">$ pip3 install --user tensorflow-rocm</span><br></pre></td></tr></table></div></figure>

<p>現在 TensorFlow 2 應該是已經成功安裝了！可喜可賀 (^_^)b</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/en/2020/Installing-Pytorch-with-ROCm-3.3.0-on-Ubuntu-18.04/">Installing Pytorch with ROCm 3.3.0 on Ubuntu 18.04</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-04-18</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-08-23</span></span></div></header><div class="post-body"><div class="post-excerpt"><!-- # Installing Pytorch with ROCm on Ubuntu 18.04 -->

        <h2 id="Goal"   >
          <a href="#Goal" class="heading-link"><i class="fas fa-link"></i></a>Goal</h2>
      <p>I have my RX 580 ready for TensorFlow, I tried to install Pytorch but it say my GPU is too old and they do not support now. I brought a VEGA 56 with 10.54 TFLOPS for FP32 from newegg.com at price 266 USD. Let’s install Pytorch on top of ROCm 3.3.0.</p>
<p>First of all, install ROCm 3.3.0 (refer to <a href="/en/2020/Installing-ROCm-for-Deep-learning-on-Ubuntu-18.04/">previous tutorial</a>), requirements are the same.</p>
<p>We follow the instructions from <span class="exturl"><a class="exturl__link"   href="https://rocm-documentation.readthedocs.io/en/latest/Deep_learning/Deep-learning.html"  target="_blank" rel="noopener">ROCm</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> first, and I will add solution to problem I encountered.</p>
<p><strong>You will need to have 16 GB RAM or more to finish the whole compile, install and test process.</strong></p>

        <h2 id="Install-dependencies"   >
          <a href="#Install-dependencies" class="heading-link"><i class="fas fa-link"></i></a>Install dependencies</h2>
      
        <h3 id="Install-Docker"   >
          <a href="#Install-Docker" class="heading-link"><i class="fas fa-link"></i></a>Install Docker</h3>
      <p>You will need Docker to finish the installation. Docker is similar to virtual machine simulate a operating system environment isolate from your computer but Docker is much lighter and faster, <span class="exturl"><a class="exturl__link"   href="https://www.docker.com/resources/what-container"  target="_blank" rel="noopener">learn more from their docuements</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>.</p>
<p>Install <span class="exturl"><a class="exturl__link"   href="https://docs.docker.com/engine/install/ubuntu/"  target="_blank" rel="noopener">Docker with instructions from Docker official document</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> or you can use their convenience script. <strong>And examine scripts downloaded from the internet before running them locally.</strong> Make sure no one added a line to install a trojan into your computer.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ curl -fsSL https://get.docker.com -o get-docker.sh</span><br><span class="line"></span><br><span class="line">$ sudo sh get-docker.sh</span><br></pre></td></tr></table></div></figure>

        <h3 id="Install-ROCm-Dev-package"   >
          <a href="#Install-ROCm-Dev-package" class="heading-link"><i class="fas fa-link"></i></a>Install ROCm-Dev package</h3>
      <p>We are going to compile Pytorch from source, it requires <code>rocm-dev</code> package.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br><span class="line"></span><br><span class="line">$ sudo apt-get upgrade</span><br><span class="line"></span><br><span class="line">$ sudo apt-get install rocm-dev</span><br></pre></td></tr></table></div></figure>

        <h2 id="Step-Two"   >
          <a href="#Step-Two" class="heading-link"><i class="fas fa-link"></i></a>Step Two</h2>
      
        <h3 id="Prepare-environment-for-compiling"   >
          <a href="#Prepare-environment-for-compiling" class="heading-link"><i class="fas fa-link"></i></a>Prepare environment for compiling</h3>
      <p>Now we get the compilation environment for ROCm 3.3.0. The official document is not up-to-date which tells you to run <code>docker pull rocm/pytorch:rocm3.0_ubuntu16.04_py3.6_pytorch</code>. You should go to <span class="exturl"><a class="exturl__link"   href="https://hub.docker.com/r/rocm/pytorch/tags"  target="_blank" rel="noopener">their DockerHub</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> and make sure the tag <code>rocm3.0_ubuntu16.04_py3.6_pytorch</code> is what you need. For ROCm 3.3.0 I need <code>rocm3.3_ubuntu16.04_py3.6_pytorch</code> so I run:</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker pull rocm/pytorch:rocm3.3_ubuntu16.04_py3.6_pytorch</span><br></pre></td></tr></table></div></figure>

        <h3 id="Prepare-source-code-for-compiling"   >
          <a href="#Prepare-source-code-for-compiling" class="heading-link"><i class="fas fa-link"></i></a>Prepare source code for compiling</h3>
      <p>Now clone the source code of Pytorch with Git, do <code>sudo apt-get install git</code> if you don’t have git.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~</span><br><span class="line"></span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/pytorch/pytorch.git</span><br></pre></td></tr></table></div></figure>
<p>And then clone the other required source code automatically.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> pytorch</span><br><span class="line"></span><br><span class="line">$ git submodule init</span><br><span class="line"></span><br><span class="line">$ git submodule update</span><br></pre></td></tr></table></div></figure>
<p>I would suggest you to run <code>git submodule update --init --recursive</code> instead of <code>git submodule update</code> as some of the required source code may have their own required repository which needs to download with <code>--recursive</code> flag.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git submodule update --init --recursive</span><br></pre></td></tr></table></div></figure>


        <h2 id="Compile-and-Install"   >
          <a href="#Compile-and-Install" class="heading-link"><i class="fas fa-link"></i></a>Compile and Install</h2>
      
        <h3 id="Enter-environment-for-compiling"   >
          <a href="#Enter-environment-for-compiling" class="heading-link"><i class="fas fa-link"></i></a>Enter environment for compiling</h3>
      <p>Make sure the tag is correct before you run this command, my tag was <code>rocm3.3_ubuntu16.04_py3.6_pytorch</code> for ROCm 3.3.0. Official document forgot to remind you that the tag really matters.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -it -v <span class="variable">$HOME</span>:/data --privileged --rm --device=/dev/kfd --device=/dev/dri --group-add video rocm/pytorch:rocm3.3_ubuntu16.04_py3.6_pytorch</span><br></pre></td></tr></table></div></figure>
<p>And you will get something look another terminal:</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;#</span><br></pre></td></tr></table></div></figure>
<p>Now we change to the mounted source code directory:</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# cd &#x2F;data&#x2F;pytorch</span><br></pre></td></tr></table></div></figure>

        <h3 id="We-now-start-building"   >
          <a href="#We-now-start-building" class="heading-link"><i class="fas fa-link"></i></a>We now start building</h3>
      <p>Export the right code for GPU. You can check the code by running <code>rocminfo</code> on your host (out side the docker) from another terminal. Or you can find it <span class="exturl"><a class="exturl__link"   href="https://llvm.org/docs/AMDGPUUsage.html#processors"  target="_blank" rel="noopener">here</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> <code>Ctrl</code>+<code>F</code> search your GPU. <code>gfx900</code> for VEGA 56.</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# export HCC_AMDGPU_TARGET&#x3D;gfx900</span><br></pre></td></tr></table></div></figure>

        <h3 id="Start-compiling"   >
          <a href="#Start-compiling" class="heading-link"><i class="fas fa-link"></i></a>Start compiling</h3>
      <p>An automated script is provided, just run the following command will build and install everything to the docker container.</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# .jenkins&#x2F;pytorch&#x2F;build.sh</span><br></pre></td></tr></table></div></figure>

        <h2 id="Test"   >
          <a href="#Test" class="heading-link"><i class="fas fa-link"></i></a>Test</h2>
      <p>Before we finish everything, we need to run a test.</p>
<p>You may run the script for test…</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# PYTORCH_TEST_WITH_ROCM&#x3D;1 python test&#x2F;run_test.py --verbose</span><br></pre></td></tr></table></div></figure>
<p>And it may say <code>Import Error : no module named torch</code>. No worry, it is easy to fix.</p>
<p>Check your Python version</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# python -V</span><br><span class="line">Python 2.7.18</span><br><span class="line">root@f78375b1c487:&#x2F;# python3 -V</span><br><span class="line">Python 3.5.8</span><br><span class="line">root@f78375b1c487:&#x2F;# python3.6 -V</span><br><span class="line">Python 3.6.10</span><br></pre></td></tr></table></div></figure>
<p>Since the Pytorch was compiled and installed for Python 3.6, you need to use Python 3.6 for running the test.</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# PYTORCH_TEST_WITH_ROCM&#x3D;1 python3.6 test&#x2F;run_test.py --verbose</span><br></pre></td></tr></table></div></figure>

        <h3 id="Error"   >
          <a href="#Error" class="heading-link"><i class="fas fa-link"></i></a>Error?</h3>
      <p>If you do not have 16 GB RAM, it will use up all the memeory and <code>malloc</code> will raise error for unable to allocate memory.</p>
<p>If you try to run the test with RX 580, Pytorch will tell you the GPU is too old and their do not support now.</p>

        <h2 id="Finishing"   >
          <a href="#Finishing" class="heading-link"><i class="fas fa-link"></i></a>Finishing</h2>
      
        <h3 id="Install-torchvision"   >
          <a href="#Install-torchvision" class="heading-link"><i class="fas fa-link"></i></a>Install torchvision</h3>
      <p>Try to install it and you suppose to see it already installed with your compilation and installation of Pytorch.</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@f78375b1c487:&#x2F;# pip install torchvision</span><br></pre></td></tr></table></div></figure>

        <h3 id="Save-the-container"   >
          <a href="#Save-the-container" class="heading-link"><i class="fas fa-link"></i></a>Save the container</h3>
      <p>Use the container ID to save it into image so you can use it for different project and prevent environment contamination of different dependencies. The container ID is the hash showing in your terminal for container, <code>f78375b1c487</code> for mine.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker commit f78375b1c487 -m <span class="string">'pytorch installed'</span></span><br></pre></td></tr></table></div></figure>
<p>Change <code>f78375b1c487</code> to your container ID.</p>
<p>The docker container will be automatically removed after quit the environment. Therefore you will need to commit the container with another terminal. If you are using Command Line Interface, use <code>Ctrl</code>+<code>Alt</code>+<code>F3</code> (Usually <code>F7</code> is the Graphic Desktop, on Fedora it is <code>F2</code>) to switch to another terminal. I used <code>tmux</code> so I <code>Ctrl</code>+<code>B</code> and then press <code>%</code> create a new terminal on screen. And commit the container.</p>

        <h2 id="DONE"   >
          <a href="#DONE" class="heading-link"><i class="fas fa-link"></i></a>DONE</h2>
      <p>Pytorch time! (&gt;w&lt;)b</p>
<p>And I think you may need a <span class="exturl"><a class="exturl__link"   href="https://docker-curriculum.com/"  target="_blank" rel="noopener">tutorial for Docker</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> to get on.</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/en/2020/Installing-ROCm-3.3.0-for-Deep-learning-on-Ubuntu-18.04/">Installing ROCm 3.3.0 for Deep learning on Ubuntu 18.04</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-04-18</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-08-23</span></span></div></header><div class="post-body"><div class="post-excerpt"><!-- # Installing ROCm for Deep learning on Ubuntu 18.04 -->

        <h2 id="Goal"   >
          <a href="#Goal" class="heading-link"><i class="fas fa-link"></i></a>Goal</h2>
      <p>We all know AMD <span class="exturl"><a class="exturl__link"   href="https://www.techpowerup.com/gpu-specs/radeon-rx-vega-56.c2993"  target="_blank" rel="noopener">VEGA 56</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> and <span class="exturl"><a class="exturl__link"   href="https://www.techpowerup.com/gpu-specs/radeon-rx-vega-64.c2871"  target="_blank" rel="noopener">VEGA 64</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> are powerful GPUs competitive to <span class="exturl"><a class="exturl__link"   href="https://www.techpowerup.com/gpu-specs/geforce-rtx-2080-ti.c3305"  target="_blank" rel="noopener">NVIDIA RTX 2080 Ti</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>, the <span class="exturl"><a class="exturl__link"   href="https://www.techpowerup.com/gpu-specs/radeon-vii.c3358"  target="_blank" rel="noopener">Radeon VII</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> is even more powerful with 13.44 TFLOPS FP32 (float) performance (Theoretical) with a lower price at 699 USD.</p>
<p>I was thinking about having a Deep Learning machine, and I looked at the price for NVIDIA 2080 Ti, it is around 1548 USD here. So I made a call to my friend who sells 2nd hand electronic stuff and get a <span class="exturl"><a class="exturl__link"   href="https://www.techpowerup.com/gpu-specs/radeon-rx-580.c2938"  target="_blank" rel="noopener">AMD Radeon RX 580</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> with around 100 USD. RX 580 is a cost-effective card to get 6 TFLOPS performance.</p>
<p>But, how to fit it with TensorFlow or Pytorch? CUDA does not agree with AMD GPUs. No worries, I have found ROCm for AMD GPUs to replace CUDA.</p>

        <h2 id="Requirements"   >
          <a href="#Requirements" class="heading-link"><i class="fas fa-link"></i></a>Requirements</h2>
      <p>It is so excited to run TensorFlow on AMD GPU. But here are some important notes:</p>
<ul>
<li>Only new CPUs are supported as it requires PCIe Gen3 and PCIe Atomics</li>
<li>Only new GPUs are supported because old GPUs are too poor in performance</li>
<li>Use Linux with kernel 4.17 or above (Or you will have a hard time with it)</li>
</ul>

        <h3 id="Supported-CPUs"   >
          <a href="#Supported-CPUs" class="heading-link"><i class="fas fa-link"></i></a>Supported CPUs</h3>
      <ul>
<li>AMD Ryzen CPUs</li>
<li>The CPUs in AMD Ryzen APUs</li>
<li>AMD Ryzen Threadripper CPUs</li>
<li>AMD EPYC CPUs</li>
<li>Intel Xeon E7 v3 or newer CPUs</li>
<li>Intel Xeon E5 v3 or newer CPUs</li>
<li>Intel Xeon E3 v3 or newer CPUs</li>
<li>Intel Core i7 v4, Core i5 v4, Core i3 v4 or newer CPUs (i.e. Haswell family or newer)</li>
<li>Some Ivy Bridge-E systems</li>
</ul>
<p>Refer to <span class="exturl"><a class="exturl__link"   href="https://github.com/RadeonOpenCompute/ROCm#supported-cpus"  target="_blank" rel="noopener">GitHub of ROCm CPU section</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>. What are those “Some Ivy Bridge-E systems”? I don’t know too. You may Email them for support on that. You may see some older CPUs are limited supported, but I would suggest you don’t waste your time on that unless you want to contribute in ROCm to make it support older CPUs. It will make your life harder.</p>

        <h3 id="Supported-GPUs"   >
          <a href="#Supported-GPUs" class="heading-link"><i class="fas fa-link"></i></a>Supported GPUs</h3>
      <ul>
<li>GFX8 GPUs<ul>
<li>“Fiji” chips, such as on the AMD Radeon R9 Fury X and Radeon Instinct MI8</li>
<li>“Polaris 10” chips, such as on the AMD Radeon RX 580 and Radeon Instinct MI6</li>
</ul>
</li>
<li>GFX9 GPUs<ul>
<li>“Vega 10” chips, such as on the AMD Radeon RX Vega 64 and Radeon Instinct MI25</li>
<li>“Vega 7nm” chips, such as on the Radeon Instinct MI50, Radeon Instinct MI60 or AMD Radeon VII</li>
</ul>
</li>
</ul>
<p>Refer to <span class="exturl"><a class="exturl__link"   href="https://github.com/RadeonOpenCompute/ROCm#supported-gpus"  target="_blank" rel="noopener">GitHub of ROCm GPU section</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>. Few GFX8 and GFX7 GPUs are supported unofficially (if you got problem, no help, no guarantee).</p>

        <h2 id="Install-ROCm"   >
          <a href="#Install-ROCm" class="heading-link"><i class="fas fa-link"></i></a>Install ROCm</h2>
      
        <h3 id="Things-I-got"   >
          <a href="#Things-I-got" class="heading-link"><i class="fas fa-link"></i></a>Things I got</h3>
      <p>I got a i5-4570 for CPU (another 2nd hand computer with 140 USD) and RX 580 for GPU and installed Ubuntu Server 18.04.</p>
<p>The <span class="exturl"><a class="exturl__link"   href="https://rocm-documentation.readthedocs.io/en/latest/Installation_Guide/Installation-Guide.html#ubuntu"  target="_blank" rel="noopener">official tutorial</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> will be just fine for installnig ROCm and TensorFlow. But you will encounter problem in Pytorch (which is the reason I write this tutorial, I gave up on the first time, and this time I find <a href="/en/2020/Installing-Pytorch-with-ROCm-on-Ubuntu-18.04/">solution</a>).</p>

        <h3 id="Install-dependencies"   >
          <a href="#Install-dependencies" class="heading-link"><i class="fas fa-link"></i></a>Install dependencies</h3>
      <blockquote>
<p>Note the ROCm version you install, I am installing ROCm 3.3.0  This information will be useful for Pytorch installation.</p>
</blockquote>
<p>Update system, install <code>libnuma-dev</code> and reboot:</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update</span><br><span class="line"></span><br><span class="line">$ sudo apt dist-upgrade</span><br><span class="line"></span><br><span class="line">$ sudo apt install libnuma-dev</span><br><span class="line"></span><br><span class="line">$ sudo reboot</span><br></pre></td></tr></table></div></figure>

        <h3 id="Install-ROCm-1"   >
          <a href="#Install-ROCm-1" class="heading-link"><i class="fas fa-link"></i></a>Install ROCm</h3>
      <p>Add the ROCm apt repository.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ wget -q -O - http://repo.radeon.com/rocm/apt/debian/rocm.gpg.key | sudo apt-key add -</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">'deb [arch=amd64] http://repo.radeon.com/rocm/apt/debian/ xenial main'</span> | sudo te</span><br></pre></td></tr></table></div></figure>
<p>Install ROCm</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update</span><br><span class="line"></span><br><span class="line">$ sudo apt install rocm-dkms</span><br></pre></td></tr></table></div></figure>


        <h3 id="Post-installation"   >
          <a href="#Post-installation" class="heading-link"><i class="fas fa-link"></i></a>Post installation</h3>
      <p>Grant yourself permission for accessing your GPU</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo usermod -a -G video <span class="variable">$LOGNAME</span></span><br></pre></td></tr></table></div></figure>
<p>If you need to add more users, check the <span class="exturl"><a class="exturl__link"   href="https://rocm-documentation.readthedocs.io/en/latest/Installation_Guide/Installation-Guide.html#ubuntu"  target="_blank" rel="noopener">document</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>Reboot</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo reboot</span><br></pre></td></tr></table></div></figure>


        <h3 id="Test-and-Cofnigure"   >
          <a href="#Test-and-Cofnigure" class="heading-link"><i class="fas fa-link"></i></a>Test and Cofnigure</h3>
      <p>Test the ROCm installation.</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ /opt/rocm/bin/rocminfo</span><br><span class="line">$ /opt/rocm/opencl/bin/x86_64/clinfo</span><br></pre></td></tr></table></div></figure>
<p>You should see something like report.</p>
<p>Add ROCm to environment PATH:</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="string">'export PATH=$PATH:/opt/rocm/bin:/opt/rocm/profiler/bin:/opt/rocm/opencl/bin/x86_64'</span> |</span><br><span class="line">&gt; sudo tee -a /etc/profile.d/rocm.sh</span><br></pre></td></tr></table></div></figure>


        <h2 id="Install-TensorFlow"   >
          <a href="#Install-TensorFlow" class="heading-link"><i class="fas fa-link"></i></a>Install TensorFlow</h2>
      <p>This is simple with two steps, get some important libraries and install TensorFlow through <code>pip</code>. Refer to <span class="exturl"><a class="exturl__link"   href="https://rocm-documentation.readthedocs.io/en/latest/Deep_learning/Deep-learning.html"  target="_blank" rel="noopener">ROCm Doc</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update</span><br><span class="line"></span><br><span class="line">$ sudo apt install rocm-libs miopen-hip cxlactivitylogger rccl</span><br><span class="line"></span><br><span class="line">$ sudo apt install wget python3-pip</span><br><span class="line"></span><br><span class="line">$ pip3 install --user tensorflow-rocm</span><br></pre></td></tr></table></div></figure>

<p>It now installed TensorFlow 2 (latest), you need to specify version if you need just like installing other packages in Python.</p>

        <h2 id="DONE"   >
          <a href="#DONE" class="heading-link"><i class="fas fa-link"></i></a>DONE</h2>
      <p>TensorFlow time~ (^_^)b</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/zh-TW/2020/Raspberry-Pi-%E5%8C%96%E8%BA%AB-WiFi-%E8%9B%8B/">Raspberry Pi 化身 WiFi 蛋</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-04-12</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-08-23</span></span></div></header><div class="post-body"><div class="post-excerpt"><!-- # Raspberry Pi 化身 WiFi 蛋 -->

        <h2 id="前文"   >
          <a href="#前文" class="heading-link"><i class="fas fa-link"></i></a>前文</h2>
      <p>我們已經改造 <a href="/zh-TW/2020/Raspberry-Pi-使用-4G-數據網路/">Raspberry Pi 使用 4G 數據網路</a></p>

        <h2 id="目標"   >
          <a href="#目標" class="heading-link"><i class="fas fa-link"></i></a>目標</h2>
      <p>這次我們要讓 Raspberry Pi 將網絡分享給其他裝置，你可以選：</p>
<ul>
<li><a href="#無線路由器">製成<strong>無線</strong>路由器</a></li>
<li><a href="#有線路由器">製成路由器（有線）</a></li>
</ul>

        <h2 id="無線路由器"   >
          <a href="#無線路由器" class="heading-link"><i class="fas fa-link"></i></a>無線路由器</h2>
      <p>因為博主很懶惰，不想重複造輪子，所以無線路由器的教材就直接引用 <span class="exturl"><a class="exturl__link"   href="https://sixfab.com/using-sixfab-raspberry-p-shield-hat-as-a-wi-fi-hotspot-access-point/"  target="_blank" rel="noopener">Sixfab 的教學</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>如果你用的是早於 Raspberry Pi 3 的版本，你大概需要一個 USB 無線網路卡。</p>

        <h3 id="備份無線網絡配置"   >
          <a href="#備份無線網絡配置" class="heading-link"><i class="fas fa-link"></i></a>備份無線網絡配置</h3>
      <p>這並不是必須的步驟，不過萬一你日後想恢復原樣，這一步會很有幫助。</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo cp /etc/wpa_supplicant/wpa_supplicant.conf /etc/wpa_supplicant/wpa_supplicant.backup.conf</span><br></pre></td></tr></table></div></figure>


        <h3 id="配置無線網絡裝置"   >
          <a href="#配置無線網絡裝置" class="heading-link"><i class="fas fa-link"></i></a>配置無線網絡裝置</h3>
      <p>用以下指令清除舊配置</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo cp /dev/null /etc/wpa_supplicant/wpa_supplicant.conf</span><br></pre></td></tr></table></div></figure>
<p>將以下的新配置寫入到 <code>/etc/wpa_supplicant/wpa_supplicant.conf</code></p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ctrl_interface&#x3D;DIR&#x3D;&#x2F;var&#x2F;run&#x2F;wpa_supplicant GROUP&#x3D;netdev</span><br><span class="line">update_config&#x3D;1</span><br></pre></td></tr></table></div></figure>


        <h3 id="安裝-RaspAP"   >
          <a href="#安裝-RaspAP" class="heading-link"><i class="fas fa-link"></i></a>安裝 RaspAP</h3>
      <p>有一個簡單的安裝精靈 <span class="exturl"><a class="exturl__link"   href="https://github.com/billz/raspap-webgui"  target="_blank" rel="noopener">RaspAP</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 跟著它的步驟去進行安裝</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ wget -q https://git.io/voEUQ -O /tmp/raspap &amp;&amp; bash /tmp/raspap -y</span><br></pre></td></tr></table></div></figure>
<p>不過由於我本人並沒有試過這個方法，所以如果有任何疑問（例如默認的密碼、管理員界面等）還請前往 <span class="exturl"><a class="exturl__link"   href="https://sixfab.com/using-sixfab-raspberry-p-shield-hat-as-a-wi-fi-hotspot-access-point/"  target="_blank" rel="noopener">Sixfab 的教學</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 和<span class="exturl"><a class="exturl__link"   href="https://howtoraspberrypi.com/create-a-wi-fi-hotspot-in-less-than-10-minutes-with-pi-raspberry/"  target="_blank" rel="noopener">原文教學（包含故障排除章節）</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>

        <h2 id="有線路由器"   >
          <a href="#有線路由器" class="heading-link"><i class="fas fa-link"></i></a>有線路由器</h2>
      <p>我自己是用的這個方法，因為感覺會比較安心，始終有線的網絡感覺會比較穩定。這一部分就要使用網絡位址轉換技術（Network Address Translation，NAT）來連接 <code>ppp0</code> 和 <code>eth0</code> 兩個網絡界面（網卡）</p>
<p>我是參考<span class="exturl"><a class="exturl__link"   href="https://raspberrypi.stackexchange.com/questions/48307/sharing-the-pis-wifi-connection-through-the-ethernet-port"  target="_blank" rel="noopener">將無線網絡分享到網線教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>然後將它改成將 PPP 網絡分享到網線</p>

        <h3 id="DHCP-和-DNS-伺服器"   >
          <a href="#DHCP-和-DNS-伺服器" class="heading-link"><i class="fas fa-link"></i></a>DHCP 和 DNS 伺服器</h3>
      <p>你可以選自己喜歡的諸如 <code>isc-dhcp-server</code> 之類比較複雜的，這邊直接用 <code>dnsmasq</code> 比較方便</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install dnsmasq</span><br></pre></td></tr></table></div></figure>

        <h3 id="設置數據包轉發"   >
          <a href="#設置數據包轉發" class="heading-link"><i class="fas fa-link"></i></a>設置數據包轉發</h3>
      <p>編輯 <code>/etc/sysctl.conf</code> 裡的 <code>#net.ipv4.ip_forwarding=1</code> </p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo nano /etc/sysctl.conf</span><br></pre></td></tr></table></div></figure>
<p>移除<code>#</code>，將這行文字變成<code>net.ipv4.ip_forwarding=1</code>。這樣下次開機的時候就會啟用數據包轉發。</p>

        <h3 id="設置網絡界面"   >
          <a href="#設置網絡界面" class="heading-link"><i class="fas fa-link"></i></a>設置網絡界面</h3>
      <p>編輯 <code>/etc/network/interfaces</code> 裡的 <code>eth0</code> 部分</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">allow-hotplug eth0  </span><br><span class="line">iface eth0 inet static  </span><br><span class="line">    address 192.168.2.1</span><br><span class="line">    netmask 255.255.255.0</span><br><span class="line">    network 192.168.2.0</span><br><span class="line">    broadcast 192.168.2.255</span><br></pre></td></tr></table></div></figure>

        <h3 id="設置-dnsmasq"   >
          <a href="#設置-dnsmasq" class="heading-link"><i class="fas fa-link"></i></a>設置 dnsmasq</h3>
      <p>先備份一下 dnsmasq 原本的設置</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mv /etc/dnsmasq.conf /etc/dnsmasq.conf.orig</span><br></pre></td></tr></table></div></figure>
<p>然後編輯 <code>/etc/dnsmasq.conf</code></p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">interface&#x3D;eth0      # 分享到 eth0  </span><br><span class="line">listen-address&#x3D;192.168.2.1 # 和&#x2F;etc&#x2F;network&#x2F;interfaces配置的 IP 要一致  </span><br><span class="line"># Bind to the interface to make sure we aren&#39;t sending things elsewhere</span><br><span class="line">#### bind-interfaces #### BUT don&#39;t enable this.</span><br><span class="line">server&#x3D;8.8.8.8       # Forward DNS requests to Google DNS  </span><br><span class="line">domain-needed        # Don&#39;t forward short names  </span><br><span class="line"># Never forward addresses in the non-routed address spaces.</span><br><span class="line">bogus-priv</span><br><span class="line"># Assign IP addresses between 192.168.2.2 and 192.168.2.100 with a</span><br><span class="line"># 12 hour lease time</span><br><span class="line">dhcp-range&#x3D;192.168.2.2,192.168.2.100,12h</span><br></pre></td></tr></table></div></figure>
<blockquote>
<p>關於 <strong><code>bind-interfaces</code></strong> 部分，原本的教學是啟用的，不過我這邊啟用的話會無法分享網絡，所以這邊用<code>#</code>註釋掉了</p>
</blockquote>

        <h3 id="設置-NAT"   >
          <a href="#設置-NAT" class="heading-link"><i class="fas fa-link"></i></a>設置 NAT</h3>
      <p>通過防火牆來設置 NAT</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo iptables -t nat -A POSTROUTING -o wwan0 -j MASQUERADE  </span><br><span class="line">$ sudo iptables -A FORWARD -i wwan0 -o eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT  </span><br><span class="line">$ sudo iptables -A FORWARD -i eth0 -o wwan0 -j ACCEPT</span><br></pre></td></tr></table></div></figure>

        <h4 id="設置為永久-NAT"   >
          <a href="#設置為永久-NAT" class="heading-link"><i class="fas fa-link"></i></a>設置為永久 NAT</h4>
      <p>保存設置</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo sh -c <span class="string">"iptables-save &gt; /etc/iptables.ipv4.nat"</span></span><br></pre></td></tr></table></div></figure>
<p>修改 <code>/etc/rc.local</code> 開機自動載入 NAT 設置</p>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Add this line above exit 0</span><br><span class="line">iptables-restore &lt; &#x2F;etc&#x2F;iptables.ipv4.nat</span><br></pre></td></tr></table></div></figure>

        <h2 id="完成"   >
          <a href="#完成" class="heading-link"><i class="fas fa-link"></i></a>完成</h2>
      <p>將手提電腦連上 Raspberry Pi 然後……可以了</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ping 8.8.8.8</span><br><span class="line">PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.</span><br><span class="line">64 bytes from 8.8.8.8: icmp_seq=2 ttl=51 time=99.2 ms</span><br><span class="line">64 bytes from 8.8.8.8: icmp_seq=1 ttl=51 time=22.9 ms</span><br><span class="line">64 bytes from 8.8.8.8: icmp_seq=3 ttl=51 time=69.7 ms</span><br></pre></td></tr></table></div></figure>
</div></div></article></section><nav class="paginator"><div class="paginator-inner"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fas fa-angle-right"></i></a></div></nav></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><section class="sidebar-toc hide"></section><!-- ov = overview--><section class="sidebar-ov"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/logo.png" alt="avatar"></div><p class="sidebar-ov-author__text">NewJerseyStyle</p></div><div class="sidebar-ov-feed"><span class="sidebar-ov-feed-rss"><a class="sidebar-ov-feed-rss__link" href="/atom.xml" target="_blank" rel="noopener"><span class="sidebar-ov-feed-rss__icon"><i class="fas fa-rss"></i></span><span>RSS Subscribe</span></a></span></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">20</div><div class="sidebar-ov-state-item__name">Tags</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en zh-tw" target="_blank" rel="noopener" data-popover="Creative Commons" data-popover-pos="up"><img src="/images/cc-by-sa.svg"></a></div></section></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2020</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>NewJerseyStyle</span></div><div><span>Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a></span><span class="footer__devider">|</span><span>Theme - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><div class="search-mask"></div><div class="search-popup"><span class="search-close"></span><div class="search-input"><input placeholder="Search for Posts (Support multiple keywords)"></div><div class="search-results"></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/ribbon.js@latest/dist/ribbon.min.js" size="120" alpha="0.6" zIndex="-1"></script><script>function initSearch() {
  var isXML = true;
  var search_path = 'search.json';

  if (!search_path) {
    search_path = 'search.xml';
  } else if (/json$/i.test(search_path)) {
    isXML = false;
  }

  var path = '/' + search_path;
  $.ajax({
    url: path,
    dataType: isXML ? 'xml' : 'json',
    async: true,
    success: function (res) {
      var datas = isXML ? $('entry', res).map(function () {
        // 将 XML 转为 JSON
        return {
          title: $('title', this).text(),
          content: $('content', this).text(),
          url: $('url', this).text()
        };
      }).get() : res;
      var $input = $('.search-input input');
      var $result = $('.search-results');
      // 搜索对象（标题、内容）的权重，影响显示顺序
      var WEIGHT = { title: 100, content: 1 };
      var searchPost = function () {
        var searchText = $input.val().toLowerCase().trim();
        // 根据空白字符分隔关键字
        var keywords = searchText.split(/[\s]+/);
        // 搜索结果
        var matchPosts = [];

        // 有多个关键字时，将原文字整个保存下来
        if (keywords.length > 1) {
          keywords.push(searchText);
        }
        // 防止未输入字符时搜索
        if (searchText.length > 0) {
          datas.forEach(function (data) {
            var isMatch  = false;
            // 没有标题的文章使用预设的 i18n 变量代替
            var title = (data.title && data.title.trim()) || '[ Untitled ]';
            var titleLower = title && title.toLowerCase();
            // 删除 HTML 标签 和 所有空白字符
            var content = data.content && data.content.replace(/<[^>]+>/g, '');
            var contentLower = content && content.toLowerCase();
            // 删除重复的 /
            var postURL = data.url && decodeURI(data.url).replace(/\/{2,}/g, '/');
            // 标题中匹配到的关键词
            var titleHitSlice = [];
            // 内容中匹配到的关键词
            var contentHitSlice = [];

            keywords.forEach(function (keyword) {
              /**
              * 获取匹配的关键词的索引
              * @param {String} keyword 要匹配的关键字
              * @param {String} text 原文字
              * @param {Boolean} caseSensitive 是否区分大小写
              * @param {Number} weight 匹配对象的权重。权重大的优先显示
              * @return {Array}
              */
              function getIndexByword (word, text, caseSensitive, weight) {
                if (!word || !text) {
                  return [];
                };

                var startIndex = 0; // 每次匹配的开始索引
                var index = -1;     // 匹配到的索引值
                var result = [];    // 匹配结果

                if (!caseSensitive) {
                  word = word.toLowerCase();
                  text = text.toLowerCase();
                }

                while((index = text.indexOf(word, startIndex)) !== -1) {
                  var hasMatch = false;
                  // 索引位置相同的关键词，保留长度较长的
                  titleHitSlice.forEach(function (hit) {
                    if (hit.index === index && hit.word.length < word.length) {
                      hit.word = word;
                      hasMatch = true;
                    }
                  });
                  startIndex = index + word.length;
                  !hasMatch && result.push({ index: index, word: word, weight: weight });
                }
                return result;
              }
              titleHitSlice = titleHitSlice.concat(getIndexByword(keyword, titleLower, false, WEIGHT.title));
              contentHitSlice = contentHitSlice.concat(getIndexByword(keyword, contentLower, false, WEIGHT.content));
            });

            var hitTitle = titleHitSlice.length;
            var hitContent = contentHitSlice.length;

            if (hitTitle > 0 || hitContent > 0) {
              isMatch = true;
            }
            if (isMatch) {
              ;[titleHitSlice, contentHitSlice].forEach(function (hit) {
                // 按照匹配文字的索引的递增顺序排序
                hit.sort(function (left, right) {
                  return left.index - right.index;
                });
              });
              /**
              * 给文本中匹配到的关键词添加标记，从而进行高亮显示
              * @param {String} text 原文本
              * @param {Array} hitSlice 匹配项的索引信息
              * @param {Number} start 开始索引
              * @param {Number} end 结束索引
              * @return {String}
              */
              function highlightKeyword (text, hitSlice, start, end) {
                if (!text || !hitSlice || !hitSlice.length) {
                  return;
                }

                var result = '';
                var startIndex = start;
                var endIndex = end;
                hitSlice.forEach(function (hit) {
                  if (hit.index < startIndex) {
                    return;
                  }

                  var hitWordEnd = hit.index + hit.word.length;
                  result += text.slice(startIndex, hit.index);
                  result += '<b>' + text.slice(hit.index, hitWordEnd) + '</b>';
                  startIndex = hitWordEnd;
                });
                result += text.slice(startIndex, endIndex);
                return result;
              }

              var postData = {};
              // 文章总的搜索权重
              var postWeight = titleHitSlice.length * WEIGHT.title + contentHitSlice.length * WEIGHT.content;
              // 标记匹配关键词后的标题
              var postTitle = highlightKeyword(title, titleHitSlice, 0, title.length) || title;
              // 标记匹配关键词后的内容
              var postContent;
              // 显示内容的长度
              var SHOW_WORD_LENGTH = 200;
              // 命中关键词前的字符显示长度
              var SHOW_WORD_FRONT_LENGTH = 20;
              var SHOW_WORD_END_LENGTH = SHOW_WORD_LENGTH - SHOW_WORD_FRONT_LENGTH;

              // 截取匹配的第一个字符，前后共 200 个字符来显示
              if (contentHitSlice.length > 0) {
                var firstIndex = contentHitSlice[0].index;
                var start = firstIndex > SHOW_WORD_FRONT_LENGTH ? firstIndex - SHOW_WORD_FRONT_LENGTH : 0;
                var end = firstIndex + SHOW_WORD_END_LENGTH;
                postContent = highlightKeyword(content, contentHitSlice, start, end);
              } else { // 未匹配到内容，直接截取前 200 个字符来显示
                postContent = content.slice(0, SHOW_WORD_LENGTH);
              }
              postData.title = postTitle;
              postData.content = postContent;
              postData.url = postURL;
              postData.weight = postWeight;
              matchPosts.push(postData);
            }
          });
        }

        var resultInnerHtml = '';
        if (matchPosts.length) {
          // 按权重递增的顺序排序，使权重大的优先显示
          matchPosts.sort(function (left, right) {
            return right.weight - left.weight;
          });
          resultInnerHtml += '<ul>';
          matchPosts.forEach(function (post) {
            resultInnerHtml += '<li><a class="search-results-title" href="' + post.url + '">';
            resultInnerHtml += post.title;
            resultInnerHtml += '</a><div class="search-results-content">';
            resultInnerHtml += post.content;
            resultInnerHtml += '</div></li>';
          });
          resultInnerHtml += '</ul>';
        } else {
          resultInnerHtml += '<div class="search-results-none"><i class="far fa-meh"></i></div>';
        }
        $result.html(resultInnerHtml);
      };
      $input.on('input', searchPost);
      $input.on('keyup', function (e) {
        if (e.keyCode === Stun.utils.codeToKeyCode('Enter')) {
          searchPost();
        }
      });
    }
  });
}

function closeSearch () {
  $('body').css({ overflow: 'auto' });
  $('.search-popup').css({ display: 'none' });
  $('.search-mask').css({ display: 'none' });
}

window.addEventListener('DOMContentLoaded', function () {
  Stun.utils.pjaxReloadLocalSearch = function () {
    $('.header-nav-search').on('click', function (e) {
      e.stopPropagation();
      $('body').css('overflow', 'hidden');
      $('.search-popup')
        .velocity('stop')
        .velocity('transition.expandIn', {
          duration: 300,
          complete: function () {
            $('.search-popup input').focus();
          }
        });
      $('.search-mask')
        .velocity('stop')
        .velocity('transition.fadeIn', {
          duration: 300
        });

      initSearch();
    });
    $('.search-mask, .search-close').on('click', function () {
      closeSearch();
    });
    $(document).on('keydown', function (e) {
      // Escape <=> 27
      if (e.keyCode === Stun.utils.codeToKeyCode('Escape')) {
        closeSearch();
      }
    });
  };

  Stun.utils.pjaxReloadLocalSearch();
}, false);</script><script src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async=""></script><script>(adsbygoogle = window.adsbygoogle || []).push({
  google_ad_client: 'ca-pub-9667639204764993',
  enable_page_level_ads: true
});</script><script src="/js/utils.js?v=2.0.0-rc.0"></script><script src="/js/stun-boot.js?v=2.0.0-rc.0"></script><script src="/js/scroll.js?v=2.0.0-rc.0"></script><script src="/js/header.js?v=2.0.0-rc.0"></script><script src="/js/sidebar.js?v=2.0.0-rc.0"></script>
        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        $('a').each(function() {
          const $this = $(this);
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'newjerseystyle.github.io' || window.location.host) {
                    $this.attr('href', '/redirect_page.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (false) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script></body></html>