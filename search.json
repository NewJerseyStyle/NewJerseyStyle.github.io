[{"title":"Pytorch with nvidia-docker on Ubuntu 18.04","url":"/en/2020/Pytorch-with-nvidia-docker-on-Ubuntu-18-04/","content":"\n<!-- # Pytorch with nvidia-docker on Ubuntu 18.04 -->\n## Goal\nA new computer with 2080 Ti just joint us. This time we try to use nvidia-docker.\n\nWe all loved docker continer don't we? [A Docker Tutorial for Beginners](https://docker-curriculum.com/)\n\n## Requirements\n- Ubuntu 16.04 or later\n- NVIDIA GPU(s) that support CUDA\n\n## Tips for LVM\nIf you install your Ubuntu with LVM, extend the LVM partition before anything else\n```bash\n$ sudo lvm\nlvm> lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv\nlvm> exit\n$ sudo resize2fs /dev/ubuntu-vg/ubuntu-lv\n```\nThe path `/dev/ubuntu-vg/ubuntu-lv` is physical device for my `root`, check your path with `sudo fdisk -l`.\n\n## Install GPU driver\nSince CUDA is with the nvidia-docker all we need to do is to install GPU driver.\n\nC++ compiler and other related tools are required to finish the installation, and I am sooooo L-A-Z-Y- that I just install everything I need to build anything.\n```bash\n$ sudo apt-get install build-essential\n```\n\nFind your driver from [NVIDIA download center](https://www.nvidia.com/download/index.aspx?lang=en-us) \n\n![Screen capture for downloading driver](/en/2020/Pytorch-with-nvidia-docker-on-Ubuntu-18-04/Pytorch-with-nvidia-docker-on-Ubuntu-18-04.png)\n\nYou will need to answer few question during installation, so don't leave the screen for too long.\n\n## Use docker for the project\n> Suppose you have installed docker, I choosed to install docker during installation of Ubuntu so it is come with my system... If you need to install it manually, check out official instructions [Install Docker Engine on Ubuntu](https://docs.docker.com/engine/install/ubuntu/)\n\nIt will be a good idea to use separated Docker for each project. It is easy to set up and run.\n\n```bash\n$ sudo docker run --gpus all nvidia/cuda nvidia-smi\n```\n\nI can see it printed the status for all my GPUs.\n\n## Use Pytorch docker\n```bash\n$ sudo docker run --gpus all pytorch/pytorch nvidia-smi\n```\n\nIt works too, great!\n\nNow mount our data and source code for a trail...\n```bash\n$ sudo docker run --gpus all --rm -v /home/user/code:/workspace -v /home/user/data:/data -v /home/user/outputs:/outputs pytorch/pytorch\n```\n\nWell done!","tags":["NVIDIA","Pytorch","Deep learning","nvidia-docker"]},{"title":"Turn Raspberry Pi 3B+ with Ubuntu Server 18.04 into Wired 4G Router","url":"/en/2020/Turn-Raspberry-Pi-3B-with-Ubuntu-Server-18-04-into-Wired-4G-Router/","content":"\n<!-- # Turn Raspberry Pi 3B+ with Ubuntu Server 18.04 into Wired 4G Router -->\n## Previous\nWe have used [Raspberry Pi as 4G LTE Router](/en/2020/Raspberry-Pi-as-4G-LTE-Router/) before with NOOBS Raspbian system. This time I installed Ubuntu Server 18.04 for the Raspberry Pi.\n\nHowever, the workflow does not work as expected with the tutorial we did before. I have just fixed the problems and made it work, here is the new tutorial for newer system.\n\n## Driver\nI assume you have finished the assembly, or you can check out the [older tutorial](/en/2020/Raspberry-Pi-as-4G-LTE-Router/#Assembly).\n\nSixfab provides two methods to control the LTE module, [PPP](https://sixfab.com/ppp-installer-for-sixfab-shield/) and [QMI interface](https://sixfab.com/qmi-interface-with-3g-4g-lte-base-shield-v2/).\n\nI used PPP connection here.\n\n```bash\n$ wget https://raw.githubusercontent.com/sixfab/Sixfab_PPP_Installer/master/ppp_installer/install.sh\n\n$ chmod +x install.sh\n\n$ sudo ./install.sh \n```\n\n### Tips for options\n- Choose your Sixfab\n  - `6` for the `Raspberry Pi 3G/4G&LTE Base HAT` (The option `2` for `3G, 4G/LTE Base Shield` is compatible with `6`)\n- APN\n  - Google the APN for the service provider\n  - Or insert the SIM Card to a phone and view the APN in settings\n- PORT name\n  - For 3G, 4G/LTE Base Shield && Base HAT it will be `ttyUSB3`\n  - Always `ttyUSB3`, no thing to do with physical port\n\n## Troubleshooting\n### Auto-connect not working\nThe automate establish connection bash script does not work on Ubuntu Server 18.04 start up. The connection will fail in start up. The solution is to run the script after boot.\n\nI used `crontab` with `@reboot` to run the script after the booting instead of run it in start up.\n```bash\ncrontab -e\n```\nIf it is the first time to use `crontab`, a question will pop-up and ask for the default editor for editing `crontab` jobs. Default `nano` is suggested, just press Enter. And add the following line.\n```\n@reboot /usr/src/reconnect.sh\n```\n`Ctrl`+`X`, `y`, `Enter` to save the setting in `nano`.\n### Other problems\nYou can check out the [older tutorial](/en/2020/Raspberry-Pi-as-4G-LTE-Router/#Troubleshooting).\n\n## Wired Router\nI have setup [a wired router](/en/2020/Raspberry-Pi-as-4G-LTE-Router/#Wired-Router) before, please follow the instructions there to set up the NAT connection and other DNS/DHCP server.\n\n**Beware of the patches below**\n### File `interfaces` deprecated\nUbuntu Server 18.04 uses `netplan`, so we do not use `/etc/network/interfaces`, we edit the file `/etc/netplan/50-cloud-init.yaml`.\n```bash\n$ sudo nano /etc/netplan/50-cloud-init.yaml\n```\nAnd change the `ethernets` section:\n```\nnetwork:\n    ethernets:\n        eth0:\n            addresses: [192.168.2.1/24]\n            gateway4: 192.168.2.1\n            nameservers:\n                addresses: [8.8.8.8,8.8.4.4]\n            dhcp4: no\n    version: 2\n```\nNow verify the yaml file.\n```bash\n$ sudo netplan try\n```\nIt will ask user to type enter after passing the testing, if user did not press enter, after a timeout of 120 seconds will automatically rewrite the yaml file to default configuration. I guess it is a fail safe mechanism.\n\nNow apply the configuration.\n```bash\n$ sudo netplan apply\n```\nDone!\n\n[More about netplan](https://websiteforstudents.com/configure-static-ip-addresses-on-ubuntu-18-04-beta/).\n### No wwan0 device\nChange `wwan0` to `ppp0` in the commands in the old tutorial.\n### NAT does not work\nIn Ubnutu 18.04, the `rc-local` seem to be deprecated that `iptables-restore` will not be executed. Used `crontab` to replace it.\n```bash\n$ crontab -e\n```\nAnd add one more line at the bottom\n```\n@reboot sudo iptables-restore < /etc/iptables.ipv4.nat\n```\n## DONE\nConnect laptop to Raspberry Pi \n```bash\n$ ping 8.8.8.8\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n64 bytes from 8.8.8.8: icmp_seq=2 ttl=51 time=123.8 ms\n64 bytes from 8.8.8.8: icmp_seq=1 ttl=51 time=82.9 ms\n64 bytes from 8.8.8.8: icmp_seq=3 ttl=51 time=95.7 ms\n```\n","tags":["Raspberry Pi","WWAN","4G","LTE"]},{"title":"在 Ubuntu 18.04 上安裝 CUDA 和 Pytorch","url":"/zh-TW/2020/在-Ubuntu-18-04-上安裝-CUDA-和-Pytorch/","content":"\n<!-- # 在 Ubuntu 18.04 上安裝 CUDA 和 Pytorch -->\n## 目標\n發生了不幸的事件，於是要重裝某個 GTX 1070 Ti 的電腦，安裝了 Ubuntu Server 18.04 之後我對於如何安裝 CUDA 有些混亂了，於是做個記錄方便之後參考。\n \n其實安裝步驟很簡單，但是文檔就好像很詳細、很複雜的樣子。\n \n## 系統要求\n- Ubuntu 16.04 or later\n- NVIDIA GPU(s) that support CUDA\n \n## 使用 LVM 的溫馨提示\n我安裝 Ubuntu Server 18.04 的時候用了 LVM，硬盤瞬間縮水不夠用。原來默認是不放開所有空間給系統用，所以要[調整空間大小](https://askubuntu.com/questions/1106795/ubuntu-server-18-04-lvm-out-of-space-with-improper-default-partitioning)\n```bash\n$ lvm\nlvm> lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv\nlvm> exit\n$ resize2fs /dev/ubuntu-vg/ubuntu-lv\n```\n \n## 安裝 CUDA\nCUDA 的版本其實不用管，詳細安裝文檔可以參考[鏈接](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu-installation).\n \n我已經安裝好最新的 Ubuntu Server LTS 版本，我知道它肯定支援 CUDA。而 GTX 1070 Ti也當然支援 CUDA。那就只有兩個編譯工具需要確認一下\n \n我很懶惰，所以直接一鍵安裝所有編譯工具\n```bash\n$ sudo apt-get install build-essential\n```\n \n然後安裝適合當前內核的 kernel headers 以供安裝 CUDA\n```bash\n$ sudo apt-get install linux-headers-$(uname -r)\n```\n \n如果有自帶的驅動要先卸載，圖形化桌面要暫時關閉\n```bash\nsudo apt-get purge nvidia-cuda*\nsudo apt-get purge nvidia-*\n```\n[參見](https://askubuntu.com/questions/830916/how-to-install-cuda-8-0-on-ubuntu-16-04-with-nvidia-geforce-gtx-1080)\n\n然後去 [CUDA Toolkit Download Page](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=runfilelocal) 下載安裝包，然後跟著網頁上的說明輸入指令。\n \n![Screen capture for downloading installation package](/en/2020/Installing-Pytorch-with-CUDA-on-Ubuntu-18-04/Installing-Pytorch-with-CUDA-on-Ubuntu-18.PNG)\n \n我選擇自動安裝腳本來安裝，中間要輸入同意用戶協議之類的。\n \n## 將項目放到 Docker 容器裏\n這樣更容易管理資源和系統依賴的各種版本，如果全都放在本地系統就容易互相污染。學學如何用 Docker 和 NVIDIA GPU 進行深度學習項目[一鍵傳送](https://github.com/NVIDIA/nvidia-docker#ubuntu-16041804-debian-jessiestretchbuster).\n \n```bash\n$ docker run --gpus all nvidia/cuda:10.0-base nvidia-smi\n```\n \n## 安裝 Pytorch\n你要有 Python 的軟件包管理器 `pip`，沒有就裝\n```bash\n$ sudo apt-get install python3-pip\n```\n然後安裝 Pytorch\n```bash\n$ pip3 install torch torchvision\n```\n如果你的環境和我不一樣，你需要 Pytorch [的官方指令生成器](https://pytorch.org/get-started/locally/)","tags":["NVIDIA","Pytorch","Deep learning","CUDA"]},{"title":"Installing Pytorch with CUDA on Ubuntu 18.04","url":"/en/2020/Installing-Pytorch-with-CUDA-on-Ubuntu-18-04/","content":"\n<!-- # Installing Pytorch with CUDA on Ubuntu 18.04 -->\n## Goal\nFor some reason I need to reinstall operating system and CUDA on a deep learning machine with GTX 1070 Ti. After installed Ubuntu Server 18.04, I was confused with the NVIDIA document, so I write down this notes to keep a reference.\n\nThe procedures are actually very simple, but the document was a bit too detailed or the layout is too complex to find the key points, I was lost in the lines.\n\n## Requirements\n- Ubuntu 16.04 or later\n- NVIDIA GPU(s) that support CUDA\n\n## Tips for LVM\nSince I installed the Ubuntu Server 18.04 with LVM, I soon used up all space. It seems the default space is just fit for the operating system. [Solution to it](https://askubuntu.com/questions/1106795/ubuntu-server-18-04-lvm-out-of-space-with-improper-default-partitioning) is to extend the LVM partition.\n```bash\n$ sudo lvm\nlvm> lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv\nlvm> exit\n$ sudo resize2fs /dev/ubuntu-vg/ubuntu-lv\n```\n\n## Install CUDA\nCUDA version does not really matter. [Detailed Installation guide for your reference](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu-installation).\n\nIt is simple as I have installed the latest Ubuntu Server LTS version and I know it is supports CUDA things, I also sure GTX 1070 Ti supports CUDA. All I need to do now is to install GCC compiler and Linux development packages.\n\nI am so lazy that I just install everything I need to build anything.\n```bash\n$ sudo apt-get install build-essential\n```\n\nThen install the kernel headers and development packages for the currently running kernel.\n```bash\n$ sudo apt-get install linux-headers-$(uname -r)\n```\n\nNow go to [CUDA Toolkit Download Page](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=runfilelocal) download the installation package and follow the guide to install it.\n\n![Screen capture for downloading installation package](/en/2020/Installing-Pytorch-with-CUDA-on-Ubuntu-18-04/Installing-Pytorch-with-CUDA-on-Ubuntu-18.PNG)\n\nI choosed the easiest way to install, use a automated script. Copy the instructions, enter the terminal, press Enter key and wait… Few agreement will require manual input “accept” for EULA before proceed to install the package.\n\n## Use docker for the project\nIt will be a good idea to use Docker for each project. It is easy to set up and run. If you know how to work with Docker, check out the [document](https://github.com/NVIDIA/nvidia-docker#ubuntu-16041804-debian-jessiestretchbuster).\n\n```bash\n$ docker run --gpus all nvidia/cuda:10.0-base nvidia-smi\n```\n\n## Install Pytorch\nMake sure `pip` is available for Python, install it if not.\n```bash\n$ sudo apt-get install python3-pip\n```\nAnd then install Pytorch.\n```bash\n$ pip3 install torch torchvision\n```\nFind the command for your environment from Pytorch [Official document](https://pytorch.org/get-started/locally/)","tags":["NVIDIA","Pytorch","Deep learning","CUDA"]},{"title":"在 Ubuntu 18.04 上安裝 ROCm 3.3.0 和 Pytorch","url":"/zh-TW/2020/在-Ubuntu-18-04-上安裝-ROCm-3.3.0-和-Pytorch/","content":"\n<!-- # 在 Ubuntu 18.04 上安裝 ROCm 3.3.0 和 Pytorch -->\n## 目標\n現在我有一個可以跑 TensorFlow 的 RX 580 了。可是我還是不滿足，於是買了一個 VEGA 56。10.54 TFLOPS 的 FP32 運算能力現在好像也只要 266 美刀。\n\n和之前一樣，在 Ubuntu Server 18.04 上安裝 ROCm 3.3.0 （參見[之前的操作和系統要求](/en/2020/Installing-ROCm-for-Deep-learning-on-Ubuntu-18.04/))。\n \n> RX 580 不能用 Pytorch 了，Pytorch 說它太舊了\n \n我基本上是按照 [ROCm 的官方教學](https://rocm-documentation.readthedocs.io/en/latest/Deep_learning/Deep-learning.html) 不過有些地方可能出問題，這邊提供了指引去避免這些坑。\n \n**你至少要 16 GB 記憶體，不然編譯會很慢而且測試的時候會出錯，我試過了**\n \n## 準備編譯\n### 安裝 Docker\n我們使用 Docker 來編譯，避免污染系統的設置，這樣之後編譯其他版本的時候不會需要卸載和重新安裝。Docker 其實就類似是一個虛擬機，[可以去官網瞭解更多](https://www.docker.com/resources/what-container) 我現在都基本上不用虛擬機，全都用 Docker 了。\n \n[參考官方文檔安裝 Docker ](https://docs.docker.com/engine/install/ubuntu/) 或者你可以學我直接用一鍵安裝的腳本。官方說 **千萬千萬要先自己檢查一下我們的腳本再運行，不然剛好有人惡意黑了我們改了腳本你就糟了**。很貼心的說明。\n \n```bash\n$ curl -fsSL https://get.docker.com -o get-docker.sh\n# 跑下面這句運行它之前，先打開來看看腳本裏面寫了什麼哦~\n$ sudo sh get-docker.sh\n```\n### 安裝 ROCm-Dev 開發軟件包\n編譯 Pytorch 之前要先安裝 `rocm-dev`提供 ROCm 的 API 接口\n```bash\n$ sudo apt-get update\n \n$ sudo apt-get upgrade\n \n$ sudo apt-get install rocm-dev\n```\n## Docker 鏡像和下載代碼\n### 下載編譯環境\n現在我要編譯配合 ROCm 3.3.0 的 Pytorch了。官方文檔認爲你不可能是白癡，沒有告訴你記得檢查 `docker pull rocm/pytorch:rocm3.0_ubuntu16.04_py3.6_pytorch` 這句是不是對應你的 ROCm 版本。到 [DockerHub](https://hub.docker.com/r/rocm/pytorch/tags) 尋找你的 ROCm 版本的標籤來換掉文檔中的 `rocm3.0_ubuntu16.04_py3.6_pytorch`。我的 ROCm 3.3.0 是`rocm3.3_ubuntu16.04_py3.6_pytorch`。\n```bash\n$ sudo docker pull rocm/pytorch:rocm3.3_ubuntu16.04_py3.6_pytorch\n```\n### 下載 Pytorch 源代碼\n我們用 Git 來下載代碼，沒有的話請自行安裝：`sudo apt-get install git`\n```bash\n$ cd ~\n \n$ git clone https://github.com/pytorch/pytorch.git\n```\n然後讓 Git 把其他依賴的代碼一鍵自動下載\n```bash\n$ cd pytorch\n \n$ git submodule init\n \n$ git submodule update\n```\n可是編譯的時候還是報錯，有部分的依賴好像還有自己的依賴，所以要跑 `git submodule update --init --recursive` 而不是 `git submodule update`。用 `--recursive` 將依賴的依賴的依賴的依賴什麼的都統統下載下來。\n```bash\n$ git submodule update --init --recursive\n```\n \n## 編譯！\n先跑一下 `rocminfo` 並且記下你的 GPU 型號（例如我是 gfx 900）\n### 進入編譯環境\n這裏，再一次確認你的鏡像標籤，我的標籤是 `rocm3.3_ubuntu16.04_py3.6_pytorch` 對應 ROCm 3.3.0。你可能是其他版本需要修改再跑。\n\n> 如果你想保留這個編譯的容器而不是完成之後自動移除，你可以移除 **`--rm`** 參數。\n```bash\n$ sudo docker run -it -v $HOME:/data --privileged --rm --device=/dev/kfd --device=/dev/dri --group-add video rocm/pytorch:rocm3.3_ubuntu16.04_py3.6_pytorch\n```\n之後應該會看到一個類似這樣的環境。\n```\nroot@f78375b1c487:/#\n```\n切換到代碼的位置\n```\nroot@f78375b1c487:/# cd /data/pytorch\n```\n### 開始編譯\n你需要先指出你的 GPU 型號。如果你忘記事先用 `rocminfo` 查看的話，可以去[查表](https://llvm.org/docs/AMDGPUUsage.html#processors) 我是 VEGA 56 是 `gfx900`，用這行指令指定。\n```\nroot@f78375b1c487:/# export HCC_AMDGPU_TARGET=gfx900\n```\n\n然後就用這個自動建構的指令\n```\nroot@f78375b1c487:/# .jenkins/pytorch/build.sh\n```\n如果你沒有足夠的記憶體，將會花費你很長時間……\n## 測試\n運行自動測試腳本\n```  \nroot@f78375b1c487:/# PYTORCH_TEST_WITH_ROCM=1 python test/run_test.py --verbose\n```\n然後大概你會出現 `Import Error : no module named torch` 的問題。\n \n那樣的話，你需要確認你的 Python 版本。我的情況是這樣的：\n```\nroot@f78375b1c487:/# python -V\nPython 2.7.18\nroot@f78375b1c487:/# python3 -V\nPython 3.5.8\nroot@f78375b1c487:/# python3.6 -V\nPython 3.6.10\n```\n這個 Pytorch 應該是編譯並且安裝給了 Python 3.6，所以要用 Python 3.6 來測試才對。\n```\nroot@f78375b1c487:/# PYTORCH_TEST_WITH_ROCM=1 python3.6 test/run_test.py --verbose\n```\n### 出錯？\n如果沒有 16 GB RAM 就會出現 `malloc` 無法賦予位置的錯誤\n \n### Install torchvision\n試試安裝 torchvision，應該是在編譯過程中已經一起安裝了的。\n```\nroot@f78375b1c487:/# pip install torchvision\n```\n### 保存這個 Docker 容器\n用容器 ID 來保存它，ID 一直都在上面有顯示，例如我的就是 `f78375b1c487`\n```bash\n$ sudo docker commit f78375b1c487 -m 'pytorch installed'\n```\n如果退出這個容器的話就什麼也沒有了（前面執行 `docker run` 的時候使用的 `--rm` 參數發揮效用），所以需要在另一個指令行裡執行 `commit`。你可以另外開一個命令行（Terminal）窗口，或者用 `Ctrl`+`Alt`+`F3` 進入另一個黑底白字的命令行介面，或者如果你是和我一樣在用 `tmux`，就 `Ctrl`+`B` 然後再輸入 `C` 再開一個窗口來執行 `commit`。\n \n## DONE\n[學學如何用 Docker 吧](https://github.com/twtrubiks/docker-tutorial)，它與你來日方長。\n\nPytorch time! (>w<)b","tags":["Pytorch","Deep learning","AMD","ROCm"]},{"title":"在 Ubuntu 18.04 上安裝 ROCm 3.3.0 和 TensorFlow","url":"/zh-TW/2020/在-Ubuntu-18-04-上安裝-ROCm-3.3.0-和-TensorFlow/","content":"\n<!-- # 在 Ubuntu 18.04 上安裝 ROCm 3.3.0 和 TensorFlow -->\n## 目標\n我一直覺得 AMD 出的幾張織女星顯卡很是吸引。 [VEGA 56](https://www.techpowerup.com/gpu-specs/radeon-rx-vega-56.c2993) ，[VEGA 64](https://www.techpowerup.com/gpu-specs/radeon-rx-vega-64.c2871) 都是很強勁的計算裝置，和 [NVIDIA 2080 Ti](https://www.techpowerup.com/gpu-specs/geforce-rtx-2080-ti.c3305) 不相上下。 [Radeon VII](https://www.techpowerup.com/gpu-specs/radeon-vii.c3358) 更是讓我流口水，13.44 TFLOPS FP32 (float) 運算能力（理論值）而且只有 2080 Ti 的一半價錢。\n\n爲了嘗試 AMD 的表現，和依賴庫的穩定性，我買了一張 RX 580 來玩，只花了我100美刀。[AMD Radeon RX 580](https://www.techpowerup.com/gpu-specs/radeon-rx-580.c2938) 感覺性價比很高，有 6 TFLOPS 的運算能力。\n\nNVIDIA 的 GPU 就用 CUDA 來跑，那 AMD 怎麼安裝 CUDA 呢？不怕，我們有 ROCm 來替代 CUDA。\n \n## 前提\n對於使用性價比超高的 AMD GPU 來跑模型我已經迫不及待了，不過原來 ROCm 有很多要求，不是隨便哪個舊電腦就可以跑的。\n- 要有比較新的 CPU 支援 PCIe Gen3 和 PCIe Atomics 操作的才行\n- 底板要支援 PCIe 3.0\n- GPU 也要比較新的才行，AMD 說太舊的顯卡性能太差懶得支援了\n- 更新你的 Linux 系統到內核版本 kernel 4.17 以上（如果你用 Windows 就不行了）\n \n### 支援的 CPU 型號\n- AMD Ryzen CPUs\n- The CPUs in AMD Ryzen APUs\n- AMD Ryzen Threadripper CPUs\n- AMD EPYC CPUs\n- Intel Xeon E7 v3 或以上\n- Intel Xeon E5 v3 或以上\n- Intel Xeon E3 v3 或以上\n- Intel Core i7 v4 或以上 （i.e. 要 Haswell 或更新的架構）\n- Intel Core i5 v4 或以上\n- Intel Core i3 v4 或以上\n- 某些 Ivy Bridge-E systems\n \n[原文鏈接](https://github.com/RadeonOpenCompute/ROCm#supported-cpus)\n\n我也不知道 \"某些 Ivy Bridge-E systems\" 是哪些，有需要的話請前往[提問](https://github.com/RadeonOpenCompute/ROCm/issues)。他們說有限度支援某些舊 CPU 和 GPU，不過最好就不要自尋短見了，除非你想幫忙搞底層代碼來支援那些硬件。\n \n### 支援的 GPU 型號\n- GFX8 GPUs\n  - \"Fiji\" 晶片，例如 AMD Radeon R9 Fury X 和 Radeon Instinct MI8\n  - \"Polaris 10\" 晶片，例如 AMD Radeon RX 580 和 Radeon Instinct MI6\n- GFX9 GPUs\n  - \"Vega 10\" 晶片，例如 AMD Radeon RX Vega 64 和 Radeon Instinct MI25\n  - \"Vega 7nm\" 晶片，例如 Radeon Instinct MI50, Radeon Instinct MI60 和 AMD Radeon VII\n \n參考 [原文](https://github.com/RadeonOpenCompute/ROCm#supported-gpus). 有些 GFX8 和 GFX7 系列的 GPU 碰巧可以支援，不過如果出問題的話，也沒人可以幫你解決了。順帶一提我的 RX 580 後來發現 Pytorch 不支援了，嫌棄我的 GPU 舊。.\n \n## 安裝 ROCm\n### 我的配置\n- i5-4570 CPU\n- RX 580 GPU\n- Ubuntu Server 18.04.\n \n[官方的教學](https://rocm-documentation.readthedocs.io/en/latest/Installation_Guide/Installation-Guide.html#ubuntu) 可以直接用，除非你想用 Pytorch，那可能有幾個不起眼的地方官方忘記提醒你要注意。可以汲取我的[教訓](/zh-TW/2020/在-Ubuntu-18-04-上安裝-CUDA-和-Pytorch/)避免再入坑。\n \n### 前期準備\n> 如果你安裝 Pytorch 就要記一下你選的 ROCm 版本，我裝 ROCm 3.3.0。\n \n先更新系統，然後安裝 `libnuma-dev` 然後重啓\n```bash\n$ sudo apt update\n \n$ sudo apt dist-upgrade\n \n$ sudo apt install libnuma-dev\n \n$ sudo reboot\n```\n### 安裝 ROCm\n將 ROCm 的下載位置加入到系統的軟件包管理當中\n```bash\n$ wget -q -O - http://repo.radeon.com/rocm/apt/debian/rocm.gpg.key | sudo apt-key add -\n \n$ echo 'deb [arch=amd64] http://repo.radeon.com/rocm/apt/debian/ xenial main' | sudo te\n```\n然後用系統的軟件包管理自動安裝\n```bash\n$ sudo apt update\n \n$ sudo apt install rocm-dkms\n```\n \n### 安裝善後\n記得幫你自己的用戶加入 GPU 的操作權限\n```bash\n$ sudo usermod -a -G video $LOGNAME\n```\n如果你要考慮再加其他用戶就請去複製[官方文檔的指令](https://rocm-documentation.readthedocs.io/en/latest/Installation_Guide/Installation-Guide.html#ubuntu)\n \n然後重啓系統\n```bash\n$ sudo reboot\n```\n \n### 測試安裝及啓用\n測試 ROCm 的安裝\n```bash\n$ /opt/rocm/bin/rocminfo\n$ /opt/rocm/opencl/bin/x86_64/clinfo\n```\n你應該會看到一些類似報告表格的東西，那就說明安裝成功了。\n \n接下來將 ROCm 植入系統的環境 PATH 當中讓其他程序可以找得到它\n```bash\n$ echo 'export PATH=$PATH:/opt/rocm/bin:/opt/rocm/profiler/bin:/opt/rocm/opencl/bin/x86_64' |\n> sudo tee -a /etc/profile.d/rocm.sh\n```\n \n## 安裝 TensorFlow\n這個很簡單，只有兩步，不過現在好像默認安裝 2.0 以上最新版本，如果你要安裝其他版本要自己指定版本，不會的話去問問谷歌`pip安裝如何指定版本`。[參考原文說明書](https://rocm-documentation.readthedocs.io/en/latest/Deep_learning/Deep-learning.html)\n```bash\n$ sudo apt update\n \n$ sudo apt install rocm-libs miopen-hip cxlactivitylogger rccl\n \n$ sudo apt install wget python3-pip\n \n$ pip3 install --user tensorflow-rocm\n```\n \n現在 TensorFlow 2 應該是已經成功安裝了！可喜可賀 (^\\_^)b","tags":["Deep learning","AMD","ROCm","TensorFlow"]},{"title":"Installing Pytorch with ROCm 3.3.0 on Ubuntu 18.04","url":"/en/2020/Installing-Pytorch-with-ROCm-3.3.0-on-Ubuntu-18.04/","content":"\n<!-- # Installing Pytorch with ROCm on Ubuntu 18.04 -->\n## Goal\nI have my RX 580 ready for TensorFlow, I tried to install Pytorch but it say my GPU is too old and they do not support now. I brought a VEGA 56 with 10.54 TFLOPS for FP32 from newegg.com at price 266 USD. Let's install Pytorch on top of ROCm 3.3.0.\n\nFirst of all, install ROCm 3.3.0 (refer to [previous tutorial](/en/2020/Installing-ROCm-for-Deep-learning-on-Ubuntu-18.04/)), requirements are the same.\n\nWe follow the instructions from [ROCm](https://rocm-documentation.readthedocs.io/en/latest/Deep_learning/Deep-learning.html) first, and I will add solution to problem I encountered.\n\n**You will need to have 16 GB RAM or more to finish the whole compile, install and test process.**\n\n## Install dependencies\n### Install Docker\nYou will need Docker to finish the installation. Docker is similar to virtual machine simulate a operating system environment isolate from your computer but Docker is much lighter and faster, [learn more from their docuements](https://www.docker.com/resources/what-container).\n\nInstall [Docker with instructions from Docker official document](https://docs.docker.com/engine/install/ubuntu/) or you can use their convenience script. **And examine scripts downloaded from the internet before running them locally.** Make sure no one added a line to install a trojan into your computer.\n\n```bash\n$ curl -fsSL https://get.docker.com -o get-docker.sh\n\n$ sudo sh get-docker.sh\n```\n### Install ROCm-Dev package\nWe are going to compile Pytorch from source, it requires `rocm-dev` package.\n```bash\n$ sudo apt-get update\n\n$ sudo apt-get upgrade\n\n$ sudo apt-get install rocm-dev\n```\n## Step Two\n### Prepare environment for compiling\nNow we get the compilation environment for ROCm 3.3.0. The official document is not up-to-date which tells you to run `docker pull rocm/pytorch:rocm3.0_ubuntu16.04_py3.6_pytorch`. You should go to [their DockerHub](https://hub.docker.com/r/rocm/pytorch/tags) and make sure the tag `rocm3.0_ubuntu16.04_py3.6_pytorch` is what you need. For ROCm 3.3.0 I need `rocm3.3_ubuntu16.04_py3.6_pytorch` so I run:\n```bash\n$ sudo docker pull rocm/pytorch:rocm3.3_ubuntu16.04_py3.6_pytorch\n```\n### Prepare source code for compiling\nNow clone the source code of Pytorch with Git, do `sudo apt-get install git` if you don't have git.\n```bash\n$ cd ~\n\n$ git clone https://github.com/pytorch/pytorch.git\n```\nAnd then clone the other required source code automatically.\n```bash\n$ cd pytorch\n\n$ git submodule init\n\n$ git submodule update\n```\nI would suggest you to run `git submodule update --init --recursive` instead of `git submodule update` as some of the required source code may have their own required repository which needs to download with `--recursive` flag.\n```bash\n$ git submodule update --init --recursive\n```\n\n## Compile and Install\n### Enter environment for compiling\nMake sure the tag is correct before you run this command, my tag was `rocm3.3_ubuntu16.04_py3.6_pytorch` for ROCm 3.3.0. Official document forgot to remind you that the tag really matters.\n```bash\n$ sudo docker run -it -v $HOME:/data --privileged --rm --device=/dev/kfd --device=/dev/dri --group-add video rocm/pytorch:rocm3.3_ubuntu16.04_py3.6_pytorch\n```\nAnd you will get something look another terminal:\n```\nroot@f78375b1c487:/#\n```\nNow we change to the mounted source code directory:\n```\nroot@f78375b1c487:/# cd /data/pytorch\n```\n### We now start building\nExport the right code for GPU. You can check the code by running `rocminfo` on your host (out side the docker) from another terminal. Or you can find it [here](https://llvm.org/docs/AMDGPUUsage.html#processors) `Ctrl`+`F` search your GPU. `gfx900` for VEGA 56.\n```\nroot@f78375b1c487:/# export HCC_AMDGPU_TARGET=gfx900\n```\n### Start compiling\nAn automated script is provided, just run the following command will build and install everything to the docker container.\n```\nroot@f78375b1c487:/# .jenkins/pytorch/build.sh\n```\n## Test\nBefore we finish everything, we need to run a test.\n\nYou may run the script for test...\n``` \nroot@f78375b1c487:/# PYTORCH_TEST_WITH_ROCM=1 python test/run_test.py --verbose\n```\nAnd it may say `Import Error : no module named torch`. No worry, it is easy to fix.\n\nCheck your Python version\n```\nroot@f78375b1c487:/# python -V\nPython 2.7.18\nroot@f78375b1c487:/# python3 -V\nPython 3.5.8\nroot@f78375b1c487:/# python3.6 -V\nPython 3.6.10\n```\nSince the Pytorch was compiled and installed for Python 3.6, you need to use Python 3.6 for running the test.\n```\nroot@f78375b1c487:/# PYTORCH_TEST_WITH_ROCM=1 python3.6 test/run_test.py --verbose\n```\n### Error?\nIf you do not have 16 GB RAM, it will use up all the memeory and `malloc` will raise error for unable to allocate memory.\n\nIf you try to run the test with RX 580, Pytorch will tell you the GPU is too old and their do not support now.\n## Finishing\n### Install torchvision\nTry to install it and you suppose to see it already installed with your compilation and installation of Pytorch.\n```\nroot@f78375b1c487:/# pip install torchvision\n```\n### Save the container\nUse the container ID to save it into image so you can use it for different project and prevent environment contamination of different dependencies. The container ID is the hash showing in your terminal for container, `f78375b1c487` for mine.\n```bash\n$ sudo docker commit f78375b1c487 -m 'pytorch installed'\n```\nChange `f78375b1c487` to your container ID.\n\nThe docker container will be automatically removed after quit the environment. Therefore you will need to commit the container with another terminal. If you are using Command Line Interface, use `Ctrl`+`Alt`+`F3` (Usually `F7` is the Graphic Desktop, on Fedora it is `F2`) to switch to another terminal. I used `tmux` so I `Ctrl`+`B` and then press `%` create a new terminal on screen. And commit the container.\n\n## DONE\nPytorch time! (>w<)b\n\nAnd I think you may need a [tutorial for Docker](https://docker-curriculum.com/) to get on.","tags":["Pytorch","Deep learning","AMD","ROCm"]},{"title":"Installing ROCm 3.3.0 for Deep learning on Ubuntu 18.04","url":"/en/2020/Installing-ROCm-3.3.0-for-Deep-learning-on-Ubuntu-18.04/","content":"\n<!-- # Installing ROCm for Deep learning on Ubuntu 18.04 -->\n## Goal\nWe all know AMD [VEGA 56](https://www.techpowerup.com/gpu-specs/radeon-rx-vega-56.c2993) and [VEGA 64](https://www.techpowerup.com/gpu-specs/radeon-rx-vega-64.c2871) are powerful GPUs competitive to [NVIDIA RTX 2080 Ti](https://www.techpowerup.com/gpu-specs/geforce-rtx-2080-ti.c3305), the [Radeon VII](https://www.techpowerup.com/gpu-specs/radeon-vii.c3358) is even more powerful with 13.44 TFLOPS FP32 (float) performance (Theoretical) with a lower price at 699 USD.\n\nI was thinking about having a Deep Learning machine, and I looked at the price for NVIDIA 2080 Ti, it is around 1548 USD here. So I made a call to my friend who sells 2nd hand electronic stuff and get a [AMD Radeon RX 580](https://www.techpowerup.com/gpu-specs/radeon-rx-580.c2938) with around 100 USD. RX 580 is a cost-effective card to get 6 TFLOPS performance.\n\nBut, how to fit it with TensorFlow or Pytorch? CUDA does not agree with AMD GPUs. No worries, I have found ROCm for AMD GPUs to replace CUDA.\n\n## Requirements\nIt is so excited to run TensorFlow on AMD GPU. But here are some important notes:\n- Only new CPUs are supported as it requires PCIe Gen3 and PCIe Atomics\n- Only new GPUs are supported because old GPUs are too poor in performance\n- Use Linux with kernel 4.17 or above (Or you will have a hard time with it)\n\n### Supported CPUs\n- AMD Ryzen CPUs\n- The CPUs in AMD Ryzen APUs\n- AMD Ryzen Threadripper CPUs\n- AMD EPYC CPUs\n- Intel Xeon E7 v3 or newer CPUs\n- Intel Xeon E5 v3 or newer CPUs\n- Intel Xeon E3 v3 or newer CPUs\n- Intel Core i7 v4, Core i5 v4, Core i3 v4 or newer CPUs (i.e. Haswell family or newer)\n- Some Ivy Bridge-E systems\n\nRefer to [GitHub of ROCm CPU section](https://github.com/RadeonOpenCompute/ROCm#supported-cpus). What are those \"Some Ivy Bridge-E systems\"? I don't know too. You may Email them for support on that. You may see some older CPUs are limited supported, but I would suggest you don't waste your time on that unless you want to contribute in ROCm to make it support older CPUs. It will make your life harder.\n\n### Supported GPUs\n- GFX8 GPUs\n  - \"Fiji\" chips, such as on the AMD Radeon R9 Fury X and Radeon Instinct MI8\n  - \"Polaris 10\" chips, such as on the AMD Radeon RX 580 and Radeon Instinct MI6\n- GFX9 GPUs\n  - \"Vega 10\" chips, such as on the AMD Radeon RX Vega 64 and Radeon Instinct MI25\n  - \"Vega 7nm\" chips, such as on the Radeon Instinct MI50, Radeon Instinct MI60 or AMD Radeon VII\n\nRefer to [GitHub of ROCm GPU section](https://github.com/RadeonOpenCompute/ROCm#supported-gpus). Few GFX8 and GFX7 GPUs are supported unofficially (if you got problem, no help, no guarantee).\n\n## Install ROCm\n### Things I got\nI got a i5-4570 for CPU (another 2nd hand computer with 140 USD) and RX 580 for GPU and installed Ubuntu Server 18.04.\n\nThe [official tutorial](https://rocm-documentation.readthedocs.io/en/latest/Installation_Guide/Installation-Guide.html#ubuntu) will be just fine for installnig ROCm and TensorFlow. But you will encounter problem in Pytorch (which is the reason I write this tutorial, I gave up on the first time, and this time I find [solution](/en/2020/Installing-Pytorch-with-ROCm-on-Ubuntu-18.04/)).\n\n### Install dependencies\n> Note the ROCm version you install, I am installing ROCm 3.3.0  This information will be useful for Pytorch installation.\n\nUpdate system, install `libnuma-dev` and reboot:\n```bash\n$ sudo apt update\n\n$ sudo apt dist-upgrade\n\n$ sudo apt install libnuma-dev\n\n$ sudo reboot\n```\n### Install ROCm\nAdd the ROCm apt repository.\n```bash\n$ wget -q -O - http://repo.radeon.com/rocm/apt/debian/rocm.gpg.key | sudo apt-key add -\n\n$ echo 'deb [arch=amd64] http://repo.radeon.com/rocm/apt/debian/ xenial main' | sudo te\n```\nInstall ROCm\n```bash\n$ sudo apt update\n\n$ sudo apt install rocm-dkms\n```\n\n### Post installation\nGrant yourself permission for accessing your GPU\n```bash\n$ sudo usermod -a -G video $LOGNAME\n```\nIf you need to add more users, check the [document](https://rocm-documentation.readthedocs.io/en/latest/Installation_Guide/Installation-Guide.html#ubuntu)\n\nReboot\n```bash\n$ sudo reboot\n```\n\n### Test and Cofnigure\nTest the ROCm installation.\n```bash\n$ /opt/rocm/bin/rocminfo\n$ /opt/rocm/opencl/bin/x86_64/clinfo\n```\nYou should see something like report.\n\nAdd ROCm to environment PATH:\n```bash\n$ echo 'export PATH=$PATH:/opt/rocm/bin:/opt/rocm/profiler/bin:/opt/rocm/opencl/bin/x86_64' |\n> sudo tee -a /etc/profile.d/rocm.sh\n```\n\n## Install TensorFlow\nThis is simple with two steps, get some important libraries and install TensorFlow through `pip`. Refer to [ROCm Doc](https://rocm-documentation.readthedocs.io/en/latest/Deep_learning/Deep-learning.html)\n```bash\n$ sudo apt update\n\n$ sudo apt install rocm-libs miopen-hip cxlactivitylogger rccl\n\n$ sudo apt install wget python3-pip\n\n$ pip3 install --user tensorflow-rocm\n```\n\nIt now installed TensorFlow 2 (latest), you need to specify version if you need just like installing other packages in Python.\n\n## DONE\nTensorFlow time~ (^_^)b","tags":["Deep learning","AMD","ROCm","TensorFlow"]},{"title":"Raspberry Pi 化身 WiFi 蛋","url":"/zh-TW/2020/Raspberry-Pi-化身-WiFi-蛋/","content":"\n<!-- # Raspberry Pi 化身 WiFi 蛋 -->\n## 前文\n我們已經改造 [Raspberry Pi 使用 4G 數據網路](/zh-TW/2020/Raspberry-Pi-使用-4G-數據網路/)\n\n## 目標\n這次我們要讓 Raspberry Pi 將網絡分享給其他裝置，你可以選：\n- [製成**無線**路由器](#無線路由器)\n- [製成路由器（有線）](#有線路由器)\n\n## 無線路由器\n因為博主很懶惰，不想重複造輪子，所以無線路由器的教材就直接引用 [Sixfab 的教學](https://sixfab.com/using-sixfab-raspberry-p-shield-hat-as-a-wi-fi-hotspot-access-point/)\n\n如果你用的是早於 Raspberry Pi 3 的版本，你大概需要一個 USB 無線網路卡。\n\n### 備份無線網絡配置\n這並不是必須的步驟，不過萬一你日後想恢復原樣，這一步會很有幫助。\n\n```bash\n$ sudo cp /etc/wpa_supplicant/wpa_supplicant.conf /etc/wpa_supplicant/wpa_supplicant.backup.conf\n```\n\n### 配置無線網絡裝置\n用以下指令清除舊配置\n```bash\n$ sudo cp /dev/null /etc/wpa_supplicant/wpa_supplicant.conf\n```\n將以下的新配置寫入到 `/etc/wpa_supplicant/wpa_supplicant.conf`\n```\nctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev\nupdate_config=1\n```\n\n### 安裝 RaspAP\n有一個簡單的安裝精靈 [RaspAP](https://github.com/billz/raspap-webgui) 跟著它的步驟去進行安裝\n```bash\n$ wget -q https://git.io/voEUQ -O /tmp/raspap && bash /tmp/raspap -y\n```\n不過由於我本人並沒有試過這個方法，所以如果有任何疑問（例如默認的密碼、管理員界面等）還請前往 [Sixfab 的教學](https://sixfab.com/using-sixfab-raspberry-p-shield-hat-as-a-wi-fi-hotspot-access-point/) 和[原文教學（包含故障排除章節）](https://howtoraspberrypi.com/create-a-wi-fi-hotspot-in-less-than-10-minutes-with-pi-raspberry/)\n\n## 有線路由器\n我自己是用的這個方法，因為感覺會比較安心，始終有線的網絡感覺會比較穩定。這一部分就要使用網絡位址轉換技術（Network Address Translation，NAT）來連接 `ppp0` 和 `eth0` 兩個網絡界面（網卡）\n\n我是參考[將無線網絡分享到網線教程](https://raspberrypi.stackexchange.com/questions/48307/sharing-the-pis-wifi-connection-through-the-ethernet-port)然後將它改成將 PPP 網絡分享到網線\n\n### DHCP 和 DNS 伺服器\n你可以選自己喜歡的諸如 `isc-dhcp-server` 之類比較複雜的，這邊直接用 `dnsmasq` 比較方便\n```bash\n$ sudo apt-get install dnsmasq\n```\n### 設置數據包轉發\n編輯 `/etc/sysctl.conf` 裡的 `#net.ipv4.ip_forwarding=1` \n```bash\n$ sudo nano /etc/sysctl.conf\n```\n移除`#`，將這行文字變成`net.ipv4.ip_forwarding=1`。這樣下次開機的時候就會啟用數據包轉發。\n### 設置網絡界面\n編輯 `/etc/network/interfaces` 裡的 `eth0` 部分\n```\nallow-hotplug eth0  \niface eth0 inet static  \n    address 192.168.2.1\n    netmask 255.255.255.0\n    network 192.168.2.0\n    broadcast 192.168.2.255\n```\n### 設置 dnsmasq\n先備份一下 dnsmasq 原本的設置\n```bash\n$ sudo mv /etc/dnsmasq.conf /etc/dnsmasq.conf.orig  \n```\n然後編輯 `/etc/dnsmasq.conf`\n```\ninterface=eth0      # 分享到 eth0  \nlisten-address=192.168.2.1 # 和/etc/network/interfaces配置的 IP 要一致  \n# Bind to the interface to make sure we aren't sending things elsewhere\n#### bind-interfaces #### BUT don't enable this.\nserver=8.8.8.8       # Forward DNS requests to Google DNS  \ndomain-needed        # Don't forward short names  \n# Never forward addresses in the non-routed address spaces.\nbogus-priv\n# Assign IP addresses between 192.168.2.2 and 192.168.2.100 with a\n# 12 hour lease time\ndhcp-range=192.168.2.2,192.168.2.100,12h \n```\n> 關於 **`bind-interfaces`** 部分，原本的教學是啟用的，不過我這邊啟用的話會無法分享網絡，所以這邊用`#`註釋掉了\n\n### 設置 NAT\n通過防火牆來設置 NAT\n```bash\n$ sudo iptables -t nat -A POSTROUTING -o wwan0 -j MASQUERADE  \n$ sudo iptables -A FORWARD -i wwan0 -o eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT  \n$ sudo iptables -A FORWARD -i eth0 -o wwan0 -j ACCEPT\n```\n#### 設置為永久 NAT\n保存設置\n```bash\n$ sudo sh -c \"iptables-save > /etc/iptables.ipv4.nat\"\n```\n修改 `/etc/rc.local` 開機自動載入 NAT 設置\n```\n# Add this line above exit 0\niptables-restore < /etc/iptables.ipv4.nat\n```\n## 完成\n將手提電腦連上 Raspberry Pi 然後……可以了\n```bash\n$ ping 8.8.8.8\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n64 bytes from 8.8.8.8: icmp_seq=2 ttl=51 time=99.2 ms\n64 bytes from 8.8.8.8: icmp_seq=1 ttl=51 time=22.9 ms\n64 bytes from 8.8.8.8: icmp_seq=3 ttl=51 time=69.7 ms\n```\n","tags":["Raspberry Pi","WWAN","4G","NAT","Router"]},{"title":"Video based Motion Detection in Python with OpenCV","url":"/en/2020/Video-based-Motion-Detection-in-Python-with-OpenCV/","content":"\n<!-- # Video based Motion Detection in Python with OpenCV -->\n## Demo\n<div class=\"video-container\">\n\t<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/4cB2BpSVxBY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</div>\n\nI added 30 seconds buffer before start recording so we can see the green color indicates the detected movements.\n\n## What you need\n- A Webcam\n- Python and pip\n\n### Requirements.txt\n```\nopencv-python\nnumpy\n```\n## Goal\nTo implement a security camera auto record videos when some thing moves in the view port.\n\n### Source code\nThe [original implementation](https://github.com/RobinDavid/Motion-detection-OpenCV) was in Python 2.x with OpenCV 3.x\n\nI fork it to Python 3.x and make it compatible with OpenCV 4.x\n\n> The **`MotionDetectorContours.py`** and **`MotionDetector.py`** results the same in the original implementation. But they give different result in my implementation, I guess it is because I skiped **`cv.Erode()`** in **`MotionDetectorContours.py`**.\n\n## The original implementation\nThere are two implementation according to the developer.\n\n### Simple way\n1. Receive frames and send to process in `run()`\n2. `processImage()` calculate difference of **pixels** in frames\n3. If number of different pixels exceed the threshold, `somethingHasMoved()` return `True`\n4. `run()` enable recording if `somethingHasMoved()` return `True`\n\n### Smart way\n1. Receive frames and send to process in `run()`\n2. `processImage()` calculate difference of **areas** in frames with `cv2.findContours()`\n3. If change of area in comparing to total area exceed the threshold, `somethingHasMoved()` return `True`\n4. `run()` enable recording if `somethingHasMoved()` return `True`\n\n## Our implementation\nOur implementation will be based on `MotionDetectorContours.py`. It did better job for me and it can catch my eye blinking.\n\nImport OpenCV for image processing, Numpy for replacing `cv2.CreateImage()`, datetime and tmie for showing video recording time.\n```python\nimport cv2 as cv\nimport numpy as np\nfrom datetime import datetime\nimport time\n```\nDefine a class for image processing and maintain the loop of reading frames.\n```python\nclass MotionDetectorAdaptative():\n  def onChange(self, val): #callback when the user change the detection threshold\n    pass\n\n  def __init__(self,threshold=25, doRecord=True, showWindows=True):\n    pass\n\n  def initRecorder(self): #Create the recorder\n    pass\n\n  def run(self):\n    pass\n\n  def processImage(self, curframe):\n    pass\n\n  def somethingHasMoved(self):\n    pass\n```\nThe initializatoin:\n```python\n  def __init__(self,threshold=25, doRecord=True, showWindows=True):\n    self.writer = None\n    self.font = None\n    self.doRecord=doRecord #Either or not record the moving object\n    self.show = showWindows #Either or not show the 2 windows\n    self.frame = None\n\n    self.capture=cv.VideoCapture(0)\n    self.frame = self.capture.read()[1] #Take a frame to init recorder\n    if doRecord:\n      self.initRecorder()\n\n    self.absdiff_frame = None\n    self.previous_frame = None\n\n    self.surface = self.frame.shape[0] * self.frame.shape[1]\n    self.currentsurface = 0\n    self.currentcontours = None\n    self.threshold = threshold\n    self.isRecording = False\n    self.trigger_time = 0 #Hold timestamp of the last detection\n    self.es = cv.getStructuringElement(cv.MORPH_ELLIPSE, (9,4))\n\n    if showWindows:\n      cv.namedWindow(\"Image\")\n      # for user to change threshold in runtime\n      cv.createTrackbar(\"Detection treshold: \", \"Image\", self.threshold, 100, self.onChange)\n\n```\n`run()` will maintain the loop to:\n1. read frame\n2. pass to `processImage()`\n3. check if anything moved in `somethingHasMoved()`, `isRecording = True` if things moved\n4. if `isRecording == True` a video recorder will be activated\n5. draw area of moved/changed to frame and display it on screen\n6. repeat the steps if `Esc` was not pressed\n\n```python\n  def run(self):\n    started = time.time()\n    while True:\n\n      currentframe = self.capture.read()[1]\n      instant = time.time() #Get timestamp o the frame\n\n      self.processImage(currentframe) #Process the image\n\n      if not self.isRecording:\n        if self.somethingHasMoved():\n          self.trigger_time = instant #Update the trigger_time\n          if instant > started +10:#Wait 5 second after the webcam start for luminosity adjusting etc..\n            print(\"Something is moving !\")\n            if self.doRecord: #set isRecording=True only if we record a video\n              self.isRecording = True\n        currentframe = cv.drawContours(currentframe, self.currentcontours, -1, (0, 255, 0), cv.FILLED)\n      else:\n        if instant >= self.trigger_time +10: #Record during 10 seconds\n          print(\"Stop recording\")\n          self.isRecording = False\n        else:\n          cv.putText(currentframe,datetime.now().strftime(\"%b %d, %H:%M:%S\"), (25,30),self.font, 1, (255, 0, 0), 2, cv.LINE_AA) #Put date on the frame\n          self.writer.write(currentframe) #Write the frame\n\n      if self.show:\n        cv.imshow(\"Image\", currentframe)\n\n      c=cv.waitKey(1) % 0x100\n      if c==27 or c == 10: #Break if user enters 'Esc'.\n        break\n```\nFind the change between frames and do simple feature extraction, result saved to `self.gray_frame`.\n```python\n  def processImage(self, curframe):\n      curframe = cv.GaussianBlur(curframe, (21,21), 0) #Remove false positives\n\n      if self.absdiff_frame is None: #For the first time put values in difference, temp and moving_average\n        self.absdiff_frame = curframe.copy()\n        self.previous_frame = curframe.copy()\n        self.average_frame = np.float32(curframe) #Should convert because after runningavg take 32F pictures\n      else:\n        cv.accumulateWeighted(curframe, self.average_frame, 0.05) #Compute the average\n\n      self.previous_frame = self.average_frame.astype(np.uint8) #Convert back to 8U frame\n\n      self.absdiff_frame = cv.absdiff(curframe, self.previous_frame) # moving_average - curframe\n\n      self.gray_frame = cv.cvtColor(self.absdiff_frame, cv.COLOR_BGR2GRAY) #Convert to gray otherwise can't do threshold\n      self.gray_frame = cv.threshold(self.gray_frame, 5, 255, cv.THRESH_BINARY)[1]\n\n      self.gray_frame = cv.dilate(self.gray_frame, self.es) #to get object blobs\n      # cv.Erode(self.gray_frame, self.gray_frame, None, 10)\n```\nFind the area of changes and compare to threshold over the whole area:\n```python\n  def somethingHasMoved(self):\n\n    # Find contours, ignore other return values (image, contours, hierarchy)[1]\n    contours = cv.findContours(self.gray_frame, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)[1]\n\n    self.currentcontours = contours #Save contours\n\n    self.currentsurface = sum([cv.contourArea(c) for c in contours]) #For all contours compute the area\n\n    avg = (self.currentsurface*100)/self.surface #Calculate the average of contour area on the total size\n    self.currentsurface = 0 #Put back the current surface to 0\n\n    if avg > self.threshold:\n      return True\n    else:\n      return False\n```\nIf user change threshold during runtime, `onChange()` method in the class will be triggered:\n```python\n  def onChange(self, val): #callback when the user change the detection threshold\n    self.threshold = val\n```\nDeclare a video recorder writes frame to video file:\n```python\n  def initRecorder(self): #Create the recorder\n    codec = cv.VideoWriter_fourcc('M', 'J', 'P', 'G')\n    self.writer=cv.VideoWriter(datetime.now().strftime(\"%b-%d_%H_%M_%S\")+\".wmv\", codec, 5, self.frame.shape[1::-1], 1)\n    #FPS set to 5 because it seems to be the fps of my cam but should be ajusted to your needs\n    self.font = cv.FONT_HERSHEY_SIMPLEX #Creates a font\n```\nLet's try it.\n```python\nif __name__==\"__main__\":\n  detect = MotionDetectorAdaptative(threshold=5, doRecord=True)\n  detect.run()\n```\n\n## Improvements\nThere is a problem the video only record for 10 seconds. Base on [MotionDetectorContours.py](https://github.com/NewJerseyStyle/Motion-detection-OpenCV/blob/master/MotionDetectorContours.py) modify its condition to end recording:\n```python\n        if instant >= self.trigger_time +10 and not self.somethingHasMoved(): #Record until move stop 10 seconds\n```\n\nWe can add an Email notification in this. You may refer to the tutorial sending [Email notification for network usage report](/en/2020/Network-usage-monitor-using-Python/). And we can then combine it with Raspberry Pi to build a security camera.\n\nYou will need these things for a Raspberry Pi security camera:\n- [Raspberry Pi](https://www.raspberrypi.org/products/raspberry-pi-4-model-b/)\n- [Raspberry Pi Camera Module V2](https://www.raspberrypi.org/products/camera-module-v2/)\n- [32 GB MicroSD Card](https://www.amazon.co.jp/10%E5%AF%BE%E5%BF%9C%E3%80%91Samsung-microSD%E3%82%AB%E3%83%BC%E3%83%8932GB-Nintendo-MB-MC32GA-ECO/dp/B06XSV23T1/ref=psdc_171386011_t3_B00J84T6HW)\n\n> If you ask, I used a [wide angle camera](https://www.amazon.co.jp/dp/B07VFFRX4C/ref=sspa_dk_detail_1?psc=1&pd_rd_i=B07VFFRX4C&pd_rd_w=uSbWD&pf_rd_p=6413bd85-d494-49e7-9f81-0e63e79171a9&pd_rd_wg=KjEEj&pf_rd_r=79C32JCV4SJVAGQEC7R6&pd_rd_r=0a132dab-0895-4d9f-aa14-439b4d6d1eeb&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUEzNk1ZN1I1UkI3RDM4JmVuY3J5cHRlZElkPUEwODcxNjM4M0RGT1ZERlg4Nlo2UCZlbmNyeXB0ZWRBZElkPUEySU9FRjk0M1ZBWFQ1JndpZGdldE5hbWU9c3BfZGV0YWlsJmFjdGlvbj1jbGlja1JlZGlyZWN0JmRvTm90TG9nQ2xpY2s9dHJ1ZQ==)\n\nSixfab has a tutorial about [Raspberry Pi Security System with Sixfab 3G, 4G/LTE Base Shield](https://sixfab.com/tutorial-7-raspberry-pi-security-system-with-sixfab-3glte-shields/). It seem to use a motion sensor to detect moment in the area and activate camera when sensor detect movement, it then send a frame to a email specified in the Python script.\n\nI didn't find the hardware list of their design, but the [Python source code is here](https://raw.githubusercontent.com/sixfab/Sixfab_RPi_3G-4G-LTE_Base_Shield/master/tutorials/tutorial7/SecuritySystem.py).\n\nI think using a motion sensor is a good idea, [Docker Pi Series of Sensor Hub](https://www.instructables.com/id/Docker-Pi-Series-of-Sensor-Hub-Board-About-IOT/) seem to be a good option, considering to have it in my production environment.","tags":["Python3","Coding","OpenCV"]},{"title":"Raspberry Pi 使用 4G 數據網路","url":"/zh-TW/2020/Raspberry-Pi-使用-4G-數據網路/","content":"\n<!-- # Raspberry Pi connect to 4G LTE -->\n## 購物清單\n- [Raspberry Pi](https://www.raspberrypi.org/products/)\n- SD Card with [Linux installed](https://projects.raspberrypi.org/en/projects/raspberry-pi-setting-up)\n- [Raspberry Pi 3G/4G-LTE Base HAT](https://sixfab.com/product/raspberry-pi-base-hat-3g-4g-lte-minipcie-cards/)\n- [Quectel EC25 Mini PCle 4G/LTE Module](https://sixfab.com/product/quectel-ec25-mini-pcle-4glte-module/)\n- [LTE Main & Diversity & GNSS Triple Port u.FL Antenna ](https://sixfab.com/product/lte-main-diversity-gnss-triple-port-u-fl-antenna-100mm/)\n\n> 不想分開購買零件，可以[購買 Sixfab 的 Raspberry Pi 4G/LTE套件](https://sixfab.com/product/raspberry-pi-4g-lte-modem-kit/)\n\n## 組裝\n1. 安裝 Mini PCIe 4G IoT Module 到 3G/4G-LTE Base HAT，感覺和以前在手提電腦上安裝記憶體差不多。\n\n2. 然後將 3G/4G-LTE Base HAT 裝上 Raspberry Pi。\n![Installed onto Pi](https://sixfab-com.exactdn.com/wp-content/uploads/2019/09/Base_HAT_with_EC25A.jpg?strip=all&lossy=0&ssl=1 \" After assembly Raspberry Pi @sixfab \")<center>*完成之後大概這樣的感覺（圖片來源：[@sixfab](https://sixfab.com/product/raspberry-pi-base-hat-3g-4g-lte-minipcie-cards/)）*</center>\n\n3. 將天線也安裝上去，正確地完成安裝之後的樣子大概這樣\n![Connect Antenna](https://www.torbox.ch/wp-content/uploads/2019/12/IMG_5237-e1576357032325.jpg \" Complete assembly @https://www.torbox.ch/?p=1165 \")<center>*加上天線應該這樣個樣子吧（圖片來源：[@torbox.ch](https://www.torbox.ch/?p=1165)）*</center>\n\n最左邊和最右邊的兩個天線似乎是可以互換的，我安裝完成之後那些線是平行的。\n\n## 安裝驅動\nSixfab 提供了兩種方法驅動 LTE 模組，一個是 [PPP](https://sixfab.com/ppp-installer-for-sixfab-shield/) 一個是 [QMI interface](https://sixfab.com/qmi-interface-with-3g-4g-lte-base-shield-v2/)。這邊我用的是 PPP。\n\n在 Raspberry Pi 的終端模擬器裡進行操作，下載 sixfab 的安裝腳本，然後跟著指引進行安裝就可以了。簡單方便快捷，感謝sixfab。\n```bash\n$ wget https://raw.githubusercontent.com/sixfab/Sixfab_PPP_Installer/master/ppp_installer/install.sh\n\n$ chmod +x install.sh\n\n$ sudo ./install.sh \n```\n\n### 有些選項可能比較曖昧，給個避坑指南\n- Choose your Sixfab\n  - 因為買的是 `3G, 4G/LTE Base Shield` 所以只填 `2`\n  - 就算之後連不上也肯定不是這裡填錯\n- APN\n  - 問問谷歌、雅虎或者百度你這家電信商的基地台用什麼存取點名稱（APN），選一個填，不對之後再改\n  - 將你的 SIM 卡插入智能電話，看看設定裡行動網絡設定關於存取點名稱裡有什麼選項，選一個填，不對之後再改\n  - 之後修改的方法參見出坑指南\n- PORT name\n  - 因為買的是 `3G, 4G/LTE Base Shield` 所以只填 `ttyUSB3`\n  - 肯定是 `ttyUSB3`，跟實際上你硬件上插哪個 USB 位置好像沒關係，可能是用的 GPIO？\n\n## 沒能避開坑？出坑指南\n### 我需要登入才能上網\n如果你需要用戶名和密碼登入才能上網，完成前面的安裝和設定之後再編輯 `/etc/ppp/peers/provider` 檔案。\n\n你要移除這一行\n```\nnoauth\n```\n然後按照以下格式填入登錄資料\n```\nuser \"YOUR USERNAME\"\npassword \"YOURPASSWORD\"\n```\n### 遇到 Routing error 的錯誤\n執行以下指令\n```bash\n$ sudo route del default\n\n$ sudo route add default ppp0\n```\n### 沒有網絡連接\n誰也 ping 不到，網絡不通，或者無盡的連接超時\n```bash\n$ ping 8.8.8.8\nconnect: network is unreachable \n$ ping baidu.com\nconnect: network is unreachable \n````\n> 檢查你的移動數據是否需要先在手機上啟用\n\n試試手動連接移動數據\n```bash\n$ sudo pon\n```\n你可能發現 Modem hang up 並且不論你做什麼都沒有什麼效果。\n\n我已經坑過幾次了，基本上問題就是 APN 填錯了，或者舊的 APN 已經不能用了。於是我將 SIM 插入手機，看手機自動連上網絡的時候用的哪個 APN 再修改 `/etc/ppp/peers/provider` 文件\n```bash\n$ sudo poff\n$ sudo nano /etc/ppp/peers/provider\n```\nAPN 在我 `/etc/ppp/peers/provider` 文件裡第三行的結尾。\n\n逐一測試你所能找到的 APN，看看 `sudo pon` 能不能連上，應該其中一個能連上。至少我是成功了。\n## DONE\n```bash\n$ ping 8.8.8.8\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n64 bytes from 8.8.8.8: icmp_seq=1 ttl=52 time=20.9 ms\n64 bytes from 8.8.8.8: icmp_seq=2 ttl=52 time=111 ms\n64 bytes from 8.8.8.8: icmp_seq=3 ttl=52 time=69.7 ms\n```\n","tags":["Raspberry Pi","WWAN","4G","LTE"]},{"title":"Network usage monitor using Python","url":"/en/2020/Network-usage-monitor-using-Python/","content":"\n<!-- # Network usage monitor using Python -->\n## Previous\nWe have [built a 4G/LTE router](/en/2020/Raspberry-Pi-as-4G-LTE-Router/) but how do I know its network usage? How much will it cost me?\n\n## Goal\nWe are now going to write a Python script to send Email notificatoin for network usage and set a threshold for it.\n\n> I assume you know the basic pattern how to code in Python\n\n## Requirements.txt\n```\npsutil\npython_http_client\nsendgrid\n```\n\nYou can install them by typing in terminal:\n```bash\n$ pip3 install psutil python_http_client sendgrid\n```\n\n> You may need to specify **`pip3`** in Raspbian as both Python 2.x and Python 3.x were installed.\n\n## Coding Python\n```bash\n$ mkdir network-monitor\n$ cd network-monitor\n$ nano monitor.py\n```\nAnd then we start coding\n### Get network usage\n```python\nimport psutil\n\nNETWORK_INTERFACE = 'ppp0'\n\nnetio = psutil.net_io_counters(pernic=True)\nnet_usage = netio[NETWORK_INTERFACE].bytes_sent + netio[NETWORK_INTERFACE].bytes_recv\n\nprint(net_usage, \"bytes\")\n```\nIt will show you how many bytes it has transfered for upload and download.\n> If it shows zero, change **`NETWORK_INTERFACE`** to **`wwan0`**.\n### Set threshold\n```python\nimport psutil\n\nNETWORK_INTERFACE = 'wwan0'\nNETWORK_LIMIT = 5000000 # 5GB in SI standard\n\nwhile True:\n  netio = psutil.net_io_counters(pernic=True)\n  net_usage = netio[NETWORK_INTERFACE].bytes_sent + netio[NETWORK_INTERFACE].bytes_recv\n\n  if net_usage > NETWORK_LIMIT:\n    print(\"Meets network limit!\")\n\n    print(net_usage, \"bytes has been used\")\n```\nOnce it over the `NETWORK_LIMIT` it will print a lot of lines of \"Meets network limit!\". We can add a timer to check the network limit every X second.\n### Separate the config and code\nTry to separate the cnofiguratoin and the Python script so we can reuse this project on other devices.\n\n`configparser` is really a good helper on this.\n\nCreate a file `monitor.conf`\n```\n[Email]\nSENDGRID_API_KEY = Your.Keyfrom_SendGrid\nfrom = helper@raspberry.pi\nto = your@email.address\nsubject = From your Raspberry Pi\n\n[Network]\nINTERFACE = wwan0\nLIMIT = 45000000000\n\n[Misc]\nTIME_INTER = 36\n```\n\nNow we can load the configuration in Python\n```python\nimport time\nimport psutil\nimport configparser\nconfig = configparser.ConfigParser()\nconfig.optionxform = str  #reference: http://docs.python.org/library/configparser.html\nconfig.read('monitor.conf')\n\nNETWORK_INTERFACE = config.get('Network', 'INTERFACE')\t\t# Define interface to check\nNETWORK_LIMIT = int(config.get('Network', 'LIMIT'))\t\t\t# Define network limit\nSENDGRID_API_KEY = config.get('Email', 'SENDGRID_API_KEY')\t# Define the API key for SendGrid\nTIME_INTER = config.get('Misc', 'TIME_INTER')\t\t\t\t# Define time interval 36 seconds\n\nwhile True:\n  time.sleep(TIME_INTER) # Check every 36 seconds\n  netio = psutil.net_io_counters(pernic=True)\n  net_usage = netio[NETWORK_INTERFACE].bytes_sent + netio[NETWORK_INTERFACE].bytes_recv\n\n  if net_usage > NETWORK_LIMIT:\n    print(\"Meets network limit!\")\n\n    print(net_usage, \"bytes has been used\")\n```\n\n### Prepare for the Email\nWe use SendGrid to send the Email notification in this tutorial.\n\n> You may need to sign up on SendGrid. I choose it because of 100 free email quota every day.\n\n#### Generate SendGrid API Key\nThe option is in **Setting -> API Keys -> Create API Key** [Creating an API key](https://sendgrid.com/docs/ui/account-and-settings/api-keys/#creating-an-api-key)\n\n#### Copy the Key and paste to monitor.conf\n```\n[Email]\nSENDGRID_API_KEY = Your.Keyfrom_SendGrid\n```\n\n### Write python script\nRefer to their official guide [SendGrid GitHub repo](https://github.com/sendgrid/sendgrid-python)\n```python\nimport time\nimport psutil\nimport sendgrid\nfrom sendgrid.helpers.mail import *\n```\nRead the `monitor.conf`\n```python\nimport configparser\nconfig = configparser.ConfigParser()\nconfig.optionxform = str  #reference: http://docs.python.org/library/configparser.html\nconfig.read('netio-mon.conf')\n\nNETWORK_INTERFACE = config.get('Network', 'INTERFACE')\nNETWORK_LIMIT = int(config.get('Network', 'LIMIT'))\nNETWORK_MAX = int(config.get('Network', 'MAX'))\nSENDGRID_API_KEY = config.get('Email', 'SENDGRID_API_KEY')\nTIME_INTER = config.get('Misc', 'TIME_INTER')\n```\nI would like to have some loggings too so I added this line\n```python\nimport logging\n\nloggingFile = logging.FileHandler('my.log', 'w', 'utf-8')\n\nlogging.basicConfig(level=logging.DEBUG,\n        format='%(asctime)s %(levelname)s %(message)s',\n        datefmt='%Y-%m-%d %H:%M',\n        handlers=[loggingFile, ])\n```\nDeclare two methods for sending Email\n```python\ndef create_message(sender, to, subject, message_text):\n  logging.info(\"send email::\" + message_text)\n  from_email = Email(sender)\n  to_email = To(to)\n  subject = subject\n  content = Content(\"text/plain\", message_text)\n  return Mail(from_email, to_email, subject, content)\n\n\ndef send_message(service, message):\n  return service.client.mail.send.post(request_body=message.get())\n```\nNow the mean loop to check the network usage periodically.\n```python\n# Initialize the SendGrid API\nservice = sendgrid.SendGridAPIClient(api_key=SENDGRID_API_KEY)\n\n# A flag to make sure only send one notification\nhave_sent = False\n\nwhile True:\n  time.sleep(TIME_INTER)\n  netio = psutil.net_io_counters(pernic=True)\n  net_usage = netio[NETWORK_INTERFACE].bytes_sent + netio[NETWORK_INTERFACE].bytes_recv\n  if net_usage > NETWORK_LIMIT and not have_sent:\n    message = create_message(\n      config.get('Email', 'from'),\n      config.get('Email', 'to'),\n      config.get('Email', 'subject'),\n      'The network have used %s bytes' %net_usage)\n    send_message(service, message)\n    have_sent = True\n```\n## Improvement\n- Prevent network usage lost, save the usage in the last email with `pickle`\n- In order to monitoring network usage continuously, set one more `NETWORK_MAX` for reseting the flag after first email notification\nSee my [GitHub Repo](https://github.com/NewJerseyStyle/network-monitor)\n","tags":["Raspberry Pi","Python3","Monitoring","Email","Coding"]},{"title":"Raspberry Pi connect to 4G LTE","url":"/en/2020/Raspberry-Pi-connect-to-4G-LTE/","content":"\n<!-- # Raspberry Pi connect to 4G LTE -->\n## What you need\n- [Raspberry Pi](https://www.raspberrypi.org/products/)\n- SD Card with [Linux installed](https://projects.raspberrypi.org/en/projects/raspberry-pi-setting-up) (NOOBS I used here)\n- [Raspberry Pi 3G/4G-LTE Base HAT](https://sixfab.com/product/raspberry-pi-base-hat-3g-4g-lte-minipcie-cards/)\n- [Quectel EC25 Mini PCle 4G/LTE Module](https://sixfab.com/product/quectel-ec25-mini-pcle-4glte-module/)\n- [LTE Main & Diversity & GNSS Triple Port u.FL Antenna ](https://sixfab.com/product/lte-main-diversity-gnss-triple-port-u-fl-antenna-100mm/)\n\n> Alternative option: [Raspberry Pi 4G/LTE HAT Kit from Sixfab](https://sixfab.com/product/raspberry-pi-4g-lte-modem-kit/)\n\n## Assembly\n1. Install Mini PCIe 4G IoT Module on Raspberry Pi 3G/4G-LTE Base HAT, it is similar to installing RAM modules in laptop.\n\n2. Install Raspberry Pi 3G/4G-LTE Base HAT on Raspberry, it is simple.\n![Installed onto Pi](https://sixfab-com.exactdn.com/wp-content/uploads/2019/09/Base_HAT_with_EC25A.jpg?strip=all&lossy=0&ssl=1 \" After assembly Raspberry Pi @sixfab \")<center>*After assembly Raspberry Pi [@sixfab](https://sixfab.com/product/raspberry-pi-base-hat-3g-4g-lte-minipcie-cards/)*</center>\n\n3. Connect the Antenna to the Raspberry Pi 3G/4G-LTE Base HAT, the wire should be parallel if you connect them to right port.\n![Connect Antenna](https://www.torbox.ch/wp-content/uploads/2019/12/IMG_5237-e1576357032325.jpg \" Complete assembly @https://www.torbox.ch/?p=1165 \")<center>*Complete assembly [@torbox.ch](https://www.torbox.ch/?p=1165)*</center>\n\nThe function of two outermost cable seem to be identical, all Antenna cables are parallel in my assembly and it works well.\n\n## Driver\nSixfab provides two methods to control the LTE module, [PPP](https://sixfab.com/ppp-installer-for-sixfab-shield/) and [QMI interface](https://sixfab.com/qmi-interface-with-3g-4g-lte-base-shield-v2/).\n\nI used PPP connection here.\n\n```bash\n$ wget https://raw.githubusercontent.com/sixfab/Sixfab_PPP_Installer/master/ppp_installer/install.sh\n\n$ chmod +x install.sh\n\n$ sudo ./install.sh \n```\n\n### Few options confused me and here are tips:\n- Choose your Sixfab\n  - Always `2` for the `3G, 4G/LTE Base Shield` (Compatible with `6` option for `Raspberry Pi 3G/4G&LTE Base HAT`)\n- APN\n  - Google the APN for the service provider\n  - Or insert the SIM Card to a phone and view the APN in settings\n- PORT name\n  - For 3G, 4G/LTE Base Shield && Base HAT it will be `ttyUSB3`\n  - Always `ttyUSB3`, no thing to do with physical port\n\n## Troubleshooting\n### Need auth option in setup\nIf your service provider need username/password to use the network, edit `/etc/ppp/peers/provider` later to add your username and password.\nRemove line\n```\nnoauth\n```\nAnd add two lines\n```\nuser \"YOUR USERNAME\"\npassword \"YOURPASSWORD\"\n```\n### Routing error\nIn this case, run the following commands\n```bash\n$ sudo route del default\n\n$ sudo route add default ppp0\n```\n### No network\nTry manually connect to cellular network:\n```bash\n$ sudo pon\n```\nModem hang up and you tried all solution, nothing work and do not know why\n\nI have encountered few time on this problem, it hang up while connecting to network.\nBecause of incorrect APN, try all APN you can find on network and in your phone’s setting. To change the APN, edit `/etc/ppp/peers/provider`\n```bash\n$ sudo poff\n$ sudo nano /etc/ppp/peers/provider\n```\nThe APN is on the end of the 3rd line in my `/etc/ppp/peers/provider`.\n\nTry every APN you can find for the service provider try connect with `sudo pon` and one of them should work.\n## DONE\n```bash\n$ ping 8.8.8.8\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n64 bytes from 8.8.8.8: icmp_seq=1 ttl=52 time=20.9 ms\n64 bytes from 8.8.8.8: icmp_seq=2 ttl=52 time=111 ms\n64 bytes from 8.8.8.8: icmp_seq=3 ttl=52 time=69.7 ms\n```\n","tags":["Raspberry Pi","WWAN","4G","LTE"]},{"title":"Raspberry Pi as 4G LTE Router","url":"/en/2020/Raspberry-Pi-as-4G-LTE-Router/","content":"\n<!-- # Raspberry Pi as 4G LTE Router -->\n## Previous\nWe have [established connection to 4G LTE network](/en/2020/Raspberry-Pi-connect-to-4G-LTE/)\n\n## Goal\nWe are going to turn the Raspberry Pi into a Router for our devices, pick your need:\n- [Goto Wireless router section](#Wireless-Router)\n- [Goto Wired router section](#Wired-Router)\n\n## Wireless Router\nInstead of reinventing the wheel, we follow the guide [Sixfab tutorial](https://sixfab.com/using-sixfab-raspberry-p-shield-hat-as-a-wi-fi-hotspot-access-point/)\n\nIf you are using Raspberry Pi 2 or earlier, you will need a USB WiFi adaptor.\n\n### Backup wireless configurations\nNot a must but you may want to do this, in case later you changed your mind.\n\n```bash\n$ sudo cp /etc/wpa_supplicant/wpa_supplicant.conf /etc/wpa_supplicant/wpa_supplicant.backup.conf\n```\n\n### Configure wireless device\nClear the configuration file\n```bash\n$ sudo cp /dev/null /etc/wpa_supplicant/wpa_supplicant.conf\n```\nAdd configurations into `/etc/wpa_supplicant/wpa_supplicant.conf`:\n```\nctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev\nupdate_config=1\n```\n\n### Install RaspAP\nUse a quick installer of [RaspAP](https://github.com/billz/raspap-webgui) and follow the questions to setup the wireless network\n```bash\n$ wget -q https://git.io/voEUQ -O /tmp/raspap && bash /tmp/raspap -y\n```\nI did not tested this, so any problem or question (default password etc.), please refer to the [Sixfab tutorial](https://sixfab.com/using-sixfab-raspberry-p-shield-hat-as-a-wi-fi-hotspot-access-point/) and the toubleshooting in the [original tutorial](https://howtoraspberrypi.com/create-a-wi-fi-hotspot-in-less-than-10-minutes-with-pi-raspberry/)\n\n## Wired Router\nWe are going to use network address translation (NAT) to bridge `ppp0` with `eth0`\n\nThis tutorial was adopting [sharing wifi through the ethernet](https://raspberrypi.stackexchange.com/questions/48307/sharing-the-pis-wifi-connection-through-the-ethernet-port) and change it to share PPP connection to ethernet\n\n### DHCP and DNS server\nI used `dnsmasq` for DHCP + DNS.\n```bash\n$ sudo apt-get install dnsmasq\n```\n### Configurate interfaces\nEdit the `eth0` section in file `/etc/network/interfaces`:\n```\nallow-hotplug eth0  \niface eth0 inet static  \n    address 192.168.2.1\n    netmask 255.255.255.0\n    network 192.168.2.0\n    broadcast 192.168.2.255\n```\n### Configure forwarding\nEdit `/etc/sysctl.conf` to enable packet forwarding.\n```bash\n$ sudo nano /etc/sysctl.conf\n```\nFind the line `#net.ipv4.ip_forwarding=1` and remove the `#` at the beginning to make it `net.ipv4.ip_forwarding=1`. This will enable packet forwarding once the system reboot.\n### Configure dnsmasq\nBackup dnsmasq configuration\n```bash\n$ sudo mv /etc/dnsmasq.conf /etc/dnsmasq.conf.orig  \n```\nEdit `/etc/dnsmasq.conf`\n```\ninterface=eth0      # Use interface eth0  \nlisten-address=192.168.2.1 # listen on  \n# Bind to the interface to make sure we aren't sending things elsewhere  \n#### bind-interfaces #### BUT don't enable this.\nserver=8.8.8.8       # Forward DNS requests to Google DNS  \ndomain-needed        # Don't forward short names  \n# Never forward addresses in the non-routed address spaces.\nbogus-priv\n# Assign IP addresses between 192.168.2.2 and 192.168.2.100 with a\n# 12 hour lease time\ndhcp-range=192.168.2.2,192.168.2.100,12h \n```\n> Enable **`bind-interfaces`** cause me unable to share the internet. You may need to test it.\n\n### NAT configuration\n```bash\n$ sudo iptables -t nat -A POSTROUTING -o wwan0 -j MASQUERADE  \n$ sudo iptables -A FORWARD -i wwan0 -o eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT  \n$ sudo iptables -A FORWARD -i eth0 -o wwan0 -j ACCEPT\n```\nMake the rules persistent.\n```bash\n$ sudo sh -c \"iptables-save > /etc/iptables.ipv4.nat\"\n```\nEdit `/etc/rc.local`\n```\n# Add this line above exit 0\niptables-restore < /etc/iptables.ipv4.nat\n```\n## DONE\nConnect my laptop to Raspberry Pi \n```bash\n$ ping 8.8.8.8\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n64 bytes from 8.8.8.8: icmp_seq=2 ttl=51 time=99.2 ms\n64 bytes from 8.8.8.8: icmp_seq=1 ttl=51 time=22.9 ms\n64 bytes from 8.8.8.8: icmp_seq=3 ttl=51 time=69.7 ms\n```\n","tags":["Raspberry Pi","WWAN","4G","NAT","Router"]},{"title":"Hello World","url":"/en/2020/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"}]