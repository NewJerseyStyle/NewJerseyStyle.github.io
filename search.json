[{"title":"Installing Pytorch with ROCm 3.3.0 on Ubuntu 18.04","url":"/en/2020/Installing-Pytorch-with-ROCm-3.3.0-on-Ubuntu-18.04/","content":"\n<!-- # Installing Pytorch with ROCm on Ubuntu 18.04 -->\n## Goal\nNow I have got my RX 580 ready for TensorFlow, and I brought a VEGA 56 with 10.54 TFLOPS for FP32 from newegg.com at price 266 USD. Let's install Pytorch this time? Well, there will be few problem you may encounter like I did during installation of Pytorch on top of ROCm 3.3.0. Watch me how to fix them.\n\nFirst of all, install ROCm 3.3.0 (refer to [previous tutorial](/en/2020/Installing-ROCm-for-Deep-learning-on-Ubuntu-18.04/)), requirements are the same.\n\n## Install Pytorch\nWe follow the instructions from [ROCm](https://rocm-documentation.readthedocs.io/en/latest/Deep_learning/Deep-learning.html) first, and I will add solution to problem I encountered.\n\n**You will need to have 16 GB RAM or more to finish the whole compile, install and test process.**\n\n## Step One\n### Install Docker\nYou will need Docker to finish the installation. Docker is similar to virtual machine simulate a operating system environment isolate from your computer but Docker is much lighter and faster, [learn more from their docuements](https://www.docker.com/resources/what-container).\n\nInstall [Docker with instructions from Docker official document](https://docs.docker.com/engine/install/ubuntu/) or you can use their convenience script. **And examine scripts downloaded from the internet before running them locally.** Make sure no one added a line to install a trojan into your computer.\n\n```bash\n$ curl -fsSL https://get.docker.com -o get-docker.sh\n\n$ sudo sh get-docker.sh\n```\n### Install ROCm-Dev package\nWe are going to compile Pytorch from source, it requires `rocm-dev` package.\n```bash\n$ sudo apt-get update\n\n$ sudo apt-get upgrade\n\n$ sudo apt-get install rocm-dev\n```\n## Step Two\n### Prepare environment for compiling\nNow we get the compilation environment for ROCm 3.3.0. The official document is not up-to-date which tells you to run `docker pull rocm/pytorch:rocm3.0_ubuntu16.04_py3.6_pytorch`. You should go to [their DockerHub](https://hub.docker.com/r/rocm/pytorch/tags) and make sure the tag `rocm3.0_ubuntu16.04_py3.6_pytorch` is what you need. For ROCm 3.3.0 I need `rocm3.3_ubuntu16.04_py3.6_pytorch` so I run:\n```bash\n$ sudo docker pull rocm/pytorch:rocm3.3_ubuntu16.04_py3.6_pytorch\n```\n### Prepare source code for compiling\nNow clone the source code of Pytorch with Git, do `sudo apt-get install git` if you don't have git.\n```bash\n$ cd ~\n\n$ git clone https://github.com/pytorch/pytorch.git\n```\nAnd then clone the other required source code automatically.\n```bash\n$ cd pytorch\n\n$ git submodule init\n\n$ git submodule update\n```\nI would suggest you to run `git submodule update --init --recursive` instead of `git submodule update` as some of the required source code may have their own required repository which needs to download with `--recursive` flag.\n```bash\n$ git submodule update --init --recursive\n```\n\n## Step Three\n### Enter environment for compiling\nJust run this:\n```bash\n$ sudo docker run -it -v $HOME:/data --privileged --rm --device=/dev/kfd --device=/dev/dri --group-add video rocm/pytorch:rocm3.0_ubuntu16.04_py3.6_pytorch\n```\nAnd you will get something look another terminal:\n```\nroot@f78375b1c487:/#\n```\nNow we change to the mounted source code directory:\n```\nroot@f78375b1c487:/# cd /data/pytorch\n```\n### We now start building\nHowever you may encounter some problems. Here was my solution in 20 Apr 2020. I hope the problems have already been fixed while you read this, but in case it isn't...\n#### Patch 1\nDepends on your GPU, export the right code for it. You can check the code by running `rocminfo` on your host (out side the docker) on another terminal. Or you can find it [here](https://llvm.org/docs/AMDGPUUsage.html#processors) Ctrl-F search your GPU. `gfx803` for RX 580 and `gfx900` for VEGA 56.\n```\nroot@f78375b1c487:/# export HCC_AMDGPU_TARGET=gfx900\n```\n#### Patch 2\nCheck you have `hip_version.h` in the path `${ROCM_DIR}/include/hip/hip_version.h`, add such a file if it does not exist. Otherwise compilation may fail at `78%`.\n```\nroot@f78375b1c487:/# nano ${ROCM_DIR}/include/hip/hip_version.h\n```\nIt sould look like this.\n```c++\n#ifndef HIP_VERSION\n#define HIP_VERSION 330\n#endif\n```\n`330` here means ROCm 3.3.0, change it to `300` for ROCm 3.0.0, depends on your ROCm version.\nIn case you need to add it:\n```\nroot@f78375b1c487:/# mkdir -p ${ROCM_DIR}/include/hip/\n\nroot@f78375b1c487:/# nano ${ROCM_DIR}/include/hip/hip_version.h\n```\n#### Patch 3\nMake sure packages such as `rccl` have installed in the docker container, otherwise compiler will not be able to find the libaray and fail the compilation at around `79%`.\n```\nroot@f78375b1c487:/# apt install rocm-libs miopen-hip rccl\n```\n### Start compiling\nA automated script is provided, just run the following command will build and install everything to the docker container.\n```\nroot@f78375b1c487:/# .jenkins/pytorch/build.sh\n```\nYou may take a break and had tea time or go hiking, It takes more than one hour on my i5-4570.\n## Step Four\nBefore we finish everything, we need to run a test.\n### Test\nYou may run script for testing...\n``` \nroot@f78375b1c487:/# PYTORCH_TEST_WITH_ROCM=1 python test/run_test.py --verbose\n```\nAnd it may say `Import Error : no module named torch` no worry, let's fix it.\n### Patch 1\nIn order to pass the test, you will need Ninja, the container does not contain Ninja while I was running it on 19 Apr 2020, so I need to install it myself (The strange thing is, Ninja should be used in compiling to speed up everything. Cannot see why it is not installed before running testing.).\n```\nroot@f78375b1c487:/# apt-get install -y ninja-build\n```\n### Patch 2\nCheck your Python version\n```\nroot@f78375b1c487:/# python -V\nPython 2.7.18\nroot@f78375b1c487:/# python3 -V\nPython 3.5.8\nroot@f78375b1c487:/# python3.6 -V\nPython 3.6.10\n```\nSince the Pytorch was compiled and installed for Python 3.6, you need to use Python 3.6 for running the test.\n```\nroot@f78375b1c487:/# PYTORCH_TEST_WITH_ROCM=1 python3.6 test/run_test.py --verbose\n```\n### Patch 3\nIf you do not have 16 GB RAM, it will use up all the memeory and `malloc` will raise error for unable to allocate memory.\n## Step Five\n### Install torchvision\nTry to install it and you suppose to see it already installed with your compilation and installation of Pytorch.\n```\nroot@f78375b1c487:/# pip install torchvision\n```\n### Save the container\nExit your container with Ctrl-D and use the container ID to save it into image so you can use it for different project and prevent environment contamination of different dependencies. The container ID is the hash showing in your terminal for container, `f78375b1c487` for mine.\n```bash\n$ sudo docker commit f78375b1c487 -m 'pytorch installed'\n```\nChange `f78375b1c487` to your container ID.\n\n## DONE\nPytorch time! (>w<)b","tags":["AMD","Pytorch","Deep learning","ROCm"]},{"title":"Installing ROCm 3.3.0 for Deep learning on Ubuntu 18.04","url":"/en/2020/Installing-ROCm-3.3.0-for-Deep-learning-on-Ubuntu-18.04/","content":"\n<!-- # Installing ROCm for Deep learning on Ubuntu 18.04 -->\n## Goal\nWe all know AMD [VEGA 56](https://www.techpowerup.com/gpu-specs/radeon-rx-vega-56.c2993) and [VEGA 64](https://www.techpowerup.com/gpu-specs/radeon-rx-vega-64.c2871) are powerful GPUs are competitive to [NVIDIA 2080 Ti](https://www.techpowerup.com/gpu-specs/geforce-rtx-2080-ti.c3305), the [Radeon VII](https://www.techpowerup.com/gpu-specs/radeon-vii.c3358) is even more powerful with 13.44 TFLOPS FP32 (float) performance (Theoretical) and price at 699 USD.\n\nI was thinking about having a Deep Learning machine, and I looked at the price for NVIDIA 2080 Ti, it is around 1548 USD here. So I made a call to my friend who sells 2nd hand electronic stuff and get a [AMD Radeon RX 580](https://www.techpowerup.com/gpu-specs/radeon-rx-580.c2938) with around 100 USD. RX 580 is a cost-effective card to get 6 TFLOPS performance.\n\nBut, how to fit it with TensorFlow or Pytorch? CUDA does not agree with AMD GPUs. But no worries, I have found ROCm for AMD GPUs to replace CUDA.\n\n## Requirements\nIt is so excited to run TensorFlow on AMD GPU. But here are some important notes:\n- Only new CPUs are supported as it requires PCIe Gen3 and PCIe Atomics\n- Only new GPUs are supported because old GPUs are too poor in performance\n- Use Linux with kernel 4.17 or above (Or you will have a hard time with it)\n\n### Supported CPUs\n- AMD Ryzen CPUs\n- The CPUs in AMD Ryzen APUs\n- AMD Ryzen Threadripper CPUs\n- AMD EPYC CPUs\n- Intel Xeon E7 v3 or newer CPUs\n- Intel Xeon E5 v3 or newer CPUs\n- Intel Xeon E3 v3 or newer CPUs\n- Intel Core i7 v4, Core i5 v4, Core i3 v4 or newer CPUs (i.e. Haswell family or newer)\n- Some Ivy Bridge-E systems\n\nRefer to [GitHub of ROCm CPU section](https://github.com/RadeonOpenCompute/ROCm#supported-cpus). What are those \"Some Ivy Bridge-E systems\"? I don't know too. You may Email them for support on that. You may see some older CPUs are limited supported, but I would suggest you don't waste your time on that unless you want to contribute in ROCm to make it support older CPUs. It will make your life harder.\n\n### Supported GPUs\n- GFX8 GPUs\n  - \"Fiji\" chips, such as on the AMD Radeon R9 Fury X and Radeon Instinct MI8\n  - \"Polaris 10\" chips, such as on the AMD Radeon RX 580 and Radeon Instinct MI6\n- GFX9 GPUs\n  - \"Vega 10\" chips, such as on the AMD Radeon RX Vega 64 and Radeon Instinct MI25\n  - \"Vega 7nm\" chips, such as on the Radeon Instinct MI50, Radeon Instinct MI60 or AMD Radeon VII\n\nRefer to [GitHub of ROCm GPU section](https://github.com/RadeonOpenCompute/ROCm#supported-gpus). Few GFX8 and GFX7 GPUs are supported unofficially (if you got problem, no help, no guarantee).\n\n## Install ROCm\n### Things I got\nI got a i5-4570 for CPU (another 2nd hand computer with 140 USD) and RX 580 for GPU and installed Ubuntu Server 18.04.\n\nThe [official tutorial](https://rocm-documentation.readthedocs.io/en/latest/Installation_Guide/Installation-Guide.html#ubuntu) will be just fine for installnig ROCm and TensorFlow. But you will encounter problem in Pytorch (which is the reason I write this tutorial, I gave up on the first time, and this time I find [solution](/en/2020/Installing-Pytorch-with-ROCm-on-Ubuntu-18.04/)).\n\n### Step one\n> Note the ROCm version you install, I am installing ROCm 3.3.0  This information will be useful during Pytorch installation.\n\nUpdate system, install `libnuma-dev` and reboot:\n```bash\n$ sudo apt update\n\n$ sudo apt dist-upgrade\n\n$ sudo apt install libnuma-dev\n\n$ sudo reboot\n```\n### Step two\nAdd the ROCm apt repository.\n```bash\n$ wget -q -O - http://repo.radeon.com/rocm/apt/debian/rocm.gpg.key | sudo apt-key add -\n\n$ echo 'deb [arch=amd64] http://repo.radeon.com/rocm/apt/debian/ xenial main' | sudo te\n```\nInstall ROCm\n```bash\n$ sudo apt update\n\n$ sudo apt install rocm-dkms\n```\n\n### Step three\nGrant yourself permission for accessing your GPU\n```bash\n$ sudo usermod -a -G video $LOGNAME\n```\nIf you need to add more users, check the [document](https://rocm-documentation.readthedocs.io/en/latest/Installation_Guide/Installation-Guide.html#ubuntu)\n\nReboot\n```bash\n$ sudo reboot\n```\n\n### Step four\nTest the ROCm installation.\n```bash\n$ /opt/rocm/bin/rocminfo\n$ /opt/rocm/opencl/bin/x86_64/clinfo\n```\nYou should see something like report.\n\nAdd ROCm to environment PATH:\n```bash\n$ echo 'export PATH=$PATH:/opt/rocm/bin:/opt/rocm/profiler/bin:/opt/rocm/opencl/bin/x86_64' |\n> sudo tee -a /etc/profile.d/rocm.sh\n```\n\n## Install TensorFlow\nThis is simple with two steps, get some important libraries and install TensorFlow through `pip`. Refer to [ROCm Doc](https://rocm-documentation.readthedocs.io/en/latest/Deep_learning/Deep-learning.html)\n```bash\n$ sudo apt update\n\n$ sudo apt install rocm-libs miopen-hip cxlactivitylogger rccl\n\n$ sudo apt install wget python3-pip\n\n$ pip3 install --user tensorflow-rocm\n```\n\nIt now installed TensorFlow 2 (latest), you need to specify version if you need just like installing other packages in Python.\n\n## DONE\nTensorFlow time~ (^_^)b","tags":["AMD","Deep learning","ROCm","TensorFlow"]},{"title":"Raspberry Pi 化身 WiFi 蛋","url":"/zh-TW/2020/Raspberry-Pi-化身-WiFi-蛋/","content":"\n<!-- # Raspberry Pi 化身 WiFi 蛋 -->\n## 前文\n我們已經改造 [Raspberry Pi 使用 4G 數據網路](/en/2020/Raspberry-Pi-connect-to-4G-LTE/)\n\n## 目標\n這次我們要讓 Raspberry Pi 將網絡分享給其他裝置，你可以選：\n- [製成**無線**路由器](#無線路由器)\n- [製成路由器（有線）](#有線路由器)\n\n## 無線路由器\n因為博主很懶惰，不想重複造輪子，所以無線路由器的教材就直接引用 [Sixfab 的教學](https://sixfab.com/using-sixfab-raspberry-p-shield-hat-as-a-wi-fi-hotspot-access-point/)\n\n如果你用的是早於 Raspberry Pi 3 的版本，你大概需要一個 USB 無線網路卡。\n\n### 備份無線網絡配置\n這並不是必須的步驟，不過萬一你日後想恢復原樣，這一步會很有幫助。\n\n```bash\n$ sudo cp /etc/wpa_supplicant/wpa_supplicant.conf /etc/wpa_supplicant/wpa_supplicant.backup.conf\n```\n\n### 配置無線網絡裝置\n用以下指令清除舊配置\n```bash\n$ sudo cp /dev/null /etc/wpa_supplicant/wpa_supplicant.conf\n```\n將以下的新配置寫入到 `/etc/wpa_supplicant/wpa_supplicant.conf`\n```\nctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev\nupdate_config=1\n```\n\n### 安裝 RaspAP\n有一個簡單的安裝精靈 [RaspAP](https://github.com/billz/raspap-webgui) 跟著它的步驟去進行安裝\n```bash\n$ wget -q https://git.io/voEUQ -O /tmp/raspap && bash /tmp/raspap -y\n```\n不過由於我本人並沒有試過這個方法，所以如果有任何疑問（例如默認的密碼、管理員界面等）還請前往 [Sixfab 的教學](https://sixfab.com/using-sixfab-raspberry-p-shield-hat-as-a-wi-fi-hotspot-access-point/) 和[原文教學（包含故障排除章節）](https://howtoraspberrypi.com/create-a-wi-fi-hotspot-in-less-than-10-minutes-with-pi-raspberry/)\n\n## 有線路由器\n我自己是用的這個方法，因為感覺會比較安心，始終有線的網絡感覺會比較穩定。這一部分就要使用網絡位址轉換技術（Network Address Translation，NAT）來連接 `ppp0` 和 `eth0` 兩個網絡界面（網卡）\n\n我是參考[將無線網絡分享到網線教程](https://raspberrypi.stackexchange.com/questions/48307/sharing-the-pis-wifi-connection-through-the-ethernet-port)然後將它改成將 PPP 網絡分享到網線\n\n### DHCP 和 DNS 伺服器\n你可以選自己喜歡的諸如 `isc-dhcp-server` 之類比較複雜的，這邊直接用 `dnsmasq` 比較方便\n```bash\n$ sudo apt-get install dnsmasq\n```\n### 設置網絡界面\n編輯 `/etc/network/interfaces` 裡的 `eth0` 部分\n```\nallow-hotplug eth0  \niface eth0 inet static  \n    address 192.168.2.1\n    netmask 255.255.255.0\n    network 192.168.2.0\n    broadcast 192.168.2.255\n```\n### 設置 dnsmasq\n先備份一下 dnsmasq 原本的設置\n```bash\n$ sudo mv /etc/dnsmasq.conf /etc/dnsmasq.conf.orig  \n```\n然後編輯 `/etc/dnsmasq.conf`\n```\ninterface=eth0      # 分享到 eth0  \nlisten-address=192.168.2.1 # 和/etc/network/interfaces配置的 IP 要一致  \n# Bind to the interface to make sure we aren't sending things elsewhere\n#### bind-interfaces #### BUT don't enable this.\nserver=8.8.8.8       # Forward DNS requests to Google DNS  \ndomain-needed        # Don't forward short names  \n# Never forward addresses in the non-routed address spaces.\nbogus-priv\n# Assign IP addresses between 192.168.2.2 and 192.168.2.100 with a\n# 12 hour lease time\ndhcp-range=192.168.2.2,192.168.2.100,12h \n```\n> 關於 **`bind-interfaces`** 部分，原本的教學是啟用的，不過我這邊啟用的話會無法分享網絡，所以這邊用`#`註釋掉了\n\n### 設置 NAT\n通過防火牆來設置 NAT\n```bash\n$ sudo iptables -t nat -A POSTROUTING -o wwan0 -j MASQUERADE  \n$ sudo iptables -A FORWARD -i wwan0 -o eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT  \n$ sudo iptables -A FORWARD -i eth0 -o wwan0 -j ACCEPT\n```\n#### 設置為永久 NAT\n保存設置\n```bash\n$ sudo sh -c \"iptables-save > /etc/iptables.ipv4.nat\"\n```\n修改 `/etc/rc.local` 開機自動載入 NAT 設置\n```\n# Add this line above exit 0\niptables-restore < /etc/iptables.ipv4.nat\n```\n## 完成\n將手提電腦連上 Raspberry Pi 然後……可以了\n```bash\n$ ping 8.8.8.8\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n64 bytes from 8.8.8.8: icmp_seq=2 ttl=51 time=99.2 ms\n64 bytes from 8.8.8.8: icmp_seq=1 ttl=51 time=22.9 ms\n64 bytes from 8.8.8.8: icmp_seq=3 ttl=51 time=69.7 ms\n```\n","tags":["Raspberry Pi","NAT","WWAN","4G","Router"]},{"title":"Video based Motion Detection in Python with OpenCV","url":"/en/2020/Video-based-Motion-Detection-in-Python-with-OpenCV/","content":"\n<!-- # Video based Motion Detection in Python with OpenCV -->\n## Demo\n<div class=\"video-container\">\n\t<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/4cB2BpSVxBY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</div>\n\nI added 30 seconds buffer before start recording so we can see the green color indicates the detected movements.\n\n## What you need\n- A Webcam\n- Python and pip\n\n### Requirements.txt\n```\nopencv-python\nnumpy\n```\n## Goal\nTo implement a security camera auto record videos when some thing moves in the view port.\n\n### Source code\nThe [original implementation](https://github.com/RobinDavid/Motion-detection-OpenCV) was in Python 2.x with OpenCV 3.x\n\nI fork it to Python 3.x and make it compatible with OpenCV 4.x\n\n> The **`MotionDetectorContours.py`** and **`MotionDetector.py`** results the same in the original implementation. But they give different result in my implementation, I guess it is because I skiped **`cv.Erode()`** in **`MotionDetectorContours.py`**.\n\n## The original implementation\nThere are two implementation according to the developer.\n\n### Simple way\n1. Receive frames and send to process in `run()`\n2. `processImage()` calculate difference of **pixels** in frames\n3. If number of different pixels exceed the threshold, `somethingHasMoved()` return `True`\n4. `run()` enable recording if `somethingHasMoved()` return `True`\n\n### Smart way\n1. Receive frames and send to process in `run()`\n2. `processImage()` calculate difference of **areas** in frames with `cv2.findContours()`\n3. If change of area in comparing to total area exceed the threshold, `somethingHasMoved()` return `True`\n4. `run()` enable recording if `somethingHasMoved()` return `True`\n\n## Our implementation\nOur implementation will be based on `MotionDetectorContours.py`. It did better job for me and it can catch my eye blinking.\n\nImport OpenCV for image processing, Numpy for replacing `cv2.CreateImage()`, datetime and tmie for showing video recording time.\n```python\nimport cv2 as cv\nimport numpy as np\nfrom datetime import datetime\nimport time\n```\nDefine a class for image processing and maintain the loop of reading frames.\n```python\nclass MotionDetectorAdaptative():\n  def onChange(self, val): #callback when the user change the detection threshold\n    pass\n\n  def __init__(self,threshold=25, doRecord=True, showWindows=True):\n    pass\n\n  def initRecorder(self): #Create the recorder\n    pass\n\n  def run(self):\n    pass\n\n  def processImage(self, curframe):\n    pass\n\n  def somethingHasMoved(self):\n    pass\n```\nThe initializatoin:\n```python\n  def __init__(self,threshold=25, doRecord=True, showWindows=True):\n    self.writer = None\n    self.font = None\n    self.doRecord=doRecord #Either or not record the moving object\n    self.show = showWindows #Either or not show the 2 windows\n    self.frame = None\n\n    self.capture=cv.VideoCapture(0)\n    self.frame = self.capture.read()[1] #Take a frame to init recorder\n    if doRecord:\n      self.initRecorder()\n\n    self.absdiff_frame = None\n    self.previous_frame = None\n\n    self.surface = self.frame.shape[0] * self.frame.shape[1]\n    self.currentsurface = 0\n    self.currentcontours = None\n    self.threshold = threshold\n    self.isRecording = False\n    self.trigger_time = 0 #Hold timestamp of the last detection\n    self.es = cv.getStructuringElement(cv.MORPH_ELLIPSE, (9,4))\n\n    if showWindows:\n      cv.namedWindow(\"Image\")\n      # for user to change threshold in runtime\n      cv.createTrackbar(\"Detection treshold: \", \"Image\", self.threshold, 100, self.onChange)\n\n```\n`run()` will maintain the loop to:\n1. read frame\n2. pass to `processImage()`\n3. check if anything moved in `somethingHasMoved()`, `isRecording = True` if things moved\n4. if `isRecording == True` a video recorder will be activated\n5. draw area of moved/changed to frame and display it on screen\n6. repeat the steps if `Esc` was not pressed\n\n```python\n  def run(self):\n    started = time.time()\n    while True:\n\n      currentframe = self.capture.read()[1]\n      instant = time.time() #Get timestamp o the frame\n\n      self.processImage(currentframe) #Process the image\n\n      if not self.isRecording:\n        if self.somethingHasMoved():\n          self.trigger_time = instant #Update the trigger_time\n          if instant > started +10:#Wait 5 second after the webcam start for luminosity adjusting etc..\n            print(\"Something is moving !\")\n            if self.doRecord: #set isRecording=True only if we record a video\n              self.isRecording = True\n        currentframe = cv.drawContours(currentframe, self.currentcontours, -1, (0, 255, 0), cv.FILLED)\n      else:\n        if instant >= self.trigger_time +10: #Record during 10 seconds\n          print(\"Stop recording\")\n          self.isRecording = False\n        else:\n          cv.putText(currentframe,datetime.now().strftime(\"%b %d, %H:%M:%S\"), (25,30),self.font, 1, (255, 0, 0), 2, cv.LINE_AA) #Put date on the frame\n          self.writer.write(currentframe) #Write the frame\n\n      if self.show:\n        cv.imshow(\"Image\", currentframe)\n\n      c=cv.waitKey(1) % 0x100\n      if c==27 or c == 10: #Break if user enters 'Esc'.\n        break\n```\nFind the change between frames and do simple feature extraction, result saved to `self.gray_frame`.\n```python\n  def processImage(self, curframe):\n      curframe = cv.GaussianBlur(curframe, (21,21), 0) #Remove false positives\n\n      if self.absdiff_frame is None: #For the first time put values in difference, temp and moving_average\n        self.absdiff_frame = curframe.copy()\n        self.previous_frame = curframe.copy()\n        self.average_frame = np.float32(curframe) #Should convert because after runningavg take 32F pictures\n      else:\n        cv.accumulateWeighted(curframe, self.average_frame, 0.05) #Compute the average\n\n      self.previous_frame = self.average_frame.astype(np.uint8) #Convert back to 8U frame\n\n      self.absdiff_frame = cv.absdiff(curframe, self.previous_frame) # moving_average - curframe\n\n      self.gray_frame = cv.cvtColor(self.absdiff_frame, cv.COLOR_BGR2GRAY) #Convert to gray otherwise can't do threshold\n      self.gray_frame = cv.threshold(self.gray_frame, 5, 255, cv.THRESH_BINARY)[1]\n\n      self.gray_frame = cv.dilate(self.gray_frame, self.es) #to get object blobs\n      # cv.Erode(self.gray_frame, self.gray_frame, None, 10)\n```\nFind the area of changes and compare to threshold over the whole area:\n```python\n  def somethingHasMoved(self):\n\n    # Find contours, ignore other return values (image, contours, hierarchy)[1]\n    contours = cv.findContours(self.gray_frame, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)[1]\n\n    self.currentcontours = contours #Save contours\n\n    self.currentsurface = sum([cv.contourArea(c) for c in contours]) #For all contours compute the area\n\n    avg = (self.currentsurface*100)/self.surface #Calculate the average of contour area on the total size\n    self.currentsurface = 0 #Put back the current surface to 0\n\n    if avg > self.threshold:\n      return True\n    else:\n      return False\n```\nIf user change threshold during runtime, `onChange()` method in the class will be triggered:\n```python\n  def onChange(self, val): #callback when the user change the detection threshold\n    self.threshold = val\n```\nDeclare a video recorder writes frame to video file:\n```python\n  def initRecorder(self): #Create the recorder\n    codec = cv.VideoWriter_fourcc('M', 'J', 'P', 'G')\n    self.writer=cv.VideoWriter(datetime.now().strftime(\"%b-%d_%H_%M_%S\")+\".wmv\", codec, 5, self.frame.shape[1::-1], 1)\n    #FPS set to 5 because it seems to be the fps of my cam but should be ajusted to your needs\n    self.font = cv.FONT_HERSHEY_SIMPLEX #Creates a font\n```\nLet's try it.\n```python\nif __name__==\"__main__\":\n  detect = MotionDetectorAdaptative(threshold=5, doRecord=True)\n  detect.run()\n```\n\n## Improvements\nThere is a problem the video only record for 10 seconds. Base on [MotionDetectorContours.py](https://github.com/NewJerseyStyle/Motion-detection-OpenCV/blob/master/MotionDetectorContours.py) modify its condition to end recording:\n```python\n        if instant >= self.trigger_time +10 and not self.somethingHasMoved(): #Record until move stop 10 seconds\n```\n\nWe can add an Email notification in this. You may refer to the tutorial sending [Email notification for network usage report](/en/2020/Network-usage-monitor-using-Python/). And we can then combine it with Raspberry Pi to build a security camera.\n\nYou will need these things for a Raspberry Pi security camera:\n- [Raspberry Pi](https://www.raspberrypi.org/products/raspberry-pi-4-model-b/)\n- [Raspberry Pi Camera Module V2](https://www.raspberrypi.org/products/camera-module-v2/)\n- [32 GB MicroSD Card](https://www.amazon.co.jp/10%E5%AF%BE%E5%BF%9C%E3%80%91Samsung-microSD%E3%82%AB%E3%83%BC%E3%83%8932GB-Nintendo-MB-MC32GA-ECO/dp/B06XSV23T1/ref=psdc_171386011_t3_B00J84T6HW)\n\n> If you ask, I used a [wide angle camera](https://www.amazon.co.jp/dp/B07VFFRX4C/ref=sspa_dk_detail_1?psc=1&pd_rd_i=B07VFFRX4C&pd_rd_w=uSbWD&pf_rd_p=6413bd85-d494-49e7-9f81-0e63e79171a9&pd_rd_wg=KjEEj&pf_rd_r=79C32JCV4SJVAGQEC7R6&pd_rd_r=0a132dab-0895-4d9f-aa14-439b4d6d1eeb&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUEzNk1ZN1I1UkI3RDM4JmVuY3J5cHRlZElkPUEwODcxNjM4M0RGT1ZERlg4Nlo2UCZlbmNyeXB0ZWRBZElkPUEySU9FRjk0M1ZBWFQ1JndpZGdldE5hbWU9c3BfZGV0YWlsJmFjdGlvbj1jbGlja1JlZGlyZWN0JmRvTm90TG9nQ2xpY2s9dHJ1ZQ==)\n\nSixfab has a tutorial about [Raspberry Pi Security System with Sixfab 3G, 4G/LTE Base Shield](https://sixfab.com/tutorial-7-raspberry-pi-security-system-with-sixfab-3glte-shields/). It seem to use a motion sensor to detect moment in the area and activate camera when sensor detect movement, it then send a frame to a email specified in the Python script.\n\nI didn't find the hardware list of their design, but the [Python source code is here](https://raw.githubusercontent.com/sixfab/Sixfab_RPi_3G-4G-LTE_Base_Shield/master/tutorials/tutorial7/SecuritySystem.py).\n\nI think using a motion sensor is a good idea, [Docker Pi Series of Sensor Hub](https://www.instructables.com/id/Docker-Pi-Series-of-Sensor-Hub-Board-About-IOT/) seem to be a good option, considering to have it in my production environment.","tags":["Python3","Coding","OpenCV"]},{"title":"Raspberry Pi 使用 4G 數據網路","url":"/zh-TW/2020/Raspberry-Pi-使用-4G-數據網路/","content":"\n<!-- # Raspberry Pi connect to 4G LTE -->\n## 購物清單\n- [Raspberry Pi](https://www.raspberrypi.org/products/)\n- SD Card with [Linux installed](https://projects.raspberrypi.org/en/projects/raspberry-pi-setting-up)\n- [Raspberry Pi 3G/4G-LTE Base HAT](https://sixfab.com/product/raspberry-pi-base-hat-3g-4g-lte-minipcie-cards/)\n- [Quectel EC25 Mini PCle 4G/LTE Module](https://sixfab.com/product/quectel-ec25-mini-pcle-4glte-module/)\n- [LTE Main & Diversity & GNSS Triple Port u.FL Antenna ](https://sixfab.com/product/lte-main-diversity-gnss-triple-port-u-fl-antenna-100mm/)\n\n> 不想分開購買零件，可以[購買 Sixfab 的 Raspberry Pi 4G/LTE套件](https://sixfab.com/product/raspberry-pi-4g-lte-modem-kit/)\n\n## 組裝\n1. 安裝 Mini PCIe 4G IoT Module 到 3G/4G-LTE Base HAT，感覺和以前在手提電腦上安裝記憶體差不多。\n\n2. 然後將 3G/4G-LTE Base HAT 裝上 Raspberry Pi。\n![Installed onto Pi](https://sixfab-com.exactdn.com/wp-content/uploads/2019/09/Base_HAT_with_EC25A.jpg?strip=all&lossy=0&ssl=1 \" After assembly Raspberry Pi @sixfab \")<center>*完成之後大概這樣的感覺（圖片來源：[@sixfab](https://sixfab.com/product/raspberry-pi-base-hat-3g-4g-lte-minipcie-cards/)）*</center>\n\n3. 將天線也安裝上去，正確地完成安裝之後的樣子大概這樣\n![Connect Antenna](https://www.torbox.ch/wp-content/uploads/2019/12/IMG_5237-e1576357032325.jpg \" Complete assembly @https://www.torbox.ch/?p=1165 \")<center>*加上天線應該這樣個樣子吧（圖片來源：[@torbox.ch](https://www.torbox.ch/?p=1165)）*</center>\n\n最左邊和最右邊的兩個天線似乎是可以互換的，我安裝完成之後那些線是平行的。\n\n## 安裝驅動\nSixfab 提供了兩種方法驅動 LTE 模組，一個是 [PPP](https://sixfab.com/ppp-installer-for-sixfab-shield/) 一個是 [QMI interface](https://sixfab.com/qmi-interface-with-3g-4g-lte-base-shield-v2/)。這邊我用的是 PPP。\n\n在 Raspberry Pi 的終端模擬器裡進行操作，下載 sixfab 的安裝腳本，然後跟著指引進行安裝就可以了。簡單方便快捷，感謝sixfab。\n```bash\n$ wget https://raw.githubusercontent.com/sixfab/Sixfab_PPP_Installer/master/ppp_installer/install.sh\n\n$ chmod +x install.sh\n\n$ sudo ./install.sh \n```\n\n### 有些選項可能比較曖昧，給個避坑指南\n- Choose your Sixfab\n  - 因為買的是 `3G, 4G/LTE Base Shield` 所以只填 `2`\n  - 就算之後連不上也肯定不是這裡填錯\n- APN\n  - 問問谷歌、雅虎或者百度你這家電信商的基地台用什麼存取點名稱（APN），選一個填，不對之後再改\n  - 將你的 SIM 卡插入智能電話，看看設定裡行動網絡設定關於存取點名稱裡有什麼選項，選一個填，不對之後再改\n  - 之後修改的方法參見出坑指南\n- PORT name\n  - 因為買的是 `3G, 4G/LTE Base Shield` 所以只填 `ttyUSB3`\n  - 肯定是 `ttyUSB3`，跟實際上你硬件上插哪個 USB 位置好像沒關係，可能是用的 GPIO？\n\n## 沒能避開坑？出坑指南\n### 我需要登入才能上網\n如果你需要用戶名和密碼登入才能上網，完成前面的安裝和設定之後再編輯 `/etc/ppp/peers/provider` 檔案。\n\n你要移除這一行\n```\nnoauth\n```\n然後按照以下格式填入登錄資料\n```\nuser \"YOUR USERNAME\"\npassword \"YOURPASSWORD\"\n```\n### 遇到 Routing error 的錯誤\n執行以下指令\n```bash\n$ sudo route del default\n\n$ sudo route add default ppp0\n```\n### 沒有網絡連接\n誰也 ping 不到，網絡不通，或者無盡的連接超時\n```bash\n$ ping 8.8.8.8\nconnect: network is unreachable \n$ ping baidu.com\nconnect: network is unreachable \n````\n> 檢查你的移動數據是否需要先在手機上啟用\n\n試試手動連接移動數據\n```bash\n$ sudo pon\n```\n你可能發現 Modem hang up 並且不論你做什麼都沒有什麼效果。\n\n我已經坑過幾次了，基本上問題就是 APN 填錯了，或者舊的 APN 已經不能用了。於是我將 SIM 插入手機，看手機自動連上網絡的時候用的哪個 APN 再修改 `/etc/ppp/peers/provider` 文件\n```bash\n$ sudo poff\n$ sudo nano /etc/ppp/peers/provider\n```\nAPN 在我 `/etc/ppp/peers/provider` 文件裡第三行的結尾。\n\n逐一測試你所能找到的 APN，看看 `sudo pon` 能不能連上，應該其中一個能連上。至少我是成功了。\n## DONE\n```bash\n$ ping 8.8.8.8\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n64 bytes from 8.8.8.8: icmp_seq=1 ttl=52 time=20.9 ms\n64 bytes from 8.8.8.8: icmp_seq=2 ttl=52 time=111 ms\n64 bytes from 8.8.8.8: icmp_seq=3 ttl=52 time=69.7 ms\n```\n","tags":["Raspberry Pi","WWAN","4G","LTE"]},{"title":"Network usage monitor using Python","url":"/en/2020/Network-usage-monitor-using-Python/","content":"\n<!-- # Network usage monitor using Python -->\n## Previous\nWe have [built a 4G/LTE router](/en/2020/Raspberry-Pi-as-4G-LTE-Router/) but how do I know its network usage? How much will it cost me?\n\n## Goal\nWe are now going to write a Python script to send Email notificatoin for network usage and set a threshold for it.\n\n> I assume you know the basic pattern how to code in Python\n\n## Requirements.txt\n```\npsutil\npython_http_client\nsendgrid\n```\n\nYou can install them by typing in terminal:\n```bash\n$ pip3 install psutil python_http_client sendgrid\n```\n\n> You may need to specify **`pip3`** in Raspbian as both Python 2.x and Python 3.x were installed.\n\n## Coding Python\n```bash\n$ mkdir network-monitor\n$ cd network-monitor\n$ nano monitor.py\n```\nAnd then we start coding\n### Get network usage\n```python\nimport psutil\n\nNETWORK_INTERFACE = 'ppp0'\n\nnetio = psutil.net_io_counters(pernic=True)\nnet_usage = netio[NETWORK_INTERFACE].bytes_sent + netio[NETWORK_INTERFACE].bytes_recv\n\nprint(net_usage, \"bytes\")\n```\nIt will show you how many bytes it has transfered for upload and download.\n> If it shows zero, change **`NETWORK_INTERFACE`** to **`wwan0`**.\n### Set threshold\n```python\nimport psutil\n\nNETWORK_INTERFACE = 'wwan0'\nNETWORK_LIMIT = 5000000 # 5GB in SI standard\n\nwhile True:\n  netio = psutil.net_io_counters(pernic=True)\n  net_usage = netio[NETWORK_INTERFACE].bytes_sent + netio[NETWORK_INTERFACE].bytes_recv\n\n  if net_usage > NETWORK_LIMIT:\n    print(\"Meets network limit!\")\n\n    print(net_usage, \"bytes has been used\")\n```\nOnce it over the `NETWORK_LIMIT` it will print a lot of lines of \"Meets network limit!\". We can add a timer to check the network limit every X second.\n### Separate the config and code\nTry to separate the cnofiguratoin and the Python script so we can reuse this project on other devices.\n\n`configparser` is really a good helper on this.\n\nCreate a file `monitor.conf`\n```\n[Email]\nSENDGRID_API_KEY = Your.Keyfrom_SendGrid\nfrom = helper@raspberry.pi\nto = your@email.address\nsubject = From your Raspberry Pi\n\n[Network]\nINTERFACE = wwan0\nLIMIT = 45000000000\n\n[Misc]\nTIME_INTER = 36\n```\n\nNow we can load the configuration in Python\n```python\nimport time\nimport psutil\nimport configparser\nconfig = configparser.ConfigParser()\nconfig.optionxform = str  #reference: http://docs.python.org/library/configparser.html\nconfig.read('monitor.conf')\n\nNETWORK_INTERFACE = config.get('Network', 'INTERFACE')\t\t# Define interface to check\nNETWORK_LIMIT = int(config.get('Network', 'LIMIT'))\t\t\t# Define network limit\nSENDGRID_API_KEY = config.get('Email', 'SENDGRID_API_KEY')\t# Define the API key for SendGrid\nTIME_INTER = config.get('Misc', 'TIME_INTER')\t\t\t\t# Define time interval 36 seconds\n\nwhile True:\n  time.sleep(TIME_INTER) # Check every 36 seconds\n  netio = psutil.net_io_counters(pernic=True)\n  net_usage = netio[NETWORK_INTERFACE].bytes_sent + netio[NETWORK_INTERFACE].bytes_recv\n\n  if net_usage > NETWORK_LIMIT:\n    print(\"Meets network limit!\")\n\n    print(net_usage, \"bytes has been used\")\n```\n\n### Prepare for the Email\nWe use SendGrid to send the Email notification in this tutorial.\n\n> You may need to sign up on SendGrid. I choose it because of 100 free email quota every day.\n\n#### Generate SendGrid API Key\nThe option is in **Setting -> API Keys -> Create API Key** [Creating an API key](https://sendgrid.com/docs/ui/account-and-settings/api-keys/#creating-an-api-key)\n\n#### Copy the Key and paste to monitor.conf\n```\n[Email]\nSENDGRID_API_KEY = Your.Keyfrom_SendGrid\n```\n\n### Write python script\nRefer to their official guide [SendGrid GitHub repo](https://github.com/sendgrid/sendgrid-python)\n```python\nimport time\nimport psutil\nimport sendgrid\nfrom sendgrid.helpers.mail import *\n```\nRead the `monitor.conf`\n```python\nimport configparser\nconfig = configparser.ConfigParser()\nconfig.optionxform = str  #reference: http://docs.python.org/library/configparser.html\nconfig.read('netio-mon.conf')\n\nNETWORK_INTERFACE = config.get('Network', 'INTERFACE')\nNETWORK_LIMIT = int(config.get('Network', 'LIMIT'))\nNETWORK_MAX = int(config.get('Network', 'MAX'))\nSENDGRID_API_KEY = config.get('Email', 'SENDGRID_API_KEY')\nTIME_INTER = config.get('Misc', 'TIME_INTER')\n```\nI would like to have some loggings too so I added this line\n```python\nimport logging\n\nloggingFile = logging.FileHandler('my.log', 'w', 'utf-8')\n\nlogging.basicConfig(level=logging.DEBUG,\n        format='%(asctime)s %(levelname)s %(message)s',\n        datefmt='%Y-%m-%d %H:%M',\n        handlers=[loggingFile, ])\n```\nDeclare two methods for sending Email\n```python\ndef create_message(sender, to, subject, message_text):\n  logging.info(\"send email::\" + message_text)\n  from_email = Email(sender)\n  to_email = To(to)\n  subject = subject\n  content = Content(\"text/plain\", message_text)\n  return Mail(from_email, to_email, subject, content)\n\n\ndef send_message(service, message):\n  return service.client.mail.send.post(request_body=message.get())\n```\nNow the mean loop to check the network usage periodically.\n```python\n# Initialize the SendGrid API\nservice = sendgrid.SendGridAPIClient(api_key=SENDGRID_API_KEY)\n\n# A flag to make sure only send one notification\nhave_sent = False\n\nwhile True:\n  time.sleep(TIME_INTER)\n  netio = psutil.net_io_counters(pernic=True)\n  net_usage = netio[NETWORK_INTERFACE].bytes_sent + netio[NETWORK_INTERFACE].bytes_recv\n  if net_usage > NETWORK_LIMIT and not have_sent:\n    message = create_message(\n      config.get('Email', 'from'),\n      config.get('Email', 'to'),\n      config.get('Email', 'subject'),\n      'The network have used %s bytes' %net_usage)\n    send_message(service, message)\n    have_sent = True\n```\n## Improvement\n- Prevent network usage lost, save the usage in the last email with `pickle`\n- In order to monitoring network usage continuously, set one more `NETWORK_MAX` for reseting the flag after first email notification\nSee my [GitHub Repo](https://github.com/NewJerseyStyle/network-monitor)\n","tags":["Raspberry Pi","Python3","Monitoring","Email","Coding"]},{"title":"Raspberry Pi connect to 4G LTE","url":"/en/2020/Raspberry-Pi-connect-to-4G-LTE/","content":"\n<!-- # Raspberry Pi connect to 4G LTE -->\n## What you need\n- [Raspberry Pi](https://www.raspberrypi.org/products/)\n- SD Card with [Linux installed](https://projects.raspberrypi.org/en/projects/raspberry-pi-setting-up)\n- [Raspberry Pi 3G/4G-LTE Base HAT](https://sixfab.com/product/raspberry-pi-base-hat-3g-4g-lte-minipcie-cards/)\n- [Quectel EC25 Mini PCle 4G/LTE Module](https://sixfab.com/product/quectel-ec25-mini-pcle-4glte-module/)\n- [LTE Main & Diversity & GNSS Triple Port u.FL Antenna ](https://sixfab.com/product/lte-main-diversity-gnss-triple-port-u-fl-antenna-100mm/)\n\n> Alternative option: [Raspberry Pi 4G/LTE HAT Kit from Sixfab](https://sixfab.com/product/raspberry-pi-4g-lte-modem-kit/)\n\n## Assembly\n1. Install Mini PCIe 4G IoT Module on Raspberry Pi 3G/4G-LTE Base HAT, it is similar to installing RAM modules in laptop.\n\n2. Install Raspberry Pi 3G/4G-LTE Base HAT on Raspberry, it is simple.\n![Installed onto Pi](https://sixfab-com.exactdn.com/wp-content/uploads/2019/09/Base_HAT_with_EC25A.jpg?strip=all&lossy=0&ssl=1 \" After assembly Raspberry Pi @sixfab \")<center>*After assembly Raspberry Pi [@sixfab](https://sixfab.com/product/raspberry-pi-base-hat-3g-4g-lte-minipcie-cards/)*</center>\n\n3. Connect the Antenna to the Raspberry Pi 3G/4G-LTE Base HAT, the wire should be parallel if you connect them to right port.\n![Connect Antenna](https://www.torbox.ch/wp-content/uploads/2019/12/IMG_5237-e1576357032325.jpg \" Complete assembly @https://www.torbox.ch/?p=1165 \")<center>*Complete assembly [@torbox.ch](https://www.torbox.ch/?p=1165)*</center>\n\nThe function of two outermost cable seem to be identical, all Antenna cables are parallel in my assembly and it works well.\n\n## Driver\nSixfab provides two methods to control the LTE module, [PPP](https://sixfab.com/ppp-installer-for-sixfab-shield/) and [QMI interface](https://sixfab.com/qmi-interface-with-3g-4g-lte-base-shield-v2/).\n\nI used PPP connection here.\n\n```bash\n$ wget https://raw.githubusercontent.com/sixfab/Sixfab_PPP_Installer/master/ppp_installer/install.sh\n\n$ chmod +x install.sh\n\n$ sudo ./install.sh \n```\n\n### Few options confused me and here are tips:\n- Choose your Sixfab\n  - Always `2` for the `3G, 4G/LTE Base Shield`\n- APN\n  - Google the APN for the service provider\n  - Or insert the SIM Card to a phone and view the APN in settings\n- PORT name\n  - For 3G, 4G/LTE Base Shield && Base HAT it will be `ttyUSB3`\n  - Always `ttyUSB3`, no thing to do with physical port\n\n## Troubleshooting\n### Need auth option in setup\nIf your service provider need username/password to use the network, edit `/etc/ppp/peers/provider` later to add your username and password.\nRemove line\n```\nnoauth\n```\nAnd add two lines\n```\nuser \"YOUR USERNAME\"\npassword \"YOURPASSWORD\"\n```\n### Routing error\nIn this case, run the following commands\n```bash\n$ sudo route del default\n\n$ sudo route add default ppp0\n```\n### No network\nTry manually connect to cellular network:\n```bash\n$ sudo pon\n```\nModem hang up and you tried all solution, nothing work and do not know why\n\nI have encountered few time on this problem, it hang up while connecting to network.\nBecause of incorrect APN, try all APN you can find on network and in your phone’s setting. To change the APN, edit `/etc/ppp/peers/provider`\n```bash\n$ sudo poff\n$ sudo nano /etc/ppp/peers/provider\n```\nThe APN is on the end of the 3rd line in my `/etc/ppp/peers/provider`.\n\nTry every APN you can find for the service provider try connect with `sudo pon` and one of them should work.\n## DONE\n```bash\n$ ping 8.8.8.8\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n64 bytes from 8.8.8.8: icmp_seq=1 ttl=52 time=20.9 ms\n64 bytes from 8.8.8.8: icmp_seq=2 ttl=52 time=111 ms\n64 bytes from 8.8.8.8: icmp_seq=3 ttl=52 time=69.7 ms\n```\n","tags":["Raspberry Pi","WWAN","4G","LTE"]},{"title":"Raspberry Pi as 4G LTE Router","url":"/en/2020/Raspberry-Pi-as-4G-LTE-Router/","content":"\n<!-- # Raspberry Pi as 4G LTE Router -->\n## Previous\nWe have [established connection to 4G LTE network](/en/2020/Raspberry-Pi-connect-to-4G-LTE/)\n\n## Goal\nWe are going to turn the Raspberry Pi into a Router for our devices, pick your need:\n- [Goto Wireless router section](#Wireless-Router)\n- [Goto Wired router section](#Wired-Router)\n\n## Wireless Router\nInstead of reinventing the wheel, we follow the guide [Sixfab tutorial](https://sixfab.com/using-sixfab-raspberry-p-shield-hat-as-a-wi-fi-hotspot-access-point/)\n\nIf you are using Raspberry Pi 2 or earlier, you will need a USB WiFi adaptor.\n\n### Backup wireless configurations\nNot a must but you may want to do this, in case later you changed your mind.\n\n```bash\n$ sudo cp /etc/wpa_supplicant/wpa_supplicant.conf /etc/wpa_supplicant/wpa_supplicant.backup.conf\n```\n\n### Configure wireless device\nClear the configuration file\n```bash\n$ sudo cp /dev/null /etc/wpa_supplicant/wpa_supplicant.conf\n```\nAdd configurations into `/etc/wpa_supplicant/wpa_supplicant.conf`:\n```\nctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev\nupdate_config=1\n```\n\n### Install RaspAP\nUse a quick installer of [RaspAP](https://github.com/billz/raspap-webgui) and follow the questions to setup the wireless network\n```bash\n$ wget -q https://git.io/voEUQ -O /tmp/raspap && bash /tmp/raspap -y\n```\nI did not tested this, so any problem or question (default password etc.), please refer to the [Sixfab tutorial](https://sixfab.com/using-sixfab-raspberry-p-shield-hat-as-a-wi-fi-hotspot-access-point/) and the toubleshooting in the [original tutorial](https://howtoraspberrypi.com/create-a-wi-fi-hotspot-in-less-than-10-minutes-with-pi-raspberry/)\n\n## Wired Router\nWe are going to use network address translation (NAT) to bridge `ppp0` with `eth0`\n\nThis tutorial was adopting [sharing wifi through the ethernet](https://raspberrypi.stackexchange.com/questions/48307/sharing-the-pis-wifi-connection-through-the-ethernet-port) and change it to share PPP connection to ethernet\n\n### DHCP and DNS server\nI used `dnsmasq` for DHCP + DNS.\n```bash\n$ sudo apt-get install dnsmasq\n```\n### Configurate interfaces\nEdit the `eth0` section in file `/etc/network/interfaces`:\n```\nallow-hotplug eth0  \niface eth0 inet static  \n    address 192.168.2.1\n    netmask 255.255.255.0\n    network 192.168.2.0\n    broadcast 192.168.2.255\n```\n### Configure dnsmasq\nBackup dnsmasq configuration\n```bash\n$ sudo mv /etc/dnsmasq.conf /etc/dnsmasq.conf.orig  \n```\nEdit `/etc/dnsmasq.conf`\n```\ninterface=eth0      # Use interface eth0  \nlisten-address=192.168.2.1 # listen on  \n# Bind to the interface to make sure we aren't sending things elsewhere  \n#### bind-interfaces #### BUT don't enable this.\nserver=8.8.8.8       # Forward DNS requests to Google DNS  \ndomain-needed        # Don't forward short names  \n# Never forward addresses in the non-routed address spaces.\nbogus-priv\n# Assign IP addresses between 192.168.2.2 and 192.168.2.100 with a\n# 12 hour lease time\ndhcp-range=192.168.2.2,192.168.2.100,12h \n```\n> Enable **`bind-interfaces`** cause me unable to share the internet. You may need to test it.\n\n### NAT configuration\n```bash\n$ sudo iptables -t nat -A POSTROUTING -o wwan0 -j MASQUERADE  \n$ sudo iptables -A FORWARD -i wwan0 -o eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT  \n$ sudo iptables -A FORWARD -i eth0 -o wwan0 -j ACCEPT\n```\nMake the rules persistent.\n```bash\n$ sudo sh -c \"iptables-save > /etc/iptables.ipv4.nat\"\n```\nEdit `/etc/rc.local`\n```\n# Add this line above exit 0\niptables-restore < /etc/iptables.ipv4.nat\n```\n## DONE\nConnect my laptop to Raspberry Pi \n```bash\n$ ping 8.8.8.8\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n64 bytes from 8.8.8.8: icmp_seq=2 ttl=51 time=99.2 ms\n64 bytes from 8.8.8.8: icmp_seq=1 ttl=51 time=22.9 ms\n64 bytes from 8.8.8.8: icmp_seq=3 ttl=51 time=69.7 ms\n```\n","tags":["Raspberry Pi","NAT","WWAN","4G","Router"]},{"title":"Hello World","url":"/en/2020/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"}]